УДК 004.05+004.4’23

              А.А. ПЕТРОВ , В.А. ПАРХОМЕНКО
       СРАВНЕНИЕ ОТКРЫТЫХ CI/CD ПЛАТФОРМ ПО
      ЭФФЕКТИВНОСТИ ПРОВЕДЕНИЯ НАГРУЗОЧНОГО
                    ТЕСТИРОВАНИЯ

Петров А.А., Пархоменко В.А. Сравнение открытых CI/CD платформ по эффективности
проведения нагрузочного тестирования.
    Аннотация. В работе рассмотрены CI/CD платформы с открытым исходным кодом. Для
сравнения выбраны Jenkins, GitLab CI и Drone. В них проверялось проведение нагрузочного
тестирования, сбора метрик о производительности и формирование отчетов с последующей
отправкой через Telegram, Email и файловую систему. В отличие от классических систем,
Drone предоставляет минималистичный и гибкий подход к конфигурации пайплайнов,
основанный на контейнерной структуре. Однако для его полноценного сравнения
потребовалось разработать отдельный плагин. Проведено функциональное, мутационное
тестирование и профилирование, подтверждающие корректность и эффективность работы
нового плагина на базе k6. В работе представлена новая технология поиска оптимального
сочетания использования ресурсов оперативной памяти и высокой производительности
на основе выбора интервала ожидания между параллельно работающими приложениями
в Drone (на примере ожидания между проверками готовности отчетов k6). Сравнение с
аналогами на базе Jenkins и GitLab CI показало конкурентоспособность предложенного
подхода: среднее время выполнения пайплайна составило 29 секунд (против 31 у Jenkins и
36 у GitLab), а среднее потребление оперативной памяти — 526 МБ (против 990 у Jenkins и
588 у GitLab).
    Ключевые слова: CI/CD, opensource, drone, плагин, нагрузочное тестирование, k6,
Jenkins, Gitlab CI.


       С развитием программирования требования к качеству и надеж-
ности программного обеспечения становятся все более высокими. Ав-
томатизация процессов сборки, тестирования и развертывания выходит
на первый план. Одним из важнейших подходов в данной области яв-
ляется Continuous Integration / Continuous Deployment (далее — CI/CD)
— непрерывная интеграция и непрерывное развертывание. Каждый из ин-
струментов CI/CD имеет свои особенности, преимущества и ограничения,
что требует осознанного выбора при разработке и запуске соответствую-
щих процессов (далее — пайплайна).
       Лидерами на рынке свободно-распространяемого программного
обеспечения считаются Jenkins и GitLab, однако существуют и менее
распространенные платформы, например, Drone, Argo CD и Flux. Два
последних инструмента фокусируются исключительно на CD, не предо-
ставляя встроенных механизмов CI, поэтому они исключены из сравнения
на этапе предварительного отбора, несмотря на зрелость технологий по
мнению CNCF [1]. По мнению исследователей [2] Jenkins, GitLab, Drone
и Netlify являются одними из самых востребованных. Однако Netlify
выделяют как наиболее специализированную на веб-ориентированных
системах платформу, что несколько сужает область ее применения и
поэтому она также исключена из сравнения.
       По мнению авторов обзорной статьи [2], наблюдается тенденция
на миграции с платформы Travis и приток пользователей к платформе
GitHub Actions. Другой тенденцией в области CI/CD является активизация
использования искусственного интеллекта. В частности, формирование
корректирующих и предупредительных действий на основе анализа изме-
нений в репозиториях кода с помощью алгоритмов машинного обучения
обсуждается в [3], а автоматизированное создание модульных тестов
с помощью LLM — в [4, 5]. В [6] CI/CD подход адаптирован для по-
иска воспроизводимых сборок программ (устойчиво воспроизводимое
формирование побитово идентичного бинарного исполняемого файла
из исходного кода) в качестве самостоятельного метода повышения без-
опасности программ. Вопросы энергетической эффективности создания
сборок затрагиваются в [7].
       Drone [8] — легковесная и масштабируемая система автоматизации
CI/CD. В основе этого инструмента лежит технология контейнеризации,
поэтому он позволяет запускать процессы сборки, тестирования и развер-
тывания в изолированных средах (контейнерах). Это делает его довольно
гибким. Однако мы не смогли найти для Drone готовых плагинов нагрузоч-
ного тестирования и решения сопутствующих задач. Требуется доработка
имеющихся средств в виде обертки в Drone для проведения сравнения.
       Основной гипотезой в рамках исследования является лучшая
эффективность проведения нагрузочного тестирования (использование
меньшего объема оперативной памяти, времени работы плагина) в Drone
по сравнению с Jenkins и GitLab за счет гибкой настройки и контейнерной
архитектуры первого. Основным ограничением экспериментов является
использование стандартных средств нагрузочного тестирования в Jenkins
и GitLab. Создание и настройка плагина в Drone, в свою очередь, оп-
тимизируется. Цель работы — разработка плагина сбора метрик при
нагрузочном тестировании для Drone и его сравнение с аналогами в
Jenkins и GitLab.
       Для сопоставимости сравнения трех платформ в качестве основ-
ного компонента тестирования решено использовать k6 [9]. В каждой
платформе решались три задачи:
       1. Проведение нагрузочного тестирования.
       2. Сбор метрик производительности.
       3. Формирование отчета и его отправка в Telegram, Email и файло-
вую систему.
       Для их решения в Jenkins и GitLab требуется последовательное
выполнение нескольких независимых друг от друга приложений. Для
этого нужно запустить, как минимум, три шага в цепочке пайплайна, что
усложняет понимание процесса и повышает вероятность возникновения
неожиданных ошибок. Разработанный плагин позволяет выполнить все эти
действия за один шаг в пайплайне, получая ту же функциональность. Все
шаги сравнения CI/CD платформ автоматизированы и вместе с плагином
размещены в открытом доступе [10]. Для сравнения платформ исполь-
зовалось приложение «Книжный магазин» в качестве иллюстративного
примера.
       Дальнейшая часть работы организована следующим образом. В
разделе 1 представлен краткий обзор работ по сравнению CI/CD плат-
форм. В разделе 2 разрабатывается плагин-обертка над k6 для Drone, а в
разделе 3 описывается приложение для тестирования. В разделе 4 описан
процесс проверки, оптимизации работы плагина, а также его размещения
в DockerHub. В разделе 5 приводятся результаты экспериментального
сравнения CI/CD платформ по времени выполнения и потребляемой
оперативной памяти на примере нагрузочного тестирования.
       1. ИССЛЕДОВАНИЕ АНАЛОГОВ. Нагрузочное тестирование
— вид нефункционального тестирования, целью которого является провер-
ка работоспособности системы при ожидаемой или повышенной нагрузке.
Оно позволяет выявить поведение приложения при высоком числе поль-
зователей и является частью тестирования производительности.
       Во время нагрузочного тестирования в реальном времени ведут-
ся измерения, фиксируются данные о каждом запросе: время отклика,
успешность запроса, объем переданных данных и т.д. Также собирается
информация о состоянии системы: загрузка процессора, использование
памяти. По завершении теста все полученные данные агрегируются, и на
их основе рассчитываются ключевые метрики: среднее время отклика,
процент ошибок, пропускная способность, процентильные значения и дру-
гие показатели. Это позволяет сделать выводы о поведении приложения
под различной нагрузкой и выявить возможные проблемы.
       Существует много инструментов для нагрузочного тестирова-
ния. Наиболее популярными среди них являются Apache JMeter, k6 и
Gatling [11]. Для целей дальнейшего сравнения в платформах CI/CD вы-
бран k6, потому что он имеет открытый исходный код и позволяет писать
сценарии на JavaScript, а также легко запускается в Docker контейнере
и интегрируется в пайплайн CI/CD. Смена инструмента, на наш взгляд,
никак не повлияет на результаты сравнения платформ, так как везде
используется один и тот же фреймворк. Одним из ключевых преимуществ
k6 является наличие встроенных метрик производительности, таких как:
времени отклика, средней задержки, 95-й процентиль и др.
       1.1. Обзор публикаций. В качестве основного источника поиска
аналогичных работ мы использовали DBLP. В данной базе не найдено
работ на стыке CI/CD и нагрузочного тестирования, а запрос по сло-
вам "CI/CD"выдает 111 источников на момент подачи статьи. Однако из
этих работ всего две, на наш взгляд, наиболее релевантны выбранной
теме. Так, например, в [12] сравниваются Azure DevOps и GitHub по
следующим основным критериям: функциональность, масштабируемость,
защищенность, удобство использования и ценовая политика. Оба средства
выбраны с точки зрения поддержки Microsoft. Однако мы не нашли сравне-
ния численных характеристик эффективности работы данных платформ.
В [13] представлен обзор работ по использованию CI/CD платформ в
задачах защиты информации в облачных сервисах, вопросы численных
экспериментов также не обсуждаются.
       В [14] исследуются возможности использования фреймворка нагру-
зочного тестирования Kieker в Jenkins при организации CI/CD процессов
на специально подобранных программах для тестирования. Получены
оценки производительности на данных программах. Сравнение внедре-
ния Kieker в других платформах не производилось. Авторы заключают,
что внедрение нагрузочного тестирования в процесс разработки ПО с
одновременным использованием СI/CD платформ позволяет выявлять
проблемы производительности ПО на ранних стадиях разработки. Это,
безусловно, снижает издержки на выявление и исправление дефектов.
       В [15] рассматриваются вопросы нагрузочного тестирования
Jenkins и Gitlab, где под нагрузкой понимается облачное микросервисное
приложение на сервере Amazon. Численные временные эксперименты
доставки ПО показали, что Jenkins и Gitlab работают сопоставимо, если
в последнем используется индивидуально-настраиваемый запуск сбор-
ки. Авторы приходят к выводу, что Jenkins тяжело использовать в силу
многочисленных плагинов, которые приходится устанавливать в процес-
се разработки. Однако в этом заключается преимущество платформы,
т.к. можно разработать новый плагин для своих целей. Конечный выбор
предлагается осуществлять по потребностям разработчиков.
       В других работах можно также найти интересные сравнения плат-
форм интеграции и доставки. Так, например, в [16] сравниваются GitLab
и GitHub. На собранных наборах 12 тыс. репозиториев GitHub собирает
проекты из коммитов быстрее GitLab в среднем на 5,5 часов, а количе-
ство выявленных проблем по проекту в среднем больше на 83,34 штук.
Авторы приходят к мнению о «бесполезности» GitLab, с чем мы не можем
согласиться, так как эта платформа с открытым исходным кодом и не
может быть корректно сравнима с коммерческими продуктами. Созданию
мультипроектного и мультисредового средства для интеграции и доставки
ПО посвящена [17]. Авторы используют для этих целей Jenkins, одна-
ко не сравнивают эффективность с другими системами, ограничиваясь
обсуждением GitLab.
       В целом вопросы быстродействия исследуемых платформ для
проектов, которые долго собираются, имеют решающее значение. Так,
например, нагрузочное тестирование на регресс [18, 19] предполагает
сборку, запуск и тестирование каждой версии программы. В данных ра-
ботах проанализировано, как архитектура микросервисных программ
влияет на производительность программ. Основным результатом является
декомпозиция программы на компоненты, которые могут тестироваться
независимо в процессе разработки. Похожий подход, на основе комби-
наторного подхода к выполнению отдельных тестов, предложен в [20].
Авторы статьи анализируют 3 открытые программы, полный набор нагру-
зочных тестов на которых составляет 24 часа, а сокращенный на основе
предложений — 8,5 часов. В [21] описан статистический подход к иден-
тификации проблем к производительности программ. В [22] предлагают
использовать эффективность энергопотребления ПО в рамках настройки
пайплайнов, что позволяет отлаживать проекты с точки зрения заботы об
окружающей среде.
       Предсказание производительности программ в рамках CI/CD пай-
плайнов осуществлено в [23]. Авторы используют GitHub для применение
своей модели Performance Model eXtractor, оценка точности работы ко-
торой еще не осуществлена. Авторы [24] предлагают предсказательную
модель производительности программ, называемую CIPM, которая рабо-
тает инкрементально в процессе изменения кода при разработке. Подход
позволил снизить количество измерений на 12,6% – 83,3% в зависимости
от конкретных случаев. Исследована чувствительность CIPM при уве-
личении количества параметров. Показана хорошая масштабируемость
модели. Приложение для реализации модели написано авторами на Lua.
Предсказанию результатов нагрузочного тестирования посвящена ста-
тья [25]. Ансамблевый подход к прогнозированию позволяет улучшить
результаты на 24-94% по сравнению с отдельными моделями.
       В [26] исследуется применение технологии ускорения пайплайнов
Bazel в таких платформах как GitHub Actions, CircleCI, Travis CI и Buildkite.
Однако авторов интересовали агрегированные численные значения экс-
периментов, а не разбитые по отдельным платформам. Только 27,76%
всех репозиториев с Bazel используют его возможности для ускорения
сборок. Выгода измеряется от выигрыша в 2 до порядка 12 раз при разных
настройках параллелизации.
       Проведенное исследование публикаций показало недостаток работ
по сравнению CI/CD платформ. В научной литературе не обнаружено
сравнение Drone с другими открытыми платформами.
       1.2. Описательное сравнение CI/CD платформ. Результаты опи-
сательного сравнения выбранных ранее открытых CI/CD платформ приве-
дены в табл. 1. В ней использованы следующие критерии:
       – Востребованность - количество загрузок на DockerHub и актив-
ность на GitHub, отражающие реальное использование в сфере.
       – Лицензия - наличие открытой лицензии, позволяющей свободно
использовать систему.
       – Архитектура - контейнерная, монолитная или гибридная архи-
тектура, влияющая на масштабируемость.
       – Интеграция с нагрузочным тестированием - простота встраи-
вания инструментов, таких как k6.
       – Тип развертывания (платформа) - доступность CI/CD-системы
в виде SaaS (облачного сервиса), возможности для локального разверты-
вания.
       – Открытость исходного кода (Opensource) - наличие публичного
репозитория, степень открытости кода.
       2. РАЗРАБОТКА ПЛАГИНА В DRONE. Высокоуровневая ар-
хитектура плагина представлена на рис. 1. В качестве языка программи-
рования выбрана Java в связке с фреймворком Spring. Основная идея
заключается в следующем: запускать нагрузочное тестирование с по-
мощью k6, а затем собирать полученные метрики и отправлять их в
различные сервисы в удобном формате.
       Для управления параметрами плагина используются переменные
окружения, значения которых автоматически подставляются в конфигу-
рационный файл с помощью библиотеки Typesafe Config. Это обес-
печивает гибкость настройки без необходимости изменять исходный
код.
       2.1. Метрики. Для формирования отчетов необходимо определить
метрики, которые будут собираться и рассылаться. Для этого создан DTO-
класс Metrics, содержащий основные параметры производительности.
       Описание полей класса и соответствующих метрик приведено в
табл. 2.
           Таблица 1. Описательное сравнение CI/CD платформ
Критерий          Drone              Jenkins           GitLab CI
Тип развертыва- Self-hosted,         Self-hosted, Web SaaS
ния (Платформа) Docker,              container         (GitLab.com)
                  Kubernetes                           + Self-hosted
Востребованность 50M+                100M+             1B+
(Docker Hub)
Лицензия          Apache 2.0         MIT               MIT
Opensource        Да                 Да                Частично, только
                                                       Comunity версия
Сообщество        Небольшое, но Очень большое Большое сообще-
                  активное           сообщество        ство
Архитектура       Микросервисная Плагинно-             Интегрированная
                  (Docker-native)    монолитная        DevOps-
                                                       платформа
Интеграция с k6 Отличная (через Возможна (через Отличная
и нагрузочным Docker)                плагины)          (CI       YAML-
тестированием                                          интеграция)




              Рис. 1. Высокоуровневая архитектура плагина
      Таблица 2. Описание метрик нагрузочного тестирования
Поле                     Тип      Описание
_httpReqDurationAvg      double   Средняя длительность HTTP-
                                  запросов
_httpReqDurationP95      double   95-й перцентиль длительности
                                  HTTP-запросов
_httpReqDurationMax      double   Максимальная длительность
                                  HTTP-запроса
_iterationsCount         int      Общее количество итераций
                                  (вызовов функции default в
                                  K6)
_httpReqsCount           int      Количество      выполненных
                                  HTTP-запросов
_checksPasses            int      Количество успешно пройден-
                                  ных проверок check
_httpReqFailedValue      double   Доля (или процент) неудачных
                                  HTTP-запросов
_dataReceivedCount       int      Объем полученных данных в
                                  килобайтах
_vusMaxValue             int      Максимальное количество вир-
                                  туальных пользователей (VUs)
_httpReqWaitingMax       double   Максимальное время ожида-
                                  ния первого байта от сервера
                                  (TTFB)
       2.2. Классы плагина. В приложении плагина реализовано девять
основных классов. На рис. 2 представлена UML диаграмма классов плаги-
на, отражающая их структуру и взаимосвязи. Главным классом является
Transporter. Он отвечает за считывание конфигурационных парамет-
ров и организацию работы всех компонентов плагина. В этом классе
используется паттерн проектирования «Стратегия», который позволяет
динамически выбирать реализацию в зависимости от переданных пере-
менных окружения. Так, например, есть интерфейс DataShell, который
реализуют PdfFileShell, MarkdownShell, TextFileShell.




                 Рис. 2. UML диаграмма классов плагина

       Аналогичный подход применяется и для сервисов-подписчиков,
куда отправляется результат тестирования. Используется интерфейс
Follower, который реализуют следующие классы: TelegramFollower,
FileSystemFollower, EmailFollower. Класс FilesManager отвечает
за отслеживание появления итогового файла от k6. При запуске он
фиксирует начальное время, затем в установленный интервал времени
анализирует файловую систему. Как только тестирование завершается,
файл считывается, преобразуется в объект класса Metrics и передается
на следующий этап обработки.
       3. ПРИЛОЖЕНИЕ ДЛЯ ТЕСТИРОВАНИЯ. Для демонстрации
и тестирования работы CI/CD использовалось API-приложение на Java
Spring, реализующее функциональность книжного магазина. В качестве
СУБД применялась PostgreSQL. Функционал приложения и разработанная
модель сущность-связь приведены на рис. 3 и рис. 4, соответственно.
       Запуск приложения и базы данных осуществлялся с использова-
нием Docker и описывался в конфигурационных файлах Dockerfile и
docker-compose.yml. Это обеспечивало удобную изоляцию и переноси-
мость среды.
                  Рис. 3. REST-эндпоинты приложения




                   Рис. 4. Диаграмма сущность-связь


       4. Проверка и оптимизация работы плагина.
       4.1. Тестовое окружение. Все измерения в данном исследовании
производились на виртуальной машине под управлением Ubuntu 24.04.
Виртуальная машина имеет следующие характеристики:
       – 2 виртуальных ядра (AMD Ryzen 5 2600X).
       – 2 ГБ оперативной памяти.
       – Виртуальный SSD-диск объемом 30 ГБ.
       4.2. Общие результаты. Для оценки корректности работы плагина
проведены функциональные тесты, охватывающие все доступные каналы
доставки и форматы генерации отчетов. Для реализации модульных тестов
по проверке функциональности использовалась библиотека JUnit 5, а для
подмены зависимостей — Mockito.
       Для примера сценариев приведем шаги сценария отправки данных
в Telegram-бот, который использовался при создании тестов.
       – Создать бота:
       1. Начать диалог с @BotFather.
       2. Указать отображаемое имя бота и его username.
       3. Получить токен, который выдаст @BotFather - он понадобится
для отправки запросов к Telegram API.
       – Получение chat_id:
       1. Отправить сообщение созданному боту.
        2. Открыть в браузере следующий адрес, подставив полученный
 ранее токен: https://api.telegram.org/bot<токен нашего бота>/getUpdates
        3. Найти поле chat.id в ответе API. Оно находится в блоке: result
-> [0] -> message -> chat -> id.
        4.3. Мутационное тестирование. Мутационное тестирование
- это техника оценки качества тестов, при которой исходный код на-
 меренно модифицируется (создаются мутации), и затем проверяется,
 способны ли существующие тесты обнаружить эти изменения. Если тесты
 не проваливаются при наличии мутаций, это указывает на их слабую
 эффективность.
        В данном проекте для мутационного тестирования используется
 плагин Pitest, так как он является одним из самых популярных и удобных
 инструментов для Java. Он легко интегрируется с Maven и поддерживает
 фреймворк JUnit 5.
        Результаты итогового запуска мутационного тестирования пред-
 ставлены на рис. 5.




     Рис. 5. Результат второго запуска мутационного тестирования (Pitest)

       Для группы классов DataShell удалось снизить количество выжив-
ших мутантов до 45%. При этом устранены все мутации, затрагивающие
логику работы с данными. Оставшиеся мутанты связаны преимуществен-
но с нюансами форматирования (PDF, Markdown, TXT), которые сложно
отследить с помощью модульных тестов. Поэтому результат можно счи-
тать хорошим. В свою очередь, для группы классов Follower удалось
добиться почти полного устранения мутантов, что свидетельствует о
высоком качестве покрывающих тестов.
       Первоначальные настройки плагина показывали существенное
снижение потребления оперативной памяти (почти в два раза) по ре-
зультатам предварительного тестирования. Однако было зафиксировано
значительное отставание плагина по времени выполнения — в среднем на
3–4 секунды. В связи с этим, ключевым приоритетом стало повышение
производительности плагина с целью расширения круга потенциальных
пользователей. Решено донастроить плагин для оптимального сочетания
использование ресурсов оперативной памяти и высокой производительно-
сти без потери качества в функциональности.
        4.4. Выбор промежутка времени между проверками готовно-
сти отчета. Первоначальная архитектура предполагала параллельный
запуск самого плагина и процесса нагрузочного тестирования. Для ми-
нимизации нагрузки на CPU проверка наличия отчета осуществлялась
каждые 5 секунд. Однако при сравнительно коротком времени выполнения
нагрузочного теста такая задержка становилась критичной.
        Для выбора оптимального значения интервала ожидания между
проверками готовности отчетов k6 проведено экспериментальное иссле-
дование с использованием различных значений интервала, уменьшение
которого увеличивает загрузку CPU и уменьшает время выполнения
плагина. Для решения задачи оптимального выбора значения интервала
для каждого из интервалов, отображенных на рис. 6, проводилось по 5
повторных измерений. На график выведено среднее значение. Значения
дисперсии для интервалов 0,5 с., 1 с., 3 с. 4 с., 5 с. следующие: 0,167
с., 0,103 с., 0,053 с., 0,025 с., 0,013 с., 0,025 с., соответственно. Линией
на рисунке выведен график функции времени выполнения плагина от
значений интервала ожидания.
        Отметим, что график функции состоит из двух почти прямых
частей с точкой перегиба при значении переменной «1 секунда». Для
каждого значения переменной на рисунке цветом отображается загружен-
ность CPU, которая объясняет резкое изменение характера выявленной
закономерности. Значение «1 секунда» является оптимальной точкой, так
как дальнейшее уменьшение интервала не дает значительного прироста
в скорости, и лишь приводит к заметному росту нагрузки на CPU. На
основании полученных данных принято решение использовать данную
константу в качестве рабочего значения для настройки плагина.
        Результаты экспериментов показали увеличение средней загрузки
процессора на 4% по сравнению со значением константы до экспериментов
(«5 секунд»), что объясняется более частой сменой контекста выполнения
в операционной системе. Тем не менее, это увеличение оправдано: прирост
скорости позволяет плагину почти сравняться, а, в каких-то временных
отрезках, получить лучшие значения по времени выполнения плагина,
чем для Jenkins, сохранив при этом экономичное использование памяти.
        4.5. Профилирование. Для выявления узких мест в работе плаги-
на дополнительно проведено профилирование с использованием встро-
енного профайлера IntelliJ IDEA, который применяет async-profiler и
Java Flight Recorder. Профилирование было запущено в режиме «CPU
+ Memory», с фокусом на наиболее нагруженных участках приложения.
  Рис. 6. Тепловая карта загрузки CPU и скорость выполнения относительно
                   промежутка проверки готовности отчета


После записи были получены профили в виде flame-графов и дерева
вызовов:
      – Методы с максимальной нагрузкой CPU (рис. 7).
      – Методы с наибольшими аллокациями памяти (рис. 8).
      – Дерево вызовов с детализацией по памяти (рис. 9).
      – Дерево вызовов с детализацией по времени CPU (рис. 10).



              Рис. 7. Методы с максимальной нагрузкой CPU




       Рис. 8. Методы с наибольшими затратами на аллокации памяти

      Профилирование показало, что основная нагрузка по CPU и памяти
распределяется между методами инициализации, чтения файлов и сбора
метрик. Эти участки кода реализованы эффективно: основные трудоза-
тратные методы работают оптимально и их последующее улучшение не
требуется.
      4.6. Сборка приложения в Docker контейнер. Для упрощения
запуска и развертывания отлаженное приложение упаковано в Docker-
контейнер. На первом этапе происходит сборка Spring-приложения. Далее,
во втором этапе, в файл конфигурации нагрузочного тестирования вно-
сятся изменения: все вхождения localhost и 127.0.0.1 заменяются
на host.docker.internal. Это необходимо для того, чтобы тестовые
запросы корректно достигали нужных сервисов изнутри контейнера.
              Рис. 9. Дерево вызовов с детализацией по памяти




          Рис. 10. Дерево вызовов с детализацией по времени CPU


        После подготовки конфигурации одновременно запускаются два
 процесса: k6 и сам плагин. Плагин ожидает завершения теста, чтобы затем
 обработать и отправить полученные метрики. Для сборки контейнера
 используется команда «docker build -t plugin-name».
        Docker-образ плагина загружен на DockerHub, чтобы его можно
 было использовать в любых пайплайнах Drone CI/CD, скачивая напрямую
 из реестра по ссылке [27].
        5. Экспериментальное сравнение CI/CD платформ. Напомним,
 что тестируемое приложение и характеристики вычислительной машины
 описаны в рубриках 3 и 4.1, соответственно.
        Пайплайны во всех трех системах сопоставимы по структуре: на
 первом этапе выполнялась сборка и запуск тестируемого API-приложения.
 Во втором этапе различия заключались в способе организации нагрузоч-
 ного тестирования и последующей отправки результатов:
        – В Drone запускался разработанный плагин, который автоматиче-
 ски выполнял нагрузочное тестирование с использованием k6, собирал
 метрики и отправлял отчет через специальную библиотеку.
        – В Jenkins запуск k6 осуществлялся как отдельный шаг, а отправка
 результатов происходила через скрипт, использующий Telegram API.
        – В GitLab CI нагрузочное тестирование также проводилось с
 использованием k6, а отправка отчетов производилась аналогично Jenkins
- через внешний скрипт, обращающийся к Telegram API.
        Такой подход позволил сравнить производительность и удобство
 реализации тестирования в рамках разных CI/CD-сред.
        5.1. Результаты сравнения. На рис. 11 представлено сравнение
 загрузки процессора в трех платформах CI/CD: Jenkins, Drone и GitLab. В
 плане потребления ресурсов CPU система GitLab демонстрирует наилуч-
шие показатели: ее средняя нагрузка на процессор существенно ниже по
сравнению с другими решениями.
       На рис. 12 показано сравнение использования оперативной памяти.
Видно, что GitLab также демонстрирует низкое потребление RAM, при-
ближаясь по эффективности к системе Drone, которая изначально имела
минимальные показатели.
       На основе нескольких запусков рассчитано среднее время выполне-
ния - около 35–36 секунд. Этот показатель оказался выше по сравнению с
другими системами, где выполнение происходило быстрее.




              Рис. 11. Сравнительный график загрузки CPU




     Рис. 12. Сравнительный график потребляемой оперативной памяти

      Для наглядного представления основных характеристик сравнива-
емых CI/CD-систем составлена сводная табл. 3. В ней учтены следующие
параметры:
      1. Среднее время выполнения пайплайна.
      2. Объем потребляемой оперативной памяти (без учета штатного
потребления ОС).
      3. Средняя загрузка процессора.
           Рис. 13. Сравнительный график скорости выполнения


      4. Удобство использования (субъективная оценка).

    Таблица 3. Сравнительная таблица подходов в разных CI/CD-системах
 Характеристика                         Drone      Jenkins     GitLab
 Усредненное время выполнения            29          31          36
 пайплайна (сек)
 Потребление ОЗУ системами без           526         990         588
 учета штатного потребления ОС
 (МБ)
 Средний процент загрузки процес-      70.0%       68.8%       52.2%
 сора
 Удобство развертывания               Простое     Сложное      Среднее

       6. ЗАКЛЮЧЕНИЕ. В результате проделанной работы построен
CI/CD пайплайн на основе Drone CI/CD: настроен Git-сервер (Gitea [28]),
развернут Drone-сервер и агент, а также подготовлена среда для тести-
рования Java-приложения. На этой базе разработан плагин, реализую-
щий проведение нагрузочного тестирования с использованием k6, сбор
производственных метрик и отправку отчетов через различные каналы
(Telegram, Email, файловая система).
       Проведена работа по улучшению качества плагина в Drone. Основ-
ное внимание уделено следующим направлениям:
       – Экспериментально обоснованный выбор значения интервалов
между проверками готовности отчетов в зависимости от соотношения
общего времени выполнения плагина и загрузки CPU.
       – Реализация модульных тестов на основе JUnit 5 и расширение
охвата функциональности.
       – Проведение мутационного тестирования с использованием Pitest
для оценки качества тестов.
       Разработанный плагин для Drone по нагрузочному сравнению и
оповещению размещен открыто в [10] и DockerHub для удобства исполь-
зования другими пользователями. Проведена настройка аналогичного
функционала в Jenkins и GitLab CI на базе k6.
       Экспериментальное сравнение показало, что плагин для Drone обес-
печивает сопоставимую или лучшую производительность при значительно
меньшем потреблении оперативной памяти, а также позволяет упростить
пайплайн за счет объединения нескольких этапов в один, что существенно
ускоряет внедрение и снижает требования к ресурсам, особенно в сре-
дах с ограниченными вычислительными возможностями. Cреднее время
выполнения пайплайна составило 29 секунд (против 31 у Jenkins и 36 у
GitLab), а среднее потребление оперативной памяти — 526 МБ (против
990 у Jenkins и 588 у GitLab).
       Список литературы.
 [1] CNCF. Graduated and incubating projects. [Электронный ресурс].
     Дата обращения: 26.10.2025. [Online]. Available: https://www.cncf.io/
     projects/
 [2] P. Rostami Mazrae, T. Mens, M. Golzadeh, and A. Decan, “On the
     usage, co-usage and migration of ci/cd tools: A qualitative analysis,”
     Empirical Softw. Engg., vol. 28, no. 2, Mar. 2023. [Online]. Available:
     https://doi.org/10.1007/s10664-022-10285-5
 [3] Y. Bugayenko, K. Daniakin, M. Farina, F. Jolha et al.,
     “Extracting corrective actions from code repositories,” in Proceedings
     of the 19th International Conference on Mining Software
     Repositories (MSR 2022). ACM, 2022. [Online]. Available:
     https://dl.acm.org/doi/abs/10.1145/3524842.3528517
 [4] N. Alshahwan, J. Chheda, A. Finogenova, B. Gokkaya, M. Harman,
     I. Harper, A. Marginean, S. Sengupta, and E. Wang, “Automated
     unit test improvement using large language models at meta,” in
     Companion Proceedings of the 32nd ACM International Conference on
     the Foundations of Software Engineering, ser. FSE 2024. New York,
     NY, USA: Association for Computing Machinery, 2024, p. 185–196.
     [Online]. Available: https://doi.org/10.1145/3663529.3663839
 [5] N. Mündler, M. N. Müller, J. He, and M. Vechev, “Swt-bench: testing and
     validating real-world bug-fixes with code agents,” in Proceedings of the
     38th International Conference on Neural Information Processing Systems,
     ser. NIPS ’24. Red Hook, NY, USA: Curran Associates Inc., 2024.
     [Online]. Available: https://dl.acm.org/doi/10.5555/3737916.3740517
 [6] M. S. Melara and C. Kimes, “Auditing the ci/cd platform: Reproducible
     builds vs. hardware-attested build environments, which is right for
     you?” in Proceedings of the 2024 Workshop on Software Supply Chain
     Offensive Research and Ecosystem Defenses, ser. SCORED ’24. New
     York, NY, USA: Association for Computing Machinery, 2024, p. 43–44.
     [Online]. Available: https://doi.org/10.1145/3689944.3696351
 [7] A. V. Kruglov, G. Succi, and X. Z. Vasquez, “Incorporating energy
     efficiency measurement into CI\CD pipeline,” in ESSE 2021: 2nd
     European Symposium on Software Engineering, Larissa, Greece,
     November 19 - 21, 2021. ACM, 2021, pp. 14–20. [Online]. Available:
     https://doi.org/10.1145/3501774.3501777
 [8] Drone CI. (2025) Официальная документация. [Электронный ресурс].
     Дата обращения: 22.02.2025. [Online]. Available: https://docs.drone.io/
 [9] k6. Официальная документация. [Электронный ресурс]. Дата
     обращения: 26.10.2025. [Online]. Available: https://k6.io/docs/
[10] A. A. Petrov and V. A. Parkhomenko. (2025, Aug.)
     sw3zeg/loadtestingmetricsplugin: v1.0. [Online]. Available: https:
     //doi.org/10.5281/zenodo.16732330
[11] v. d. H. Nicole. (2021) Comparing k6 and jmeter for load testing. [Элек-
     тронный ресурс]. Дата обращения: 22.02.2025. [Online]. Available:
     https://grafana.com/blog/2021/01/27/k6-vs-jmeter-comparison/
[12] V. Manolov, D. Gotseva, and N. Hinov, “Practical comparison between the
     CI/CD platforms azure devops and github,” Future Internet, vol. 17, no. 4,
     p. 153, 2025. [Online]. Available: https://doi.org/10.3390/fi17040153

[13] S. Saleh, N. Madhavji, and J. Steinbacher, “A systematic literature
     review on continuous integration and deployment (ci/cd) for secure cloud
     computing,” in Proceedings of the 20th International Conference on
     Web Information Systems and Technologies. SCITEPRESS - Science
     and Technology Publications, 2024, p. 331–341. [Online]. Available:
     http://dx.doi.org/10.5220/0013018500003825

[14] J. Waller, N. C. Ehmke, and W. Hasselbring, “Including performance
     benchmarks into continuous integration to enable devops,” ACM
     SIGSOFT Software Engineering Notes, vol. 40, no. 2, pp. 1–4, 2015.
     [Online]. Available: https://dl.acm.org/doi/10.1145/2735399.2735416
[15] C. Singh, N. S. Gaba, M. Kaur, and B. Kaur, “Comparison of
     different ci/cd tools integrated with cloud platform,” in 2019 9th
     International Conference on Cloud Computing, Data Science &
     Engineering (Confluence). IEEE, 2019, pp. 154–159. [Online].
     Available: https://ieeexplore.ieee.org/document/8776985

[16] J. Fairbanks, A. Tharigonda, and N. U. Eisty, “Analyzing the effects
     of CI/CD on open source repositories in github and gitlab,” in
     21st IEEE/ACIS International Conference on Software Engineering
     Research, Management and Applications, SERA 2023, Orlando, FL,
     USA, May 23-25, 2023. IEEE, 2023, pp. 176–181. [Online]. Available:
     https://doi.org/10.1109/SERA57763.2023.10197778
[17] B. Erdenebat, B. Bud, T. Batsuren, and T. Kozsik, “Multi-project
     multi-environment approach - an enhancement to existing devops
     and continuous integration and continuous deployment tools,”
     Comput., vol. 12, no. 12, p. 254, 2023. [Online]. Available:
     https://doi.org/10.3390/computers12120254
[18] L. Liao, “Addressing performance regressions in devops: Can we escape
     from system performance testing?” in 2023 IEEE/ACM 45th International
     Conference on Software Engineering: Companion Proceedings (ICSE-
     Companion), 2023, pp. 203–207.

[19] L. Liao, S. Eismann, H. Li, C.-P. Bezemer, D. E. Costa, A. van Hoorn,
     and W. Shang, “Early detection of performance regressions by bridging
     local performance data and architectural models,” in 2025 IEEE/ACM
     47th International Conference on Software Engineering (ICSE), 2025,
     pp. 2841–2853.

[20] H. M. AlGhamdi, C.-P. Bezemer, W. Shang, A. E. Hassan,
     and P. Flora, “Towards reducing the time needed for load
     testing,” Journal of Software: Evolution and Process, vol. 35,
     no. 3, p. e2276, 2023, e2276 smr.2276. [Online]. Available:
     https://onlinelibrary.wiley.com/doi/abs/10.1002/smr.2276

[21] D. Daly, W. Brown, H. Ingo, J. O’Leary, and D. Bradford, “The use of
     change point detection to identify software performance regressions in
     a continuous integration system,” in Proceedings of the ACM/SPEC
     International Conference on Performance Engineering, ser. ICPE ’20.
     New York, NY, USA: Association for Computing Machinery, 2020, p.
     67–75. [Online]. Available: https://doi.org/10.1145/3358960.3375791
[22] A. Kruglov, G. Succi, and X. Vasuez, “Incorporating energy efficiency
     measurement into ci/cd pipeline,” in Proceedings of the 2021 European
     Symposium on Software Engineering, ser. ESSE ’21. New York, NY,
     USA: Association for Computing Machinery, 2022, p. 14–20. [Online].
     Available: https://doi.org/10.1145/3501774.3501777
[23] S. Weber, T. Weber, and J. Henß, “Integration of performability-
     model extraction and performability prediction in continuous
     integration / continuous delivery,” Softwaretechnik-Trends,
     vol. 45, no. 1, pp. 29–31, 2025. [Online]. Available:
     https://fb-swt.gi.de/fileadmin/FB/SWT/Softwaretechnik-Trends/
     Verzeichnis/Band_45_Heft_1/SSP24_26_camera-ready_8969.pdf
[24] M. Mazkatli, D. Monschein, M. Armbruster, R. Heinrich, and
     A. Koziolek, “Continuous integration of architectural performance
     models with parametric dependencies – the cipm approach,” Automated
     Software Engg., vol. 32, no. 2, May 2025. [Online]. Available:
     https://doi.org/10.1007/s10515-025-00521-9
[25] R. Gao and Z. M. J. Jiang, “An exploratory study on assessing the impact
     of environment variations on the results of load tests,” in Proceedings
     of the 14th International Conference on Mining Software Repositories,
     ser. MSR ’17. IEEE Press, 2017, p. 379–390. [Online]. Available:
     https://doi.org/10.1109/MSR.2017.22
[26] S. Zheng, B. Adams, and A. E. Hassan, “Does using bazel help speed up
     continuous integration builds?” Empir. Softw. Eng., vol. 29, no. 5, p. 110,
     2024. [Online]. Available: https://doi.org/10.1007/s10664-024-10497-x
[27] A.     A.     Petrov     and      V.    A.     Parkhomenko.      (2025)
     swezeg/loadtestingmetricsplugin in docker hub container image
     library. [Online]. Available: https://hub.docker.com/repository/docker/
     swezeg/loadtestingmetricsplugin/general
[28] Gitea Community. Официальная документация. [Электронный
     ресурс]. Дата обращения: 27.10.2025. [Online]. Available: https:
     //docs.gitea.com/

Петров Андрей Александрович — Студент 4 курса бакалавриата Санкт-Петербугского
политехнического университета Петра Великого по направлению Прикладная информатика.
petrov3.aa@edu.spbstu.ru; https://orcid.org/0009-0005-5917-6259; СПбПУ, Политехническая
ул., д. 29, г. Санкт-Петербург, 195251, РФ.
Пархоменко Владимир Андреевич — ст. преподаватель Высшей школы программной
инженерии Института компьютерных наук и кибербезопасности Санкт-Петербугского
политехнического университета Петра Великого. Область научных интересов: теория ре-
шёток, тестирование программного обеспечения, принятие решений, машинное обучение.
Vladimir.Parkhomenko@spbstu.ru; https://orcid.org/0000-0001-7757-377X; СПбПУ, Политех-
ническая ул., д. 29, г. Санкт-Петербург, 195251, РФ.
            A.A. PETROV , V.A. PARKHOMENKO
COMPARISON OF OPEN-SOURCE CI/CD PLATFORMS BY LOAD
               TESTING EFFICIENCY

Petrov A.A., Parkhomenko V.A. Comparison of Open-Source CI/CD Platforms by Load Testing
Efficiency.
     Abstract. This paper examines open-source CI/CD platforms. Jenkins, GitLab CI, and Drone
were selected for comparison. The study focused on evaluating their capabilities in performing
load testing, collecting performance metrics, and generating reports with subsequent delivery
via Telegram, Email, and file systems. Unlike traditional systems, Drone offers a minimalist and
flexible pipeline configuration approach based on container architecture. However, to enable a
full comparison, a custom plugin had to be developed. Functional and mutation testing, along
with profiling, confirmed the correctness and efficiency of the new plugin based on k6. The paper
presents a new technology for finding the optimal combination of RAM resource usage and high
performance based on the choice of waiting interval between parallel applications in Drone (using
the example of waiting between k6 report readiness checks). A comparison with Jenkins and
GitLab CI-based alternatives demonstrates the competitiveness of the proposed solution: the
average pipeline execution time is 29 seconds (versus 31 for Jenkins and 36 for GitLab), and the
average RAM consumption is 526 MB (versus 990 for Jenkins and 588 for GitLab).
     Keywords: CI/CD, opensource, drone, plugin, load testing, k6, Jenkins, Gitlab CI.


Petrov, Andrey Alexandrovich — 4th-year Bachelor’s student at Peter the Great St.Petersburg
Polytechnic University, specializing in Applied Informatics. petrov3.aa@edu.spbstu.ru; https:
//orcid.org/0009-0005-5917-6259; SPBPU, 29, Polytechnicheskaya str., St. Petersburg, 195251,
Russia.
Parkhomenko Vladimir Andreevich — Senior Lecturer at the Higher School of Software
Engineering, Institute of Computer Science and Cybersecurity, Peter the Great St.Petersburg
Polytechnic University. Research interests: lattice theory, software testing, decision making,
machine learning. Vladimir.Parkhomenko@spbstu.ru; https://orcid.org/0000-0001-7757-377X;
SPBPU, 29, Polytechnicheskaya str., St. Petersburg, 195251, Russia.
         Список литературы.
 [1] CNCF. Graduated and incubating projects. [Электронный ресурс]. Дата обращения:
     26.10.2025. [Online]. Available: https://www.cncf.io/projects/
 [2] P. Rostami Mazrae, T. Mens, M. Golzadeh, and A. Decan, “On the usage, co-usage and
     migration of ci/cd tools: A qualitative analysis,” Empirical Softw. Engg., vol. 28, no. 2, Mar.
     2023. [Online]. Available: https://doi.org/10.1007/s10664-022-10285-5
 [3] Y. Bugayenko, K. Daniakin, M. Farina, F. Jolha et al., “Extracting corrective
     actions from code repositories,” in Proceedings of the 19th International Conference
     on Mining Software Repositories (MSR 2022). ACM, 2022. [Online]. Available:
     https://dl.acm.org/doi/abs/10.1145/3524842.3528517
 [4] N. Alshahwan, J. Chheda, A. Finogenova, B. Gokkaya, M. Harman, I. Harper,
     A. Marginean, S. Sengupta, and E. Wang, “Automated unit test improvement using large
     language models at meta,” in Companion Proceedings of the 32nd ACM International
     Conference on the Foundations of Software Engineering, ser. FSE 2024. New York,
     NY, USA: Association for Computing Machinery, 2024, p. 185–196. [Online]. Available:
     https://doi.org/10.1145/3663529.3663839
 [5] N. Mündler, M. N. Müller, J. He, and M. Vechev, “Swt-bench: testing and validating
     real-world bug-fixes with code agents,” in Proceedings of the 38th International Conference
     on Neural Information Processing Systems, ser. NIPS ’24. Red Hook, NY, USA: Curran
     Associates Inc., 2024. [Online]. Available: https://dl.acm.org/doi/10.5555/3737916.3740517
 [6] M. S. Melara and C. Kimes, “Auditing the ci/cd platform: Reproducible builds vs.
     hardware-attested build environments, which is right for you?” in Proceedings of the 2024
     Workshop on Software Supply Chain Offensive Research and Ecosystem Defenses, ser.
     SCORED ’24. New York, NY, USA: Association for Computing Machinery, 2024, p.
     43–44. [Online]. Available: https://doi.org/10.1145/3689944.3696351
 [7] A. V. Kruglov, G. Succi, and X. Z. Vasquez, “Incorporating energy efficiency measurement
     into CI\CD pipeline,” in ESSE 2021: 2nd European Symposium on Software Engineering,
     Larissa, Greece, November 19 - 21, 2021. ACM, 2021, pp. 14–20. [Online]. Available:
     https://doi.org/10.1145/3501774.3501777
 [8] Drone CI. (2025) Официальная документация. [Электронный ресурс]. Дата обращения:
     22.02.2025. [Online]. Available: https://docs.drone.io/
 [9] k6. Официальная документация. [Электронный ресурс]. Дата обращения: 26.10.2025.
     [Online]. Available: https://k6.io/docs/
[10] A. A. Petrov and V. A. Parkhomenko. (2025, Aug.) sw3zeg/loadtestingmetricsplugin: v1.0.
     [Online]. Available: https://doi.org/10.5281/zenodo.16732330
[11] v. d. H. Nicole. (2021) Comparing k6 and jmeter for load testing. [Электронный ресурс].
     Дата обращения: 22.02.2025. [Online]. Available: https://grafana.com/blog/2021/01/27/
     k6-vs-jmeter-comparison/
[12] V. Manolov, D. Gotseva, and N. Hinov, “Practical comparison between the CI/CD platforms
     azure devops and github,” Future Internet, vol. 17, no. 4, p. 153, 2025. [Online]. Available:
     https://doi.org/10.3390/fi17040153
[13] S. Saleh, N. Madhavji, and J. Steinbacher, “A systematic literature review on continuous
     integration and deployment (ci/cd) for secure cloud computing,” in Proceedings of
     the 20th International Conference on Web Information Systems and Technologies.
     SCITEPRESS - Science and Technology Publications, 2024, p. 331–341. [Online].
     Available: http://dx.doi.org/10.5220/0013018500003825
[14] J. Waller, N. C. Ehmke, and W. Hasselbring, “Including performance benchmarks into
     continuous integration to enable devops,” ACM SIGSOFT Software Engineering Notes, vol. 40,
     no. 2, pp. 1–4, 2015. [Online]. Available: https://dl.acm.org/doi/10.1145/2735399.2735416
[15] C. Singh, N. S. Gaba, M. Kaur, and B. Kaur, “Comparison of different ci/cd tools integrated
     with cloud platform,” in 2019 9th International Conference on Cloud Computing, Data
     Science & Engineering (Confluence). IEEE, 2019, pp. 154–159. [Online]. Available:
     https://ieeexplore.ieee.org/document/8776985
[16] J. Fairbanks, A. Tharigonda, and N. U. Eisty, “Analyzing the effects of CI/CD
     on open source repositories in github and gitlab,” in 21st IEEE/ACIS International
     Conference on Software Engineering Research, Management and Applications, SERA 2023,
     Orlando, FL, USA, May 23-25, 2023. IEEE, 2023, pp. 176–181. [Online]. Available:
     https://doi.org/10.1109/SERA57763.2023.10197778
[17] B. Erdenebat, B. Bud, T. Batsuren, and T. Kozsik, “Multi-project multi-environment
     approach - an enhancement to existing devops and continuous integration and continuous
     deployment tools,” Comput., vol. 12, no. 12, p. 254, 2023. [Online]. Available:
     https://doi.org/10.3390/computers12120254
[18] L. Liao, “Addressing performance regressions in devops: Can we escape from system
     performance testing?” in 2023 IEEE/ACM 45th International Conference on Software
     Engineering: Companion Proceedings (ICSE-Companion), 2023, pp. 203–207.
[19] L. Liao, S. Eismann, H. Li, C.-P. Bezemer, D. E. Costa, A. van Hoorn, and W. Shang, “Early
     detection of performance regressions by bridging local performance data and architectural
     models,” in 2025 IEEE/ACM 47th International Conference on Software Engineering (ICSE),
     2025, pp. 2841–2853.
[20] H. M. AlGhamdi, C.-P. Bezemer, W. Shang, A. E. Hassan, and P. Flora, “Towards
     reducing the time needed for load testing,” Journal of Software: Evolution and
     Process, vol. 35, no. 3, p. e2276, 2023, e2276 smr.2276. [Online]. Available:
     https://onlinelibrary.wiley.com/doi/abs/10.1002/smr.2276
[21] D. Daly, W. Brown, H. Ingo, J. O’Leary, and D. Bradford, “The use of change point
     detection to identify software performance regressions in a continuous integration system,”
     in Proceedings of the ACM/SPEC International Conference on Performance Engineering,
     ser. ICPE ’20. New York, NY, USA: Association for Computing Machinery, 2020, p.
     67–75. [Online]. Available: https://doi.org/10.1145/3358960.3375791
[22] A. Kruglov, G. Succi, and X. Vasuez, “Incorporating energy efficiency measurement into
     ci/cd pipeline,” in Proceedings of the 2021 European Symposium on Software Engineering,
     ser. ESSE ’21. New York, NY, USA: Association for Computing Machinery, 2022, p.
     14–20. [Online]. Available: https://doi.org/10.1145/3501774.3501777
[23] S. Weber, T. Weber, and J. Henß, “Integration of performability-model
     extraction and performability prediction in continuous integration / continuous
     delivery,” Softwaretechnik-Trends, vol. 45, no. 1, pp. 29–31, 2025. [Online].
     Available: https://fb-swt.gi.de/fileadmin/FB/SWT/Softwaretechnik-Trends/Verzeichnis/
     Band_45_Heft_1/SSP24_26_camera-ready_8969.pdf
[24] M. Mazkatli, D. Monschein, M. Armbruster, R. Heinrich, and A. Koziolek, “Continuous
     integration of architectural performance models with parametric dependencies – the cipm
     approach,” Automated Software Engg., vol. 32, no. 2, May 2025. [Online]. Available:
     https://doi.org/10.1007/s10515-025-00521-9
[25] R. Gao and Z. M. J. Jiang, “An exploratory study on assessing the impact of environment
     variations on the results of load tests,” in Proceedings of the 14th International Conference
     on Mining Software Repositories, ser. MSR ’17. IEEE Press, 2017, p. 379–390. [Online].
     Available: https://doi.org/10.1109/MSR.2017.22
[26] S. Zheng, B. Adams, and A. E. Hassan, “Does using bazel help speed up continuous
     integration builds?” Empir. Softw. Eng., vol. 29, no. 5, p. 110, 2024. [Online]. Available:
     https://doi.org/10.1007/s10664-024-10497-x
[27] A. A. Petrov and V. A. Parkhomenko. (2025) swezeg/loadtestingmetricsplugin in docker
     hub container image library. [Online]. Available: https://hub.docker.com/repository/docker/
     swezeg/loadtestingmetricsplugin/general
[28] Gitea Community. Официальная документация. [Электронный ресурс]. Дата
     обращения: 27.10.2025. [Online]. Available: https://docs.gitea.com/
