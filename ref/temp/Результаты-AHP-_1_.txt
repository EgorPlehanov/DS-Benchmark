Пархоменко Владимир (ORCID): https://orcid.org/0000-0001-7757-377X
Литвак Александра (ORCID): https://orcid.org/0009-0002-0392-0075
Курдиков Артём (ORCID): https://orcid.org/0009-0007-8226-0234
Общий репозиторий: https://github.com/DM-groups/GroupDM-Bias-AHP-Analysis
Репозиторий Артёма: https://github.com/KTemka1234/Biased-GDM + коллаб: Biased-GDM.ipynb
Репозиторий Александры:  https://github.com/Alexksksss/clustering-bias-article

Исследование предвзятости подгрупп экспертов с использованием аналитического алгоритма и кластеризации 
Кластеризация при выявлении предвзятости подгрупп экспертов 
Введение (А/С)
Abstract

В данной статье проводится исследование определения предвзятости групп экспертов с использованием аналитического алгоритма и методов кластеризации. В качестве алгоритма определения предвзятости используется аналитический алгоритм, предложенный в статье Rabiee at al 2021, который в ходе исследования был модифицирован для устранения выявленной уязвимости исходного алгоритма. Для кластеризации экспертов используется методы fanny, ward, k-means, gmm, spectral, birch, dbscan и mean-shift, которые способны выявлять гетерогенные группы экспертов с системными отклонениями через анализ центроид кластеров.

Introduction

В групповом принятии решений системная предвзятость экспертов проявляется в недостаточной степени различимости (дискриминантности) между оценками альтернатив по всем критериям [2]. С одной стороны, активно развиваются аналитические решения по выявлению подгрупп предвзятых экспертов. Так, алгоритм глобальной предвзятости, предложенный Rabiee et al 2021 позволяет эффективно распознавать системную предвзятость экспертов. Однако мы выделяем также локальную предвзятость, когда эксперт значительно завышает или занижает оценку альтернативы относительно усредненной групповой оценки. Как показало наше исследование, Name не может справится с данной проблемой.

С другой стороны, известен подход к выделению подгрупп экспертов на основе машинного обучения. [1,,,] и другие работы предлагают иной, не аналитический подход к поиску подгрупп экспертов, связанных единым мнением.

Целью данного исследования является оценка способности ряда методов кластеризации воспроизвести и приблизиться к специализированным алгоритмам выявления предвзятости в векторов приоритетов экспертов. Для достижения данной цели поставлены следующие задачи:
? Спроектировать и реализовать алгоритмы нахождения глобальной и локальной предвзятости.
? Исследовать алгоритмы кластеризации в рамках выделения подгрупп предвзятых экспертов.
? Сравнить зависимости между предложенными алгоритмами и алгоритмами кластеризации на основе синтетических и реальных данных

Основной гипотезой исследования является идея, что классические алгоритмы кластеризации, например, fanny, ward, k-means, gmm, spectral, birch, dbscan и mean-shift, способны выявить гетерогенные группы экспертов с системными отклонениями через анализ центроид кластеров более точно по F1 мере, чем алгоритм нечеткой кластеризации FANNY [1].

Дальнейшая часть статьи выстроена следующим образом. В первой рубрике .... 

1. Related works (??? 15-20 источников)


Поиск источников осуществлялся DBLP следующим образом. Сначала отбирались ключевые слова, по которым обнаружилось следующее количество работ по состоянию на  ДД.ММ.ГГГГ:
1. expert bias - 
2. 
Обсудим их подробнее в различных подрубриках.

??? какие входные данные использовались (МПС объектов, объектно-признаковые таблицы и пр.)

1.1. Поиск по ключ. словам expert bias. // МОЖНО РАЗБИТЬ ПО ВИДУ ВХОДНЫХ ДАННЫХ, В КОТОРЫХ ПРЕДВЗЯТОСТЬ 
1.1. Исследование предвзятости в матрицах парных сравнений

Т.е. те работы, где, в которых не найти данные для сравнения можно упомянуть, но отбросить. Что отбросить, а что изучить особенно можно понять по количеству цитирований в GOOGLE SCHOLAR. Нужно явно указывать все размышления, количества цитат на определенную дату.


? В статье Dealing with Expert Bias in Collective Decision-Making [11] для выявления предвзятых экспертов предлагается подход Meta_CMAB на базе контекстных мультируких бандитов для агрегации советов предвзятых экспертов, превосходящий лучшие одиночные эксперты за счеты линейной комбинации их мнений. Авторы исследуют гомогенные, гетерогенные и поляризованные группы экспертов, показывая устойчивость подхода к предвзятости и быструю сходимость.
? В статье "Towards secure judgments aggregation in AHP" [12]  основная идея состоит в эвристиках: отклонении мнений от среднего и низкую согласованность МПС. Предлагаются методы APDD (на расстояниях рангов), AID (на индексах несогласованности) и комбинация двух предыдущих - MX для снижения весов экспертов с минимальным искажение честных рангов.
1. Аналитический подход к диагностике предвзятости экспертов
В ходе исследования за основу алгоритма обнаружения и обработки предвзятых экспертов подход, изложенный в статье Rabiee et al. (2021) [2]. Авторы исследуют многозначную объектно-признаковую таблицу с описанием альтернатив в качестве входных данных. Они предлагают оригинальный статистический подход, предназначенный для повышения достоверности и обоснованности групповых решений путем идентификации и нивелирования влияния предвзятых участников.
Ключевая идея алгоритма заключается в том, что предвзятость эксперта определяется через недостаточную дискриминационную способность в его суждениях. Это проявляется в том, что эксперт ставит схожие оценки всем альтернативам по всем критериям (далее - глобальная предвзятость), что приводит к аномально узкому или смещенному доверительному интервалу его оценок, который не пересекается с интервалами остальных членов группы.
1.1. Алгоритмы анализа глобальной предвзятости
Алгоритм анализа глобальной предвзятости Rabiee et al. (2021) [2] работает в два основных этапа:
1. Фаза исключения выбросов (Outlier Elimination Phase).
2. Фаза назначения весов (Weight Assignment Phase).

На первой фазе оценки всех экспертов по альтернативам и критериям нормализуются и объединяются в интегрированную матрицу решений. Для каждого эксперта на основе его нормализованных оценок вычисляется доверительный интервал (Confidence Interval, CI). Затем для каждого эксперта рассчитывается индекс предвзятости (Biasedness Index, B?), который представляет собой количество других экспертов, чьи доверительные интервалы пересекаются с его интервалом. Эксперты, чей индекс предвзятости B? оказывается ниже заданного порогового значения B, считаются полностью предвзятыми и исключаются из пула принимающих решение. См. иллюстрацию на Рис. 1???

Во второй фазе для оставшихся, считающихся непредвзятыми, экспертов проводится более тонкая настройка их влияния - вычисляется коэффициент перекрытия (Overlap Ratio, O?) каждого эксперта - относительная мера пересечения его CI с CI всех остальных экспертов. Чем больше перекрытие, тем больше согласие эксперта с группой. Одновременно рассчитывается относительный доверительный интервал (Relative CI, CI??) - отношение ширины CI эксперта к ширине общего CI всей группы, что отражает его дискриминационную способность. Итоговый вес w? для каждого эксперта вычисляется, как нормированное произведение его коэффициента перекрытия и относительного доверительного интервала. Таким образом, больший вес получают эксперты, чьи мнения более согласованы с коллективными и/или кто демонстрирует адекватную дифференциацию в оценках.

Для адаптации к различным организационным контекстам авторы предлагают три версии алгоритма:
1. Экстремальная версия (EABM - Extreme Anti-Biased Method): полное исключение предвзятых экспертов на первом этапе.
2. Умеренная версия (MABM - Moderate Anti-Biased Method): после исключения предвзятых экспертов оставшимся гарантируется минимальный предустановленный вес, а оставшаяся часть весов распределяется по описанной схеме.
3. Мягкая версия (SABM - Soft Anti-Biased Method): Исключение не применяется; всем экспертам изначально присваивается минимальный вес, а дополнительные веса распределяются на основе их согласованности с группой. Эта версия подходит для ситуаций, когда исключение участников неприемлемо (например, совет директоров).
1.2. Модификация алгоритма анализа предвзятости
Исходный алгоритм определяет только глобальную предвзятость (недостаточную дискриминантность оценок эксперта) и не может определить локальную предвзятость, под которой мы понимаем ситуацию, когда эксперт систематически завышает или занижает оценки конкретным альтернативам. 
Example 1. В качестве простейшего примера рассмотрим случай, когда эксперт ставит минимальные оценки для альтернативы 1 по всем критериям и максимальные для альтернативы 2 по всем критериям. Данное распределение оценок экспертом можно назвать предвзятым, однако исходный алгоритм не будет считать данного эксперта предвзятым, поскольку его доверительный интервал будет перекрывать доверительные интервалы всех остальных экспертов. СВЯЗАТЬ С ПОДРОБНЫМ ОПИСАНИЕМ ЕГО ЖЕ В ЭКСПЕРИМЕНТАХ
Ниже приведен пример доверительного интервала предвзятого эксперта, который не будет определен исходным алгоритмом:

На рисунке выше видно, что эксперт Egor (DM4) фактически является предвзятым, однако его доверительный интервал пересекается с интервалами других непредвзятых экспертов, поэтому алгоритм определения глобальной предвзятости не работает в данной ситуации.
Example 2. Также алгоритм Rabiee et al. не будет работать, например, в случае задания экспертом одного максимального значения по одному из критериев (как говорят, для отвода глаз) и минимальных значений по всем остальным значениям критериев.

Предлагаемая модификация исходного алгоритма призвана решить данную проблему. Алгоритм поиска локальной предвзятости (далее - АПЛП) функционирует следующим образом:
1. Вычисляется консенсусная матрица оценок путем агрегирования мнений всех экспертов (например, через усреднение их нормализованных оценок по каждому критерию для каждой альтернативы).
2. Для каждого эксперта анализируются отклонения его индивидуальных оценок от полученного консенсуса. Ключевым отличием предлагаемого метода является проведение этого анализа не в совокупности по всем оценкам, а раздельно для каждой альтернативы.
3. Для каждой пары "эксперт-альтернатива" рассчитывается усредненное отклонение по всем критериям оценивания, что позволяет количественно определить степень и направление предвзятости - положительные значения свидетельствуют о завышении оценок, отрицательные указывают на тенденцию к занижению.
4. Индекс локальной предвзятости эксперта определяется как максимальное по модулю значение среди всех рассчитанных для него усредненных отклонений, что отражает наиболее выраженную пристрастность в отношении конкретной альтернативы.
Ниже приведен пример визуализации локальной предвзятости экспертов для контрпримера, описанного выше:

Из рисунка выше видно, что за счет разработанного алгоритма определения локальной предвзятости, в приведенном примере 1 успешно определяется предвзятый эксперт. Левый график демонстрирует отклонение оценок экспертов по заданной альтернативе и критерию относительно консенсусной оценки (среднего значения нормализованной оценки экспертов по заданной альтернативе и критерию). Правый график отображает индекс локальной предвзятости экспертов и пороговое значение локальной предвзятости.
Пример 2 ???
Далее рассмотрим инструменты машинного обучения для поиска подгрупп предвзятых экспертов.
2. Кластеризация (С)

Для нахождения подгрупп предвзятых экспертов можно также использовать алгоритмы кластеризации. Обзор по выделению подгрупп (предвзятых) людей??? (по аналогии)

Гетерогенность мнений экспертов является ключевой проблемой в различных прикладных примерах применений, например в методе анализа иерархий [1]. Авторы данной статьи выбрали двухфазный алгоритм достижения консенсуса (ДАДК). Алгоритм определяет системную предвзятость через оптимальное разбиение экспертов на кластеры и строит итеративный консенсус с весами уважения. На вход алгоритма подается вектор приоритетов критериев для каждого эксперта.

Далее опишем подробнее подход к выделению предвзятых экспертов из [1] и потом перейдем к экспериментам с алгоритмами кластеризации.
2.1. ДАДК
ДАДК включает в себя следующие два этапа: сначала кластеризацию векторов приоритетов экспертов, затем вычисление внутрикластерного и глобального консенсусов.
На первом этапе векторы приоритетов экспертов кластеризуются fuzzy алгоритмом FANNY (Fuzzy Analysis Clustering). Он распределяет  экспертов по кластерам, позволяя мягкую принадлежность (эксперт может частично относиться к нескольким группам одновременно). На выходе получаются подгруппы гомогенных экспертов с похожими мнениями и центры этих кластеров. Далее в каждом шаге вычисляется матрица уважения (matrix of respects) между экспертами (чем ближе их оценки к конкретной альтернативе, тем выше вес). Эти веса используются для итеративного усреднения мнений внутри кластера до достижения консенсуса. На выходе фазы получен консенсус внутри каждого кластера.
На втором этапе каждый кластер, полученный на предыдущем шаге представляется одним "суперэкспертом" с консенсусными весами. Между этими получившимися суперэкспертами вычисляются веса уважения и итеративно строится финальный групповой вектор приоритетов, учитывающий структуру гетерогенности группы.
Выделение количества кластеров в исходном алгоритме происходит с использованием FANNY алгоритма, путем оценки стабильности кластеров.
Основная идея заключается в отсутствии зашумленности популярного мнения и возможности учета мнения меньшинств. 
{Вход:} $P_k = [p_{k1}, p_{k2}, \dots, p_{kn}]^T$, $k=1,\dots,K$ --- векторы приоритетов $K$ экспертов в $n$-мерном пространстве.

\textbf{Целевая функция FANNY:}
\begin{equation}
\min F(X) = \sum_{i=1}^N \sum_{m=1}^c u_{im}^2 u_{jm}^2 d_{ij} + \sum_{j=1}^N \frac{u_{jm}^2}{\sum_{i=1}^N u_{im}^2}
\end{equation}

где:
\begin{itemize}
    \item $u_{im}$ --- степень принадлежности эксперта $i$ к кластеру $m$ ($0 \leq u_{im} \leq 1$, $\sum_m u_{im} = 1$)
    \item $d_{ij}$ --- евклидово расстояние: $d_{ij} = \sqrt{\sum_{l=1}^n (p_{il} - p_{jl})^2}$
    \item $c$ --- оптимальное число кластеров
\end{itemize}

\textbf{Выход:} $m$ кластеров с центрами $CP_{sg}$ и матрицами членств $U_{sg}$.

 
2.2. Модификация метода ДАДК
Для проверки основной гипотезы исследования в качестве алгоритмов кластеризации выделим fanny, использовавшийся в статье, ward, k-means, gmm, spectral, birch, dbscan и mean-shift, которые способны выявлять гетерогенные группы экспертов с системными отклонениями через анализ центроид кластеров. Сначала опишем модификацию подхода.

Для сопоставимости с аналитическим решением, описанным ранее, ДАДК модифицирован для работы с исходными матрицами объектов-признаков по экспертов вместо векторов приоритетов, расширен множеством методов кластеризации с автоматическим подбором числа кластеров. Рассмотрим эти изменения подробнее.
В отличие от оригинального алгоритма, требующего на входе nD-векторов приоритетов, полученных из матриц попарных сравнений, модифицированная версия принимает исходные AHP-матрицы. Добавлен предварительный этап нормализации.

Для методов кластеризации, требующих задания гиперпараметра k (количества кластеров) (KMeans, Ward, GMM, Spectral), реализован алгоритм локального перегиба второй производной инерции (second-order elbow method):
1.1 Обучаются модели KMeans для k итеративным перебором
1.2 Вычисляется инерция I(k) и ее первые/вторые разности
1.3 Находится оптимальное k* с коррекцией на соседний локальный максимум
1. Фаза 1 дополнена семью алгоритмами кластеризации из scikit-learn [4]:
? Ward относится к иерархической агломеративной кластеризации и на каждом шаге объединяет такие кластеры, при слиянии которых, минимально растёт суммарная внутрикластерная дисперсия. За счёт этого кластеры получаются компактными и близкими по размеру, что хорошо подходит для группировки экспертов по похожим приоритетным векторам.
? k-means минимизирует сумму квадратов расстояний точек до центров кластеров, поочередно пересчитывая центры и переназначая точки к ближайшему центру. Метод чувствителен к начальному положению центров, поэтому используется многократная инициализация и стандартизация признаков.
? GMM моделирует данные смесью многомерных нормальных распределений и возвращает вероятности принадлежности эксперта к каждому кластеру. В прототипе для консенсуса используется жёсткое присвоение по максимальной вероятности.
? Spectral Clustering строит граф сходства между экспертами, вычисляет спектр матрицы Лапласа и выполняет k-means в спектральном пространстве. Такой подход позволяет выявлять кластеры сложной формы, которые неразделимы гиперплоскостями.
? Birch строит иерархическое дерево кластеров и позволяет обрабатывать данные, последовательно уплотняя их в под кластеры.
? DBSCAN - плотностной алгоритм, который выделяет области повышенной плотности и помечает разреженные точки как шум. Он не требует задавать число кластеров заранее, но чувствителен к выбору параметров eps и min_samples.
? Mean Shift - плотностный алгоритм, который ищет моды (локальные максимумы) плотности данных путем итеративного сдвига точек к ближайшим областям повышенной плотности. Не требует задания числа кластеров заранее и автоматически определяет структуру данных через ширину окна поиска (bandwidth). Чувствителен к выбору bandwidth, но устойчив к шуму и эффективен для выявления мод.
Эти алгоритмы представляют все основные семейства методов: иерархическую (Ward, Birch), партиционную (k-means, fanny), вероятностную (GMM), спектральную (Spectral Clustering) и плотностную (DBSCAN, Mean Shift) кластеризацию.
Такой выбор обеспечивает широкое методологическое покрытие фундаментальных подходов к группировке многомерных приоритетных векторов экспертов.[1]
В работе [1] используется алгоритм FANNY (Fuzzy Analysis Clustering) из пакета R для нечеткой кластеризации векторов приоритетов в $n$-мерном пространстве. В настоящей реализации применен функционально эквивалентный алгоритм нечетких $c$-средних (skfuzzy.cmeans) с параметром нечеткости $m=2.0$, обеспечивающий идентичную матрицу мягких членств $U\in^{K\times m}$ и центры кластеров для последующего построения консенсуса ДАДК.
3. Экспериментальное исследование предвзятости
Методы исследования предвзятости описаны нами в предыдущих разделах. Для проведения детального исследования обозначим следующие исходные данные:
- синтетические наборы данных, сгруппированные по количеству экспертов:
- 10 экспертов (далее synth_10);
- 50 экспертов (далее synth_50);
- 100 экспертов (далее synth_100).
- данные из реальной задачи группового принятия решений;
- данные из статьи [2];
- контрпримеры для статьи [2].

Ниже представлена таблица, которая содержит описание используемых датасетов и используемых параметров для их анализа. Общие параметры для анализа датасетов:
- alpha = 0.95 (уровень значимости)
- B = 2 (порог глобальной предвзятости)
- gamma = 0.5 (коэффициент предопределенного веса)


ДатасетЭкспертыАльтернативыКритерииПорог локальной предвзятостиИз статьи5630.3Контрпример 14330.25Контрпример 20.1Реальная задача6780.25Synth_10_11015110.1Synth_10_2146Synth_10_3196Synth_10_4164Synth_10_5139Synth_50_1507110.08Synth_50_2540.2Synth_50_310160.1Synth_50_41160.1Synth_50_51060.12Synth_100_11008140.1Synth_100_27170.1Synth_100_37140.13Synth_100_41830.15Synth_100_518100.1

План экспериментов следующий: сначала .... Выявлять будет то-то...
Перейдем к описанию разработанного экспериментального стенда.
3.1. Архитектура экспериментального стенда
На рисунке (РИСУНОК №) представлена архитектура экспериментального стенда для сравнительного анализа кластеризационных алгоритмов в рамках ДАДК???. Последовательность обработки данных включает 21 датасет: 4 реальных и 17 сгенерированных с помощью специализированного сервиса для генерации данных, что обеспечивает тестирование робастности методов на разнородных выборках. Сначала генерация синтетических данных. Далее параллельно происходит обработка двумя различными идеями для получения предвзятых экспертов: модифицированный алгоритм выявления ЛОКАЛЬНОЙ И ГЛОБАЛЬНОЙ предвзятости и модифицированный двухфазный алгоритм определения консенсуса с различными методами кластеризации.

Файл pipe_eng_with_datasets.archimate 

Исходные датасеты последовательно генерируются с использованием разработанного генератора синтетических данных, после чего результаты направляются на два различных алгоритма: специализированный алгоритм выявления предвзятостей и модифицированный ДАДК. На выходе получаются результаты предвзятых экспертов и результаты кластеризации для дальнейшего сравнения.
3.2. Датасет из статьи (А)
В качестве исходных данных с заведомо известным результатом определения глобальной предвзятости взят датасет из статьи [2]:

Датасет содержит:
? 5 экспертов;
? 6 альтернатив;
? 3 критерия для каждой альтернативы.
Значения параметров:
? alpha (уровень значимости) = 0.95
? B (пороговое значение предвзятости) = 2
? gamma (общий предопределенный вес) = 0.5

Визуализация:

3.3. Контрпример 1 (А)
Для тестирования алгоритма определения локальной предвзятости требуется задать контрпример, который позволит продемонстрировать уязвимость алгоритма определения глобальной предвзятости. Для этого был создан иллюстративный пример оценки альтернатив по 10 бальной шкале, который содержит следующие данные:

AlternativeCriteriaDM1DM2DM3DM4Phone1Camera8771Autonomy7861Cost6781Phone2Camera6555Autonomy5645Cost7675Phone3Camera43310Autonomy34210Cost85910
В данном датасете из всех оценок выделяется эксперт DM4, который занижает первую альтернативу (Phone1) и завышает последнюю альтернативу (Phone3). Эти данные явно указывают на предвзятость эксперта DM4 в отношении первой и последней альтернативы, однако оценки эксперта не имеют малую дискриминантность, что позволяет протестировать адекватность работы разработанного алгоритма определения локальной предвзятости.
Визуализация:


3.4. Контрпример 2
Для проверки работоспособности предложенного АПЛП также был создан второй контрпример, который симулирует ситуацию, когда эксперт ставит высокую оценку альтернативе по какому-то одному критерию (для отвода глаз), а другие критерии занижает. Таким образом проверяется, насколько получится запутать предложенный алгоритм поиска локальной предвзятости. Ниже приведена таблица с данными контрпримера 2:

АльтернативаКритерийDM1DM2DM3DM4Phone1Камера8771Автономность78610Цена67810Phone2Камера65510Автономность5641Цена7671Phone3Камера4335Автономность3425Цена8595
В предложенном контрпримере эксперт DM4 завышает оценки для первой альтернативы (Phone1) и занижает для второй альтернативы (Phone2). Также оценки эксперта не имеют малую дискриминантность, что позволяет протестировать адекватность работы АПЛП.
3.5. Датасет реальной задачи (А)
Для тестирования алгоритмов определения предвзятостей двух типов был создан датасет на основе реальной задачи по выбору метода беспроводной связи для дистанционного управления аппаратами запуска мишеней для стендовой стрельбы. Датасет содержит:
? 6 экспертов (1 предвзят);
? 7 альтернатив;
? 8 критериев.
Оценки заданы по 5-ти бальной шкале. По данным визуально можно выделить оценки эксперта 6, который завышает и занижает оценки некоторым альтернативам, относительно оценок остальных экспертов. Данный датасет призван протестировать алгоритмы определения предвзятости на реальных данных.
Визуализация:

Особенность датасета: эксперт 6 предвзят и глобально, и локально
3.6. Синтетические данные (А)
Для тестирования методов определения предвзятости экспертов был разработан генератор синтетических данных для получения оценок экспертов для задач многокритериального группового принятия решений, который позволяет задать глобальную/локальную предвзятость конкретному эксперту, что позволит оценить результаты работы алгоритмов определения предвзятости по заведомо известным характеристикам синтетических данных.
3.6.1. Генератор данных (А)
Представленный генератор данных предназначен для моделирования сценариев группового принятия решений (ГПР) в условиях многокритериальной оценки. Инструмент реализует композиционный подход, интегрируя базовый генератор альтернатив с модулем моделирования экспертных предвзятостей, что позволяет создавать реалистичные синтетические данные для тестирования и анализа алгоритмов ГПР.
Процесс генерации данных можно поделить на следующие фазы:
1. Фаза конфигурации системы
Инициализация системы начинается с определения структурных параметров задачи: количества критериев оценки, рассматриваемых альтернатив и числа участвующих экспертов. Параллельно осуществляется конфигурация моделей экспертной предвзятости через специализированные объекты конфигурации, определяющие тип, направление и интенсивность систематических отклонений в экспертных оценках.
2. Генерация референсных данных
На первом этапе система формирует объективную базу данных. Создаются критерии двух принципиально различных типов: абсолютные количественные шкалы с непрерывными значениями и порядковые шкалы с дискретными градациями. Для каждой альтернативы генерируются оценки по всем критериям с использованием вероятностных распределений, имитирующих реальные закономерности распределения характеристик.
3. Моделирование предвзятостей экспертов
Глобальная предвзятость
Данный тип предвзятости моделирует поведение экспертов, демонстрирующих тенденцию к сглаживанию различий между альтернативами. Вместо четкой дифференциации объектов по их качествам, такие эксперты склонны присваивать всем альтернативам схожие оценки, уменьшая вариативность своих суждений. Интенсивность этого эффекта регулируется коэффициентом, определяющим степень сближения оценок к их среднему значению.
Локальная предвзятость
Локальная предвзятость отражает ситуацию, когда эксперт демонстрирует систематическое смещение в оценках конкретной альтернативы, завышая или занижая ее характеристики относительно объективной базы. Важной методологической особенностью является то, что смещение отсчитывается не от текущей вариативной оценки эксперта, а от референсного базового значения, что исключает влияние случайных флуктуаций на величину преднамеренного искажения.
4. Имитация естественной вариативности
Для приближения модели к реальным условиям принятия решений в систему вводится аддитивный случайный шум малой амплитуды. Этот элемент имитирует естественную вариативность человеческих суждений, неизбежные погрешности восприятия и случайные колебания в экспертном оценивании.
3.6.2. Синтетические данные (А)
В ходе использования генератора синтетических данных было получено 15 датасетов, которые можно поделить на 3 типа:
1. малый датасет из 10 экспертов (5 шт):
2. средний датасет из 50 экспертов (5 шт):
3. большой датасет из 100 экспертов (5 шт).

Каждый датасет содержит следующие данные:
1. от 5 до 20 альтернатив;
2. от 3 до 20 критериев;
3. коэффициент допустимого отклонения оценок экспертов от консенсуса для непредвзятых экспертов: {0.05, 0.1, 0.15};
4. отношение абсолютных шкал к порядковым: от 0.1 до 0.9 (шаг 0.1);
5. эксперт 6 глобально предвзят;
6. эксперт 1 завышает альтернативы 1-2 на 40% от консенсуса и занижает альтернативы 3-5 на 30%, 35% и 40% от консенсуса соответственно.

Важно учитывать, что синтетические данные генерируются случайно по заданному распределению, поэтому реальная предвзятость экспертов также подвержена фактору случайности, так как значения шкал имеют ограничения по минимальному и максимальному значениям и не могут выходить за эти пределы.
4.Тестирование 
В ходе исследования для определения предвзятости было решено использовать только метод EABM, как наиболее подходящий для оценки предвзятости экспертов (метка класса).
В таблицах (НОМЕР) проиллюстрирована работа ансамбля кластеризационных алгоритмов на основе голосования пяти экспертов, при этом конкретные номера кластеров для отдельного алгоритма не интерпретируются содержательно, а важен лишь факт различий между разбиениями.
В правом столбце приведены бинарные оценки специализированного алгоритма предвзятости, где значение 0 соответствует отсутствию предвзятости, значение 1 - выявленной глобальной предвзятости, 2 - локальной предвзятости.
Столбец "Голоса за предвзятость" вычисляется как количество алгоритмов, принявшего данного эксперта в не главный кластер. Главным кластером в данном случае будет называть кластер, размер которого больше или равен половине количества экспертов из всей выборки.
В работе используется F1?score, который измеряет, насколько хорошо алгоритм кластеризации выделяет заранее заданных предвзятых экспертов по сравнению с эталонным списком, полученным алгоритмом EABM.
Для каждого метода берутся все кластеры, считается размер, и главным кластером считается кластер с максимальным числом экспертов. Все эксперты, которые не входят в главный кластер, считаются "диссидентами" (кандидатами на предвзятых).

По номерам экспертов формируются два бинарных вектора: y_true и y_pred. По ним рассчитываются значения TP (True Positive - эксперты есть как в главном списке, так и в диссидентах), FP(False Positive -  эксперты, которые алгоритм выделил как диссидента, но ложно предвзят - ошибка алгоритма), FN (False Negative - эксперты, являющиеся на самом деле предвзятыми, но алгоритм их не выделил). Далее считаются метрики precision и recall, а f1-score является их гармоническим средним.
\begin{equation}
\text{F1} = \frac{2 \cdot \text{TP}}{2 \cdot \text{TP} + \text{FP} + \text{FN}}
\end{equation}

Значения F1?score, близкие к единице, означают, что алгоритм почти полностью совпадает с эталонным набором предвзятых экспертов: он находит большинство истинно предвзятых и редко ошибается на непредвзятых.
Промежуточные значения указывают на частичное совпадение (либо есть пропуски предвзятых, либо много ложных срабатываний), а значения, близкие к нулю, свидетельствуют о том, что выделенные алгоритмом диссиденты плохо соответствуют заданному списку предвзятых экспертов.
Выбрана именно эта метрика, так как она является одновременно штрафующей как пропуски истинных предвзятых, так и ложные срабатывания на непредвзятых.
4.1. Датасет из статьи
4.1.1. Предвзятость
Используемые параметры:
"parameters": {
    "alpha": 0.95,
    "B": 2,
    "gamma": 0.5,
    "L": 0.30
}


Полученные результаты соответствуют результатам из статьи - алгоритм определения глобальной предвзятости работает корректно.

4.1.2. Кластеризация

fannywardkmeansgmmspectralbirchdbscanmean_shiftГолоса за предвзятостьАлгоритм предвзятости МОДDM10202020051DM20020001020DM32021102140DM40021003120DM51111214061, 2f1score0.5110.50.510.330
Большинство кластеризаторов продемонстрировали согласованность в выделении предвзятости: DM1 и DM5 получили по 5 голосов, DM3 - 3 голоса. 
Однако DBSCAN сформировал индивидуальные кластеры для каждого эксперта, что свидетельствует о некорректном выборе гиперпараметра eps и чрезмерной чувствительности к плотности данных. MeanShift ошибочно классифицировал экспертов DM1 и DM3 как предвзятых, несмотря на их объективный статус, что указывает на ограничения метода в сценариях с перекрывающимися распределениями.
Результаты f1-score выделяет лучшими алгоритмы: f1-score, kmeans, birch.

4.2. Контрпример 1
4.2.1. Предвзятость
Используемые параметры:
"parameters": {
    "alpha": 0.95,
    "B": 2,
    "gamma": 0.5,
    "L": 0.25
  }


Из полученных результатов видно, что индексы глобальной предвзятости имеют максимальное значение, то есть исходный алгоритм определения предвзятости не справляется с определением предвзятости эксперта DM4 в обычном понимании этого слова, поэтому для решения задачи используется алгоритм определения локальной предвзятости, который четко отделяет локально предвзятого эксперта от остальных экспертов (видно по индексам локальной предвзятости).

4.2.2. Кластеризация

fannywardkmeansgmmspectralbirchdbscanmean_shiftГолоса за предвзятостьАлгоритм предвзятостиDM10000000010DM20000000110DM30000000210DM41111111381, 2f1-score11111110.5Большинство кластеризаторов продемонстрировали согласованность в выделении предвзятости: DM4 получил 7 голосов, DM1 и DM2 - по 1 голосу. 
Расхождение и зашумленность итогового результата состоит в том, что MeanShift выделил каждого эксперта в отдельный кластер, что доказывает несостоятельность метода в данной задаче.

4.3. Контрпример 2
4.3.1. Предвзятость
Используемые параметры:
"parameters": {
    "alpha": 0.95,
    "B": 2,
    "gamma": 0.5,
    "L": 0.1
  }


Из полученных результатов видно, что индексы глобальной предвзятости имеют максимальное значение, то есть исходный алгоритм определения предвзятости не справляется с определением предвзятости эксперта DM4 в обычном понимании этого слова, поэтому для решения задачи используется алгоритм определения локальной предвзятости, который четко отделяет локально предвзятого эксперта от остальных экспертов (видно по индексам локальной предвзятости).

4.3.2. Кластеризация

fannywardkmeansgmmspectralbirchdbscanmean_shiftГолоса за предвзятостьАлгоритм предвзятостиDM10000000210DM20000000010DM30000000100DM41111111171, 2f1-dcore11111110
?4.4. Датасет реальной задачи
4.4.1. Предвзятость
Используемые параметры:
"parameters": {
    "alpha": 0.95,
    "B": 2,
    "gamma": 0.5,
    "L": 0.25
}


Из результатов видно, что эксперт 6 попадает под определение и глобальной, и локальной предвзятости
4.4.2. Кластеризация

fannywardkmeansgmmspectralbirchdbscanmean_shiftГолоса за предвзятостьАлгоритм предвзятостиDM10000000310DM20000100020DM30000000410DM40000000110DM50000100220DM61111011571, 2f1score11110110.33В данном примере все алгоритмы верно определили 7 эксперта как предвзятого. Значения 1 и 2 можно считать зашумленными.
Все методы, кроме spectral и mean_shift показали идеальный результат.
4.5. Синтетические данные 1
4.5.1. Предвзятость
Используемые параметры:
"parameters": {
    "alpha": 0.95,
    "B": 2,
    "gamma": 0.5,
    "L": 0.2
}


Все предвзятые эксперты были успешно определены согласно заданному синтетическому датасету.

4.5.2. Кластеризация

fannywardkmeansgmmspectralbirchdbscanmean_shiftГолоса за предвзятостьАлгоритм предвзятостиDM11101010180DM20010101001DM30010001011DM40010101001DM50010101001DM60010101000DM70010001011f1score0.6670.6670.6670.6770.40.6770.6770.677На данном датасете все алгоритмы единогласно выбрали первого эксперта в качестве предвзятого 6 эксперт при этом не был выделен ни одним алгоритмом.
4.6. Синтетические данные 2
4.6.1. Предвзятость
Используемые параметры:
"parameters": {
    "alpha": 0.95,
    "B": 2,
    "gamma": 0.5,
    "L": 0.15
}


Из полученных результатов видно, что все заданные предвзятые эксперты были обнаружены с помощью алгоритмов глобальной и локальной предвзятости.
4.6.2. Кластеризация

Большинство кластеризаторов продемонстрировали высокую согласованность в идентификации глобально предвзятых экспертов: DM1-DM7 получили большинство голосов. DM11, DM13, DM12 также были выделены отдельными методами в кластеры.
Эксперты с глобальной предвзятостью (DM1-DM7) систематически выделялись в малые кластеры (менее 50% экспертов) большинством методов, что подтверждает их аномальный статус в распределении экспертных суждений. Эксперты с локальной предвзятостью (DM11-DM13) изолировались лишь частично, что указывает на контекстно-зависимые отклонения, не достигающие уровня консенсуса.
Также, mean_shift полностью правильно выделил предвзятых экспертов.

fannywardkmeansgmmspectralbirchdbscanmean_shiftf1score0.320.8240.8890.8890.1820.8240.4171accuracy  0.660.970.980.980.910.970.721precision  0.2111110.2631recall0.80.70.80.80.10.711

4.7. Синтетические данные 3 (набор из 10 экспертов)
Для более масштабного тестирования были сгенерированы датасеты с различным числом экспертов.
Гиперпараметрами  для генерации, выбирающимися случайно стали:
1. Критерии: от 3 до 20
2. Альтернативы: от 5 до 20
3. Эксперты: 10, 50, 100
4. Отношение абсолютной к порядковой шкале: от 0.1 до 0.9
5. Отклонение данных оценок экспертов от эталона: 5%, 10%, 15%
В данных примерах всегда DM1 является глобальным, а DM6 - локальным предвзятыми экспертами.
4.7.1. Предвзятость
Используемые параметры для генерации датасета Синтетические данные и анализа предвзятости (+ визуализация) Результаты анализа
4.7.2. Кластеризация

10.1

\begin{tabular}{lccccc}
\hline
 & f1score & accuracy & precision & recall & количество диссидентов \\
\hline
fanny & 0.333 & 0.6 & 0.250 & 0.5 & 4 \\
ward & 1.000 & 1.0 & 1.000 & 1.0 & 2 \\
kmeans & 1.000 & 1.0 & 1.000 & 1.0 & 2 \\
gmm & 1.000 & 1.0 & 1.000 & 1.0 & 2 \\
spectral & 0.250 & 0.4 & 0.167 & 0.5 & 6 \\
birch & 1.000 & 1.0 & 1.000 & 1.0 & 2 \\
dbscan & 0.182 & 0.1 & 0.111 & 0.5 & 9 \\
mean\_shift & 1.000 & 1.0 & 1.000 & 1.0 & 2 \\
\hline
\end{tabular}





10.2 

\begin{tabular}{lccccc}
\hline
 & f1score & accuracy & precision & recall & количество диссидентов \\
\hline
fanny & 0.667 & 0.8 & 0.500 & 1.0 & 4 \\
ward & 0.667 & 0.9 & 1.000 & 0.5 & 1 \\
kmeans & 0.667 & 0.9 & 1.000 & 0.5 & 1 \\
gmm & 0.000 & 0.7 & 0.000 & 0.0 & 1 \\
spectral & 0.000 & 0.6 & 0.000 & 0.0 & 2 \\
birch & 0.667 & 0.9 & 1.000 & 0.5 & 1 \\
dbscan & 0.500 & 0.6 & 0.333 & 1.0 & 6 \\
mean\_shift & 0.800 & 0.9 & 0.667 & 1.0 & 3 \\
\hline
\end{tabular}



10.3


\begin{tabular}{lccccc}
\hline
 & f1score & accuracy & precision & recall & количество диссидентов \\
\hline
fanny & 0.571 & 0.7 & 0.400 & 1.0 & 5 \\
ward & 1.000 & 1.0 & 1.000 & 1.0 & 2 \\
kmeans & 1.000 & 1.0 & 1.000 & 1.0 & 2 \\
gmm & 1.000 & 1.0 & 1.000 & 1.0 & 2 \\
spectral & 0.667 & 0.8 & 0.500 & 1.0 & 4 \\
birch & 1.000 & 1.0 & 1.000 & 1.0 & 2 \\
dbscan & 0.667 & 0.8 & 0.500 & 1.0 & 4 \\
mean\_shift & 1.000 & 1.0 & 1.000 & 1.0 & 2 \\
\hline
\end{tabular}




10.4

\begin{tabular}{lccccc}
\hline
 & f1score & accuracy & precision & recall & количество диссидентов \\
\hline
fanny & 0.571 & 0.7 & 0.400 & 1.0 & 5 \\
ward & 1.000 & 1.0 & 1.000 & 1.0 & 2 \\
kmeans & 1.000 & 1.0 & 1.000 & 1.0 & 2 \\
gmm & 1.000 & 1.0 & 1.000 & 1.0 & 2 \\
spectral & 0.333 & 0.6 & 0.250 & 0.5 & 4 \\
birch & 1.000 & 1.0 & 1.000 & 1.0 & 2 \\
dbscan & 0.400 & 0.4 & 0.250 & 1.0 & 8 \\
mean\_shift & 1.000 & 1.0 & 1.000 & 1.0 & 2 \\
\hline
\end{tabular}



10.5

\begin{tabular}{lccccc}
\hline
 & f1score & accuracy & precision & recall & количество диссидентов \\
\hline
fanny & 0.286 & 0.5 & 0.200 & 0.5 & 5 \\
ward & 1.000 & 1.0 & 1.000 & 1.0 & 2 \\
kmeans & 1.000 & 1.0 & 1.000 & 1.0 & 2 \\
gmm & 1.000 & 1.0 & 1.000 & 1.0 & 2 \\
spectral & 0.000 & 0.4 & 0.000 & 0.0 & 4 \\
birch & 1.000 & 1.0 & 1.000 & 1.0 & 2 \\
dbscan & 1.000 & 1.0 & 1.000 & 1.0 & 2 \\
mean\_shift & 1.000 & 1.0 & 1.000 & 1.0 & 2 \\
\hline
\end{tabular}




Средний f1-score по всем экспериментам

fannywardkmeansgmmspectralbirchdbscanmean_shiftf1score0.4860.9330.9330.80.250.9330.550.96

Лучшими методами в экспериментах оказались: mean_shift (0.96), ward (0.933), kmeans (0.933), birch (0.933). Spectral (0.25), DBSCAN (0.55) и fanny (0.486) нестабильны при малом объеме данных (n=10).

КОРРЕЛЯЦИЯ КОЛЧЕСВТА ЭКСПЕРТОВ

Spectral содержит построение Лапласиана, при n=10 экспертов разница между соседними собственными значениями мала, поэтому шум доминирует. Проблема DBSCAN в настройке гиперпараметров: соотношение min_samples/eps классифицирует слишком много данных как шум. Fanny страдает от нечетких границ при малой выборке - экспертный шум размывает степени принадлежности.

В итоге, на небольшом количестве экспертов лучше использовать стандартные алгоритмы mean_shift, ward, kmeans, birch без спектральных методов, DBSCAN и нечетких ансамблей типа fanny.

4.8. Синтетические данные 4 (набор из 50 экспертов)

4.8.1. Предвзятость
Используемые параметры для генерации датасета Синтетические данные и анализа предвзятости (+ визуализация) Результаты анализа
4.8.2. Кластеризация

50.1


\begin{tabular}{lccccc}
\hline
 & f1score & accuracy & precision & recall & количество диссидентов \\
\hline
fanny & 0.160 & 0.58 & 0.087 & 1.0 & 23 \\
ward & 0.667 & 0.98 & 1.000 & 0.5 & 1 \\
kmeans & 0.667 & 0.98 & 1.000 & 0.5 & 1 \\
gmm & 0.182 & 0.82 & 0.111 & 0.5 & 9 \\
spectral & 0.667 & 0.98 & 1.000 & 0.5 & 1 \\
birch & 0.667 & 0.98 & 1.000 & 0.5 & 1 \\
dbscan & 0.667 & 0.98 & 1.000 & 0.5 & 1 \\
mean\_shift & 0.667 & 0.98 & 1.000 & 0.5 & 1 \\
\hline
\end{tabular}



50.2



\begin{tabular}{lccccc}
\hline
 & f1score & accuracy & precision & recall & количество диссидентов \\
\hline
fanny & 0.125 & 0.44 & 0.067 & 1.0 & 30 \\
ward & 0.087 & 0.58 & 0.048 & 0.5 & 21 \\
kmeans & 0.167 & 0.60 & 0.091 & 1.0 & 22 \\
gmm & 0.077 & 0.52 & 0.042 & 0.5 & 24 \\
spectral & 0.059 & 0.36 & 0.031 & 0.5 & 32 \\
birch & 0.154 & 0.56 & 0.083 & 1.0 & 24 \\
dbscan & 0.667 & 0.98 & 1.000 & 0.5 & 1 \\
mean\_shift & 1.000 & 1.00 & 1.000 & 1.0 & 2 \\
\hline
\end{tabular}


50.3

\begin{tabular}{lccccc}
\hline
 & f1score & accuracy & precision & recall & количество диссидентов \\
\hline
fanny & 0.095 & 0.62 & 0.053 & 0.5 & 19 \\
ward & 0.667 & 0.98 & 1.000 & 0.5 & 1 \\
kmeans & 0.667 & 0.98 & 1.000 & 0.5 & 1 \\
gmm & 0.182 & 0.82 & 0.111 & 0.5 & 9 \\
spectral & 0.667 & 0.98 & 1.000 & 0.5 & 1 \\
birch & 0.667 & 0.98 & 1.000 & 0.5 & 1 \\
dbscan & 1.000 & 1.00 & 1.000 & 1.0 & 2 \\
mean\_shift & 1.000 & 1.00 & 1.000 & 1.0 & 2 \\
\hline
\end{tabular}



50.4
\begin{tabular}{lccccc}
\hline
 & f1score & accuracy & precision & recall & количество диссидентов \\
\hline
fanny & 0.154 & 0.56 & 0.083 & 1.0 & 24 \\
ward & 1.000 & 1.00 & 1.000 & 1.0 & 2 \\
kmeans & 1.000 & 1.00 & 1.000 & 1.0 & 2 \\
gmm & 1.000 & 1.00 & 1.000 & 1.0 & 2 \\
spectral & 1.000 & 1.00 & 1.000 & 1.0 & 2 \\
birch & 1.000 & 1.00 & 1.000 & 1.0 & 2 \\
dbscan & 1.000 & 1.00 & 1.000 & 1.0 & 2 \\
mean\_shift & 0.800 & 0.98 & 0.667 & 1.0 & 3 \\
\hline
\end{tabular}



50.5

\begin{tabular}{lccccc}
\hline
 & f1score & accuracy & precision & recall & количество диссидентов \\
\hline
fanny & 0.000 & 0.52 & 0.000 & 0.0 & 22 \\
ward & 0.667 & 0.98 & 1.000 & 0.5 & 1 \\
kmeans & 0.667 & 0.98 & 1.000 & 0.5 & 1 \\
gmm & 0.667 & 0.98 & 1.000 & 0.5 & 1 \\
spectral & 0.667 & 0.98 & 1.000 & 0.5 & 1 \\
birch & 0.667 & 0.98 & 1.000 & 0.5 & 1 \\
dbscan & 0.500 & 0.96 & 0.500 & 0.5 & 2 \\
mean\_shift & 0.667 & 0.98 & 1.000 & 0.5 & 1 \\
\hline
\end{tabular}



Средний f1-score по всем экспериментам

fannywardkmeansgmmspectralbirchdbscanmean_shiftf1score0.1070.6180.6340.4220.6120.6310.7670.827

Лучшими методами в экспериментах с 50 экспертами оказались: mean_shift (0.827), dbscan (0.767), kmeans (0.634), birch (0.631), spectral (0.612). Худшие методы: fanny (0.107) и gmm (0.422) с наиболее нестабильным поведением.
При n=50 меняется картина: dbscan и spectral стабилизируются благодаря большему объему данных, а fanny катастрофически проваливается (0.107). GMM продолжает страдать от проблем гауссовых смесей - кластеры экспертов плохо аппроксимируются эллипсами, модель размывает границы или создает избыточное количество мелких кластеров.

Spectral работает лучше благодаря четкой дискриминации собственных значений Лапласиана при увеличенной выборке. DBSCAN выигрывает от корректной настройки eps/min_samples на плотных данных.
В итоге, на среднем количестве экспертов (n?50) лучше использовать dbscan, mean_shift, spectral, kmeans, birch, исключив gmm и fanny. Для максимальной надежности - ансамбль из dbscan + mean_shift + spectral.

4.9. Синтетические данные 5 (набор из 100 экспертов)

4.9.1. Предвзятость
Используемые параметры для генерации датасета Синтетические данные и анализа предвзятости (+ визуализация) Результаты анализа
4.9.2. Кластеризация

100.1

\begin{tabular}{lccccc}
\hline
 & f1score & accuracy & precision & recall & количество диссидентов \\
\hline
fanny & 0.082 & 0.55 & 0.043 & 1.0 & 47 \\
ward & 0.667 & 0.99 & 1.000 & 0.5 & 1 \\
kmeans & 0.667 & 0.99 & 1.000 & 0.5 & 1 \\
gmm & 0.042 & 0.54 & 0.022 & 0.5 & 46 \\
spectral & 0.667 & 0.99 & 1.000 & 0.5 & 1 \\
birch & 0.667 & 0.99 & 1.000 & 0.5 & 1 \\
dbscan & 1.000 & 1.00 & 1.000 & 1.0 & 2 \\
mean\_shift & 1.000 & 1.00 & 1.000 & 1.0 & 2 \\
\hline
\end{tabular}



100.2
\begin{tabular}{lccccc}
\hline
 & f1score & accuracy & precision & recall & количество диссидентов \\
\hline
fanny & 0.118 & 0.70 & 0.062 & 1.0 & 32 \\
ward & 0.667 & 0.99 & 1.000 & 0.5 & 1 \\
kmeans & 0.667 & 0.99 & 1.000 & 0.5 & 1 \\
gmm & 0.085 & 0.57 & 0.044 & 1.0 & 45 \\
spectral & 0.667 & 0.99 & 1.000 & 0.5 & 1 \\
birch & 0.667 & 0.99 & 1.000 & 0.5 & 1 \\
dbscan & 1.000 & 1.00 & 1.000 & 1.0 & 2 \\
mean\_shift & 0.118 & 0.70 & 0.062 & 1.0 & 32 \\
\hline
\end{tabular}




100.3

\begin{tabular}{lccccc}
\hline
 & f1score & accuracy & precision & recall & количество диссидентов \\
\hline
fanny & 0.042 & 0.54 & 0.022 & 0.5 & 46 \\
ward & 0.667 & 0.99 & 1.000 & 0.5 & 1 \\
kmeans & 0.667 & 0.99 & 1.000 & 0.5 & 1 \\
gmm & 0.333 & 0.92 & 0.200 & 1.0 & 10 \\
spectral & 0.667 & 0.99 & 1.000 & 0.5 & 1 \\
birch & 0.667 & 0.99 & 1.000 & 0.5 & 1 \\
dbscan & 1.000 & 1.00 & 1.000 & 1.0 & 2 \\
mean\_shift & 1.000 & 1.00 & 1.000 & 1.0 & 2 \\
\hline
\end{tabular}




100.4
\begin{tabular}{lccccc}
\hline
 & f1score & accuracy & precision & recall & количество диссидентов \\
\hline
fanny & 0.000 & 0.42 & 0.000 & 0.0 & 56 \\
ward & 1.000 & 1.00 & 1.000 & 1.0 & 2 \\
kmeans & 1.000 & 1.00 & 1.000 & 1.0 & 2 \\
gmm & 0.095 & 0.62 & 0.050 & 1.0 & 40 \\
spectral & 1.000 & 1.00 & 1.000 & 1.0 & 2 \\
birch & 1.000 & 1.00 & 1.000 & 1.0 & 2 \\
dbscan & 0.043 & 0.12 & 0.022 & 1.0 & 90 \\
mean\_shift & 1.000 & 1.00 & 1.000 & 1.0 & 2 \\
\hline
\end{tabular}



100.5
\begin{tabular}{lccccc}
\hline
 & f1score & accuracy & precision & recall & количество диссидентов \\
\hline
fanny & 0.075 & 0.51 & 0.039 & 1.0 & 51 \\
ward & 0.059 & 0.68 & 0.031 & 0.5 & 32 \\
kmeans & 0.077 & 0.52 & 0.040 & 1.0 & 50 \\
gmm & 0.077 & 0.52 & 0.040 & 1.0 & 50 \\
spectral & 0.667 & 0.99 & 1.000 & 0.5 & 1 \\
birch & 0.059 & 0.68 & 0.031 & 0.5 & 32 \\
dbscan & 0.041 & 0.06 & 0.021 & 1.0 & 96 \\
mean\_shift & 0.800 & 0.99 & 0.667 & 1.0 & 3 \\
\hline
\end{tabular}


Средний f1-score по всем экспериментам

fannywardkmeansgmmspectralbirchdbscanmean_shiftf1score0.0630.6120.6160.1260.7340.6120.6170.7836



Лучшими методами в экспериментах с 100 экспертами оказались mean_shift (0.7836), spectral (0.734), dbscan (0.617). Mean_shift лидирует по среднему F1-score с устойчиво высокими результатами, spectral показывает второй лучший средний F1 с отличной производительностью на четких структурах, dbscan стабильно работает на компактных кластерах. Худшие методы: fanny (0.063) и gmm (0.126) с катастрофически низкими результатами.
Причины те же, что при n=50: GMM не справляется с негауссовскими кластерами экспертов, размывая границы или создавая мелкие кластеры. Fanny полностью проваливается из-за чрезмерной нечеткости при большом объеме шумных данных.
В итоге, на большом количестве экспертов (n?100) лучше использовать mean_shift, spectral clustering, dbscan, а также ансамбль из mean_shift + spectral + dbscan + kmeans/birch/ward, исключив gmm и fanny.


5.Результаты 


Для анализа результатов был проведен тест по корреляции f1-score в зависимости от количества экспертов. Для расчетов использовался коэффициент корреляции Пирсона для выборок среднего значения f1-score на 10, 50 и 100 экспертах.
Результат:

fannywardkmeansgmmspectralbirchdbscanmean_shiftr-0.881-0.841-0.859-0.9910.942-0.860.24-0.939p0.3410.3640.3420.0850.2180.3410.8460.224

Анализ корреляционных коэффициентов показывает чёткое разделение алгоритмов кластеризации по их зависимости от размера экспертной выборки. Методы GMM, meanshift, fanny, ward, kmeans и birch демонстрируют сильную отрицательную корреляцию (r от -0.841 до -0.991), что означает их высокую эффективность при малом количестве экспертов (n?10), но резкую деградацию производительности при увеличении выборки до 50-100 экспертов. 

Напротив, spectral clustering обладает уникальной положительной корреляцией (r=+0.942), переходя от наихудших показателей при n=10 к одним из лучших при n=100. Это объясняется улучшением дискриминации собственных значений Лапласиана при росте плотности данных - разница между соседними спектральными зазорами увеличивается, что обеспечивает стабильное выделение кластеров.

DBSCAN занимает особое положение с практически нулевой корреляцией (r=+0.240), демонстрируя стабильную производительность независимо от размера выборки, что делает его универсальным выбором для переходных режимов.


Оптимальный выбор метода определяется следующим образом: при малом количестве экспертов предпочтительны meanshift, GMM, ward, kmeans или birch, обеспечивающие максимальный F1-score на малых выборках. В среднем экспертов оптимально комбинировать DBSCAN для стабильности со spectral clustering для роста производительности. При более чем 75 экспертах лидируют spectral clustering и DBSCAN, дополняемые meanshift для финальной доработки.

Полученные результаты подчеркивают отсутствие универсального алгоритма и необходимость адаптации выбора метода к размеру экспертной группы при решении задач предвзятости.
Эксперименты показали, что алгоритм fanny можно заменить на другие алгоритмы кластеризации. Это становится наиболее необходимо с ростом числа экспертов.
Несмотря на вариации отдельных методов, агрегация по принципу большинства обеспечивает четкий консенсус, идентифицируя экспертов как доминирующе предвзятых. Такая схема демонстрирует устойчивость ансамбля к артефактам кластеризации в рамках верификации экспертов.
Градация подчеркивает дискриминационную способность ансамбля: методы кластеризации с высокой степенью согласованности выявляют устойчивые аномалии (глобальная предвзятость), в то время как слабые сигналы локальной предвзятости требуют дополнительной верификации. Агрегация по принципу изоляции в малых кластерах обеспечивает робастный механизм ранжирования экспертов в AHP-процессе.
Для итогового анализа предвзятости предпочтений ансамблевым алгоритмом кластеризации предлагается использовать граничные значения, являющиеся минимальным числом методов, выделивших данного эксперта в отдельный.




Литература
1. A two-phase algorithm for consensus building in AHP-group decision making / B. Srdjevic [и др.] // Applied Mathematical Modelling. - 2013. - Т. 37, № 10. - С. 6670-6682.
2. Rabiee M., Aslani B., Rezaei J. A decision support system for detecting and handling biased decision-makers in multi criteria group decision-making problems // Expert Systems with Applications. - 2021. - Т. 171. - С. 114597.
3. Правила стрельбы скит: https://mynssa.nssa-nsca.org/wp-content/uploads/sites/6/2024/01/2024-NSSA-Rule-Book.pdf
4. Clustering [Электронный ресурс] // scikit-learn : machine learning in Python. - Электрон. дан. - Режим доступа: https://scikit-learn.org/stable/modules/clustering.html (дата обращения: 28.12.2025).
5. Pandas: https://pandas.pydata.org/
6. Numpy: https://numpy.org/
7. Click CLI: https://click.palletsprojects.com/en/stable/
8. Matplotlib: https://matplotlib.org/
9. Seaborn: https://seaborn.pydata.org/
10. Python docs: https://www.python.org/
11. Abels, Axel & Lenaerts, Tom & Trianni, Vito & Nowe, Ann. (2021). Dealing with Expert Bias in Collective Decision-Making. 10.48550/arXiv.2106.13539. 
12. Kulakowski, Konrad & Szybowski, Jacek & Mazurek, Jiri & Ernst, Sebastian. (2023). Towards secure judgments aggregation in AHP. 10.48550/arXiv.2303.15099. 
Если в других работах есть другие методы,то их тоже можно было включить (или мотивированно не использовать)
