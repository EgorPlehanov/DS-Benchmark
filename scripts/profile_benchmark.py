#!/usr/bin/env python3
"""
scripts/profile_benchmark.py
–ó–∞–ø—É—Å–∫ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ —Å —Ä–∞–∑–ª–∏—á–Ω—ã–º–∏ —É—Ä–æ–≤–Ω—è–º–∏ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è
"""

import os
import sys
import argparse
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞
current_file = Path(__file__).resolve()
project_root = current_file.parent.parent
sys.path.insert(0, str(project_root))

from src.runners.profiling_runner import ProfilingBenchmarkRunner
from src.adapters.factory import create_adapter, list_adapters


def get_test_dir(tests_arg: str) -> str:
    """–ü–æ–ª—É—á–∞–µ—Ç –ø—É—Ç—å –∫ —Ç–µ—Å—Ç–æ–≤—ã–º –¥–∞–Ω–Ω—ã–º"""
    if tests_arg == "last":
        # –ò—â–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
        last_gen_file = "data/generated/last_generation.txt"
        if os.path.exists(last_gen_file):
            with open(last_gen_file, 'r', encoding='utf-8') as f:
                folder_name = f.read().strip()
            return os.path.join("data/generated", folder_name)
        else:
            # –ò—â–µ–º –ª—é–±—É—é —Å—É—â–µ—Å—Ç–≤—É—é—â—É—é –≥–µ–Ω–µ—Ä–∞—Ü–∏—é
            generated_dir = Path("data/generated")
            if generated_dir.exists():
                # –ë–µ—Ä–µ–º –ø–æ—Å–ª–µ–¥–Ω—é—é –ø–∞–ø–∫—É
                dirs = sorted([d for d in generated_dir.iterdir() if d.is_dir()])
                if dirs:
                    return str(dirs[-1])
    
    # –ï—Å–ª–∏ —É–∫–∞–∑–∞–Ω –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –ø—É—Ç—å
    if os.path.exists(tests_arg):
        return tests_arg
    
    # –ü—Ä–æ–±—É–µ–º –∫–∞–∫ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–π –ø—É—Ç—å
    possible_path = os.path.join("data/generated", tests_arg)
    if os.path.exists(possible_path):
        return possible_path
    
    raise FileNotFoundError(f"–ù–µ —É–¥–∞–ª–æ—Å—å –Ω–∞–π—Ç–∏ —Ç–µ—Å—Ç—ã: {tests_arg}")


def main():
    available_profilers = {"cpu", "memory", "line", "scalene"}

    def parse_bool(value: str) -> bool:
        """–ü–∞—Ä—Å–µ—Ä –±—É–ª–µ–≤–æ–≥–æ –∑–Ω–∞—á–µ–Ω–∏—è –¥–ª—è CLI-–ø–∞—Ä–∞–º–µ—Ç—Ä–æ–≤ –≤–∏–¥–∞ True/False."""
        normalized = value.strip().lower()
        if normalized in {"true", "1", "yes", "y", "on"}:
            return True
        if normalized in {"false", "0", "no", "n", "off"}:
            return False
        raise argparse.ArgumentTypeError("–û–∂–∏–¥–∞–µ—Ç—Å—è –±—É–ª–µ–≤–æ –∑–Ω–∞—á–µ–Ω–∏–µ: True/False")

    def parse_profiling(value: str):
        """–ü–∞—Ä—Å–µ—Ä —Ä–µ–∂–∏–º–∞ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è: full | off | list(cpu,memory,...)"""
        normalized = value.strip().lower()

        if normalized == "full":
            return ["cpu", "memory", "line", "scalene"]

        if normalized == "off":
            return []

        tokens = [token.strip().lower() for token in value.replace(";", ",").split(",") if token.strip()]
        invalid = sorted(set(tokens) - available_profilers)

        if not tokens:
            raise argparse.ArgumentTypeError(
                "--profiling –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å 'full', 'off' –∏–ª–∏ —Å–ø–∏—Å–∫–æ–º –ø—Ä–æ—Ñ–∞–π–ª–µ—Ä–æ–≤: cpu,memory,line,scalene"
            )

        if invalid:
            raise argparse.ArgumentTypeError(
                f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–µ –ø—Ä–æ—Ñ–∞–π–ª–µ—Ä—ã: {', '.join(invalid)}. –î–æ—Å—Ç—É–ø–Ω–æ: {', '.join(sorted(available_profilers))}"
            )

        return list(dict.fromkeys(tokens))

    parser = argparse.ArgumentParser(
        description='–ó–∞–ø—É—Å–∫ –±–µ–Ω—á–º–∞—Ä–∫–æ–≤ —Å –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º –î–µ–º–ø—Å—Ç–µ—Ä–∞-–®–µ–π—Ñ–µ—Ä–∞'
    )
    
    parser.add_argument('--library', 
                       default='our',
                       choices=list_adapters(),
                       help='–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è')
    
    parser.add_argument('--tests',
                       default='last',
                       help='–ü—É—Ç—å –∫ —Ç–µ—Å—Ç–∞–º –∏–ª–∏ "last" –¥–ª—è –ø–æ—Å–ª–µ–¥–Ω–µ–π –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏')
    
    parser.add_argument('--profiling',
                       default='full',
                       type=parse_profiling,
                       help='–†–µ–∂–∏–º –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è: full | off | —Å–ø–∏—Å–æ–∫ (cpu,memory,line,scalene)')
    
    parser.add_argument('--iterations',
                       type=int,
                       default=3,
                       help='–ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–æ–≤ –∫–∞–∂–¥–æ–≥–æ —à–∞–≥–∞ –≤–Ω—É—Ç—Ä–∏ –æ–¥–Ω–æ–≥–æ –ø—Ä–æ–≥–æ–Ω–∞ —Ç–µ—Å—Ç–∞')
    
    parser.add_argument('--output-dir',
                       default='results/profiling',
                       help='–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤')
    
    parser.add_argument('--max-tests',
                       type=int,
                       default=None,
                       help='–ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤ –¥–ª—è –∑–∞–ø—É—Å–∫–∞')

    parser.add_argument('--sanitize-paths',
                       type=parse_bool,
                       default=True,
                       help='–ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø—É—Ç–∏ –≤ raw-–ø—Ä–æ—Ñ–∏–ª—è—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: True). '
                            '–î–ª—è –æ—Ç–∫–ª—é—á–µ–Ω–∏—è –ø–µ—Ä–µ–¥–∞–π—Ç–µ: --sanitize-paths False')
    
    args = parser.parse_args()
    
    print("üî¨ –ó–ê–ü–£–°–ö –ë–ï–ù–ß–ú–ê–†–ö–ê –° –ü–†–û–§–ò–õ–ò–†–û–í–ê–ù–ò–ï–ú")
    print("=" * 60)
    print(f"–ë–∏–±–ª–∏–æ—Ç–µ–∫–∞: {args.library}")
    selected_profilers = args.profiling
    profiling_mode = "off" if not selected_profilers else "full" if set(selected_profilers) == available_profilers else "custom"
    print(f"–ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ: {profiling_mode}")
    if selected_profilers:
        print(f"–ü—Ä–æ—Ñ–∞–π–ª–µ—Ä—ã: {', '.join(selected_profilers)}")
    else:
        print("–ü—Ä–æ—Ñ–∞–π–ª–µ—Ä—ã: –æ—Ç–∫–ª—é—á–µ–Ω—ã")
    print(f"–ü–æ–≤—Ç–æ—Ä–æ–≤ –∫–∞–∂–¥–æ–≥–æ —à–∞–≥–∞: {args.iterations}")
    print(f"–ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—É—Ç–µ–π: {'–≤–∫–ª—é—á–µ–Ω–∞' if args.sanitize_paths else '–≤—ã–∫–ª—é—á–µ–Ω–∞'}")
    
    runner = None

    try:
        # –ü–æ–ª—É—á–∞–µ–º –ø—É—Ç—å –∫ —Ç–µ—Å—Ç–∞–º
        test_dir = get_test_dir(args.tests)
        print(f"–¢–µ—Å—Ç—ã: {test_dir}")
        
        # –°–æ–∑–¥–∞–µ–º –∞–¥–∞–ø—Ç–µ—Ä
        adapter = create_adapter(args.library)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º backend-–∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –∞–¥–∞–ø—Ç–µ—Ä–∞ –æ–¥–∏–Ω —Ä–∞–∑ –ø–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º —Ç–µ—Å—Ç–æ–≤
        adapter._ensure_backend()
        
        # –°–æ–∑–¥–∞–µ–º —Ä–∞–Ω–Ω–µ—Ä —Å –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        runner = ProfilingBenchmarkRunner(
            adapter=adapter,
            results_dir=args.output_dir,
            profiling_mode=profiling_mode,
            selected_profilers=selected_profilers,
            sanitize_paths=args.sanitize_paths,
        )

        effective_iterations = 1 if not selected_profilers else args.iterations

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—É—Å–∫–∞ –¥–ª—è –≤–æ—Å–ø—Ä–æ–∏–∑–≤–æ–¥–∏–º–æ—Å—Ç–∏
        runner.set_run_parameters(
            library=args.library,
            tests=args.tests,
            resolved_test_dir=test_dir,
            profiling=args.profiling,
            profiling_mode=profiling_mode,
            profilers=selected_profilers,
            iterations=args.iterations,
            effective_iterations=effective_iterations,
            output_dir=args.output_dir,
            max_tests=args.max_tests,
            sanitize_paths=args.sanitize_paths,
        )
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç—ã
        print(f"\nüöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–æ–≤ –∏–∑: {test_dir}")
        summary = runner.run_test_suite(
            test_dir=test_dir,
            iterations=effective_iterations,
            max_tests=args.max_tests
        )
        
        # –í—ã–≤–æ–¥–∏–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–∏
        if selected_profilers:
            profiling_dir = Path(runner.profiling_dir)
            reports_dir = profiling_dir / "reports"
            print(f"\nüìä –î–ê–ù–ù–´–ï –ü–†–û–§–ò–õ–ò–†–û–í–ê–ù–ò–Ø:")
            print(f"   –û—Ç—á–µ—Ç—ã: {reports_dir}")
            print(f"   –°—ã—Ä—ã–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ñ–∞–π–ª–µ—Ä–æ–≤: {profiling_dir}")
            
            # –ü–æ–¥—Å—á–∏—Ç—ã–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ñ–∞–π–ª–æ–≤
            report_files = list(reports_dir.rglob("*.json"))
            raw_files = [
                p for p in profiling_dir.rglob("*.json")
                if "reports" not in p.parts and "inputs" not in p.parts
            ]
            
            print(f"   –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ –æ—Ç—á–µ—Ç–æ–≤: {len(report_files)}")
            print(f"   –°–æ—Ö—Ä–∞–Ω–µ–Ω–æ —Å—ã—Ä—ã—Ö —Ñ–∞–π–ª–æ–≤: {len(raw_files)}")
        
        print(f"\n‚úÖ –í–´–ü–û–õ–ù–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {runner.run_dir}")
        
        return 0
        
    except Exception as e:
        print(f"\n‚ùå –û—à–∏–±–∫–∞: {e}")
        import traceback
        traceback.print_exc()
        return 1
    finally:
        if runner is not None:
            try:
                runner.cleanup()
            except Exception as cleanup_error:
                print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ cleanup: {cleanup_error}")


if __name__ == "__main__":
    sys.exit(main())
