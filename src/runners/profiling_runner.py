# src/runners/profiling_runner.py
"""
ProfilingRunner - —Ä–∞—Å—à–∏—Ä–µ–Ω–∏–µ UniversalBenchmarkRunner —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è.
"""

import os
import json
import copy
from typing import Dict, Any, Optional, List
from datetime import datetime
from pathlib import Path

from .universal_runner import UniversalBenchmarkRunner
from ..profiling.composite_profiler import CompositeProfiler, CompositeProfileResult
from ..profiling.core.cpu_profiler import CPUProfiler
from ..profiling.core.memory_profiler import MemoryProfiler
from ..profiling.core.line_profiler import LineProfiler
from ..profiling.collectors import ScaleneCollector


class ProfilingBenchmarkRunner(UniversalBenchmarkRunner):
    """
    UniversalBenchmarkRunner —Å –ø–æ–¥–¥–µ—Ä–∂–∫–æ–π –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è.
    –ó–∞–ø—É—Å–∫–∞–µ—Ç —Ç–µ—Å—Ç—ã —Å–æ —Å–±–æ—Ä–æ–º –¥–µ—Ç–∞–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ –æ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.
    """
    
    def __init__(self, 
                 adapter,
                 results_dir: str = "results/profiling",
                 profiling_level: str = "medium",
                 sanitize_paths: bool = True,
                 enable_scalene: bool = False):
        """
        Args:
            adapter: –ê–¥–∞–ø—Ç–µ—Ä –¥–ª—è —Ç–µ—Å—Ç–∏—Ä—É–µ–º–æ–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
            results_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            profiling_level: –£—Ä–æ–≤–µ–Ω—å –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è (off, light, medium, full)
            sanitize_paths: –ù–æ—Ä–º–∞–ª–∏–∑–æ–≤–∞—Ç—å –ø—É—Ç–∏ –≤ raw-–¥–∞–Ω–Ω—ã—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: True)
        """
        super().__init__(adapter, results_dir)
        
        self.profiling_level = profiling_level
        self.sanitize_paths = sanitize_paths
        self.enable_scalene = enable_scalene
        self.profiler = self._setup_profiler()
        
        # –ë–∞–∑–æ–≤—ã–π –ø—É—Ç—å –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è –≤ —Å—Ç—Ä—É–∫—Ç—É—Ä–µ –∞—Ä—Ç–µ—Ñ–∞–∫—Ç–æ–≤
        self.profiling_dir = str(self.artifact_manager.run_dir / "profilers")

        self.scalene_collector = ScaleneCollector(
            output_dir=str(self.artifact_manager.run_dir / "profilers" / "scalene"),
            enabled=enable_scalene
        )
        
        print(f"üîß ProfilingRunner –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å —É—Ä–æ–≤–Ω–µ–º: {profiling_level}")
        print(f"üìä –ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤—â–∏–∫–∏: {', '.join(self.profiler.get_enabled_profilers())}")
        print(f"üõ°Ô∏è  –ù–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏—è –ø—É—Ç–µ–π: {'–≤–∫–ª—é—á–µ–Ω–∞' if self.sanitize_paths else '–≤—ã–∫–ª—é—á–µ–Ω–∞'}")
        print(f"üìà Scalene: {self.scalene_collector.get_status()}")

    def _make_path_relative(self, value: Any) -> Any:
        """–ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç –∞–±—Å–æ–ª—é—Ç–Ω—ã–µ –ø—É—Ç–∏ –≤ –æ—Ç–Ω–æ—Å–∏—Ç–µ–ª—å–Ω—ã–µ –∫ cwd, –µ—Å–ª–∏ –≤–æ–∑–º–æ–∂–Ω–æ."""
        if not isinstance(value, str):
            return value

        if not value:
            return value

        normalized = value.replace("\\", "/")

        if ":/" not in normalized and not normalized.startswith("/"):
            return value

        try:
            abs_path = Path(value).resolve()
            cwd_path = Path.cwd().resolve()
            relative = abs_path.relative_to(cwd_path)
            return str(relative).replace("\\", "/")
        except Exception:
            # –ï—Å–ª–∏ –ø—É—Ç—å –≤–Ω–µ –ø—Ä–æ–µ–∫—Ç–∞ –∏–ª–∏ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω, –Ω–µ —Ä–∞—Å–∫—Ä—ã–≤–∞–µ–º –ª–æ–∫–∞–ª—å–Ω—ã–µ –¥–µ—Ç–∞–ª–∏.
            return "<external_path>"

    def _sanitize_paths_in_value(self, value: Any) -> Any:
        """–†–µ–∫—É—Ä—Å–∏–≤–Ω–æ –Ω–æ—Ä–º–∞–ª–∏–∑—É–µ—Ç –ø—É—Ç–∏ –≤–æ –≤—Å–µ—Ö —Å—Ç—Ä–æ–∫–æ–≤—ã—Ö –∑–Ω–∞—á–µ–Ω–∏—è—Ö —Å—Ç—Ä—É–∫—Ç—É—Ä—ã –¥–∞–Ω–Ω—ã—Ö."""
        if isinstance(value, dict):
            sanitized_dict = {}
            for key, item in value.items():
                sanitized_key = self._make_path_relative(key) if isinstance(key, str) else key
                sanitized_dict[sanitized_key] = self._sanitize_paths_in_value(item)
            return sanitized_dict

        if isinstance(value, list):
            return [self._sanitize_paths_in_value(item) for item in value]

        if isinstance(value, tuple):
            return tuple(self._sanitize_paths_in_value(item) for item in value)

        if isinstance(value, str):
            return self._make_path_relative(value)

        return value

    def _prepare_profiler_payload(self, profiler_name: str, data: Dict[str, Any]) -> Dict[str, Any]:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –ø–æ–ª–Ω—ã–µ raw-–¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤—â–∏–∫–∞ —Å –æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ–π –Ω–æ—Ä–º–∞–ª–∏–∑–∞—Ü–∏–µ–π –ø—É—Ç–µ–π."""
        payload = copy.deepcopy(data)

        if not self.sanitize_paths:
            return payload

        return self._sanitize_paths_in_value(payload)
    
    def _setup_profiler(self) -> CompositeProfiler:
        """–ù–∞—Å—Ç—Ä–∞–∏–≤–∞–µ—Ç –∫–æ–º–ø–æ–∑–∏—Ç–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤—â–∏–∫ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —É—Ä–æ–≤–Ω—è"""
        profilers = []
        
        if self.profiling_level == "off":
            return CompositeProfiler(profilers=[], auto_setup=False)
        
        elif self.profiling_level == "light":
            cpu_profiler = CPUProfiler(
                name="cpu",
                enabled=True,
                sort_by='cumulative',
                limit=15
            )
            profilers.append(cpu_profiler)
        
        elif self.profiling_level == "medium":
            cpu_profiler = CPUProfiler(
                name="cpu",
                enabled=True,
                sort_by='cumulative',
                limit=25
            )
            memory_profiler = MemoryProfiler(
                name="memory",
                enabled=True,
                trace_frames=15,
                limit=10
            )
            profilers.extend([cpu_profiler, memory_profiler])
        
        elif self.profiling_level == "full":
            cpu_profiler = CPUProfiler(
                name="cpu",
                enabled=True,
                sort_by='cumulative',
                limit=40
            )
            memory_profiler = MemoryProfiler(
                name="memory",
                enabled=True,
                trace_frames=25,
                limit=20
            )
            line_profiler = LineProfiler(
                name="line",
                enabled=True,
                include_paths=[os.getcwd()],
                limit=50,
                line_limit_per_file=30
            )
            profilers.extend([cpu_profiler, memory_profiler, line_profiler])
        
        else:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —É—Ä–æ–≤–µ–Ω—å –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è: {self.profiling_level}")
        
        return CompositeProfiler(profilers=profilers, auto_setup=False)
    
    def _measure_performance(self, func, *args, step_name: str = "", 
                       test_name: str = "", repeat_count: int = 1, **kwargs):
        """
        –†–∞—Å—à–∏—Ä–µ–Ω–Ω–æ–µ –∏–∑–º–µ—Ä–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏ —Å –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º.
        """
        if self.profiling_level == "off":
            return super()._measure_performance(func, *args, step_name=step_name, **kwargs)
        
        print(f"   üìä –ü—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ {step_name}...", end="", flush=True)
        
        try:
            result, profile_result = self.profiler.profile(func, *args, **kwargs)
            
            execution_time = profile_result.metadata.get('function_execution_time', 0) * 1000
            
            base_metrics = {
                "time_ms": execution_time,
                "memory_peak_mb": 0.0,
                "cpu_usage_percent": 0.0
            }
            
            if profile_result.results:
                memory_data = profile_result.results.get('memory')
                if memory_data:
                    peak_bytes = memory_data.data.get('peak_memory_bytes', 0)
                    base_metrics["memory_peak_mb"] = peak_bytes / (1024 * 1024)
                
                self._save_profiling_data(
                    step_name=step_name,
                    profile_result=profile_result,
                    test_name=test_name,
                    repeat_count=repeat_count
                )
                
                base_metrics["profiling"] = {
                    'bottlenecks': profile_result.bottlenecks,
                    'correlations': profile_result.correlations,
                    'profiler_count': len(profile_result.results)
                }

            if self.enable_scalene and test_name:
                input_path = self._get_scalene_input_path(test_name)
                if input_path:
                    scalene_info = self.scalene_collector.profile_step(
                        input_path=input_path,
                        adapter_name=self.adapter_name,
                        step_name=step_name,
                        iteration=1,
                        test_name=test_name,
                        repeat=repeat_count
                    )
                    base_metrics["scalene"] = scalene_info

            base_metrics["step_repeat_count"] = repeat_count
            
            # ‚úÖ –ü–†–ê–í–ò–õ–¨–ù–ê–Ø –û–ë–†–ê–ë–û–¢–ö–ê –û–®–ò–ë–û–ö
            if 'error' in profile_result.metadata:
                error_info = profile_result.metadata['error']
                error_msg = str(error_info.get('error', 'Unknown error')).lower()
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —ç—Ç–æ –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ñ–ª–∏–∫—Ç –∏–ª–∏ –¥—Ä—É–≥–∞—è –æ—à–∏–±–∫–∞
                if any(keyword in error_msg for keyword in 
                    ["–ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ñ–ª–∏–∫—Ç", "full conflict", "k=1.0", "–∫–æ–Ω—Ñ–ª–∏–∫—Ç –º–µ–∂–¥—É –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏"]):
                    # –≠—Ç–æ –ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ñ–ª–∏–∫—Ç - –ù–ï –æ—à–∏–±–∫–∞, –∞ warning
                    base_metrics["warning"] = error_info.get('error', '–ü–æ–ª–Ω—ã–π –∫–æ–Ω—Ñ–ª–∏–∫—Ç –º–µ–∂–¥—É –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º–∏')
                else:
                    # –î—Ä—É–≥–∏–µ –æ—à–∏–±–∫–∏
                    base_metrics["error"] = error_info.get('error', 'Unknown error')
                    base_metrics["error_type"] = error_info.get('error_type', 'Exception')
            
            print(" ‚úì")
            return result, base_metrics
            
        except Exception as e:
            print(f" ‚ùå (–æ—à–∏–±–∫–∞ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è: {str(e)[:50]}...)")
            
            return None, {
                "time_ms": 0.0,
                "memory_peak_mb": 0.0,
                "cpu_usage_percent": 0.0,
                "error": f"–û—à–∏–±–∫–∞ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è: {str(e)}",
                "error_type": type(e).__name__
            }
    
    def _save_profiling_data(self, step_name: str, profile_result: CompositeProfileResult,
                           test_name: str = "", repeat_count: int = 1) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è —Å –ø—Ä–∏–≤—è–∑–∫–æ–π –∫ —Ç–µ—Å—Ç—É"""
        timestamp = datetime.now().strftime("%H%M%S")
        
        # ‚úÖ –°–û–ó–î–ê–ï–ú –ò–ú–Ø –§–ê–ô–õ–ê –° –ò–ù–§–û–†–ú–ê–¶–ò–ï–ô –û –¢–ï–°–¢–ï
        if test_name:
            filename = f"{test_name}_rep{repeat_count}_{step_name}_{timestamp}"
        else:
            filename = f"{step_name}_rep{repeat_count}_{timestamp}"
        
        # 1. –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –æ—Ç—á–µ—Ç
        report_data = {
            'step': step_name,
            'test_name': test_name,
            'timestamp': datetime.now().isoformat(),
            'total_duration': profile_result.total_duration,
            'bottlenecks': profile_result.bottlenecks,
            'correlations': profile_result.correlations,
            'metadata': {
                **profile_result.metadata,
                'step_repeat_count': repeat_count
            }
        }
        
        self.artifact_manager.save_json(
            f"{filename}_report.json",
            report_data,
            subdir=f"profilers/reports/{test_name or 'unknown'}"
        )
        
        # 2. –î–µ—Ç–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤—â–∏–∫–æ–≤
        for profiler_name, result in profile_result.results.items():
            profiler_data = {
                'profiler': profiler_name,
                'test_name': test_name,
                'step': step_name,
                'data': self._prepare_profiler_payload(profiler_name, result.data),
                'metadata': {
                    **result.metadata,
                    'raw_profile_mode': 'full',
                    'sanitize_paths': self.sanitize_paths,
                    'step_repeat_count': repeat_count
                }
            }
            
            self.artifact_manager.save_profiler_data(
                profiler_name=profiler_name,
                data=profiler_data,
                test_name=test_name or "unknown",
                step_name=step_name,
                repeat_count=repeat_count,
            )

        
        # 3. –ö—Ä–∞—Ç–∫–∞—è –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø–æ–∏—Å–∫–∞
        info_content = (
            f"Test: {test_name}\n"
            f"Step: {step_name}\n"
            f"Repeat count: {repeat_count}\n"
            f"Timestamp: {datetime.now().isoformat()}\n"
            f"Profiles: {', '.join(profile_result.results.keys())}\n"
        )
        self.artifact_manager.save_text(
            f"{filename}_info.txt",
            info_content,
            subdir=f"profilers/info/{test_name or 'unknown'}"
        )

    def _repeat_step(self, func, repeat_count: int, *args, **kwargs):
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç —à–∞–≥ –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –∏ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ –∑–∞–ø—É—Å–∫–∞."""
        result = None
        for _ in range(max(1, repeat_count)):
            result = func(*args, **kwargs)
        return result

    def _run_single_iteration(self, loaded_data: Any, test_data: Dict[str, Any],
                            iteration_num: int, alphas: List[float],
                            test_name: str = "", step_repeat_count: int = 1) -> Dict[str, Any]:
        """–í—ã–ø–æ–ª–Ω—è–µ—Ç –æ–¥–Ω—É –∏—Ç–µ—Ä–∞—Ü–∏—é —Ç–µ—Å—Ç–∞ —Å –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        iteration_results = {
            "run": iteration_num,
            "performance": {}
        }
        
        # –®–∞–≥ 1
        step1_results, step1_metrics = self._measure_performance(
            self._repeat_step,
            self._execute_step1,
            step_repeat_count,
            loaded_data,
            step_name="step1_original",
            test_name=test_name,
            repeat_count=step_repeat_count
        )
        iteration_results["step1"] = step1_results
        iteration_results["performance"]["step1"] = step1_metrics
        self.artifact_manager.save_metrics(step1_metrics, test_name or "unknown", "step1_original", iteration_num, repeat_count=step_repeat_count)
        
        # –®–∞–≥ 2
        step2_results, step2_metrics = self._measure_performance(
            self._repeat_step,
            self._execute_step2,
            step_repeat_count,
            loaded_data,
            step_name="step2_dempster",
            test_name=test_name,
            repeat_count=step_repeat_count
        )
        iteration_results["step2"] = step2_results
        iteration_results["performance"]["step2"] = step2_metrics
        self.artifact_manager.save_metrics(step2_metrics, test_name or "unknown", "step2_dempster", iteration_num, repeat_count=step_repeat_count)
        
        # –®–∞–≥ 3
        step3_results, step3_metrics = self._measure_performance(
            self._repeat_step,
            self._execute_step3,
            step_repeat_count,
            loaded_data,
            alphas,
            step_name="step3_discount_dempster",
            test_name=test_name,
            repeat_count=step_repeat_count
        )
        iteration_results["step3"] = step3_results
        iteration_results["performance"]["step3"] = step3_metrics
        self.artifact_manager.save_metrics(step3_metrics, test_name or "unknown", "step3_discount_dempster", iteration_num, repeat_count=step_repeat_count)
        
        # –®–∞–≥ 4
        step4_results, step4_metrics = self._measure_performance(
            self._repeat_step,
            self._execute_step4,
            step_repeat_count,
            loaded_data,
            step_name="step4_yager",
            test_name=test_name,
            repeat_count=step_repeat_count
        )
        iteration_results["step4"] = step4_results
        iteration_results["performance"]["step4"] = step4_metrics
        self.artifact_manager.save_metrics(step4_metrics, test_name or "unknown", "step4_yager", iteration_num, repeat_count=step_repeat_count)
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        iteration_results["performance"]["total"] = {
            "time_total_ms": sum(
                step["time_ms"] for step in iteration_results["performance"].values() 
                if isinstance(step, dict) and "time_ms" in step
            ),
            "memory_peak_mb": max(
                step.get("memory_peak_mb", 0) for step in iteration_results["performance"].values()
                if isinstance(step, dict)
            )
        }
        
        return iteration_results
    
    def run_test(self, test_data: Dict[str, Any], test_name: str,
                iterations: int = 3, alphas: Optional[List[float]] = None) -> Dict[str, Any]:
        """–ó–∞–ø—É—Å–∫–∞–µ—Ç —Ç–µ—Å—Ç —Å –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º.

        iterations –∏–Ω—Ç–µ—Ä–ø—Ä–µ—Ç–∏—Ä—É–µ—Ç—Å—è –∫–∞–∫ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–æ–≤ –∫–∞–∂–¥–æ–≥–æ —à–∞–≥–∞
        –≤–Ω—É—Ç—Ä–∏ –æ–¥–Ω–æ–≥–æ –ø—Ä–æ–≥–æ–Ω–∞ —Ç–µ—Å—Ç–∞.
        """
        print(f"\nüß™ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞: {test_name}")
        print(f"   –ü–æ–≤—Ç–æ—Ä–æ–≤ –Ω–∞ —à–∞–≥: {iterations}")
        step_repeat_count = max(1, iterations)
        
        test_results = {
            "metadata": {
                "test_name": test_name,
                "adapter": self.adapter_name,
                "run_count": 1,
                "iterations": 1,
                "step_repeat_count": step_repeat_count,
                "timestamp": datetime.now().isoformat(),
                "frame_size": len(test_data.get("frame_of_discernment", [])),
                "sources_count": len(test_data.get("bba_sources", []))
            },
            "runs": [],
            "iterations": [],
            "aggregated": {}
        }
        
        loaded_data = self.adapter.load_from_dass(test_data)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç–∞
        self.artifact_manager.save_test_input(test_data, test_name)
        self._save_scalene_input(test_name, test_data)
        
        if alphas is None:
            sources_count = self.adapter.get_sources_count(loaded_data)
            alphas = [0.1] * sources_count
        
        print("   –ò—Ç–µ—Ä–∞—Ü–∏—è 1/1...", end="", flush=True)
        iteration_results = self._run_single_iteration(
            loaded_data=loaded_data,
            test_data=test_data,
            iteration_num=1,
            alphas=alphas,
            test_name=test_name,
            step_repeat_count=step_repeat_count
        )
        test_results["runs"].append(iteration_results)
        test_results["iterations"].append(iteration_results)
        print(" ‚úì")
        
        test_results["aggregated"] = self._aggregate_iteration_results(
            test_results["runs"]
        )
        
        self._save_test_results(test_results, test_name)
        self.results.append(test_results)
        
        return test_results


    def _save_test_results(self, test_results: Dict[str, Any], test_name: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∞: –≤–æ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–µ–º API –æ—Å—Ç–∞–≤–ª—è–µ–º iterations, –≤ —Ñ–∞–π–ª–µ —Å–æ—Ö—Ä–∞–Ω—è–µ–º runs."""
        persisted_results = {
            **test_results,
            "metadata": {
                **test_results.get("metadata", {}),
            },
            "runs": list(test_results.get("runs") or test_results.get("iterations", [])),
        }
        persisted_results["metadata"].pop("iterations", None)
        persisted_results.pop("iterations", None)

        self.artifact_manager.save_test_results(persisted_results, test_name)
        self._create_short_report(test_results, test_name)

    def _save_scalene_input(self, test_name: str, test_data: Dict[str, Any]) -> None:
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç–∞ –¥–ª—è scalene."""
        if not self.enable_scalene:
            return
        self.artifact_manager.save_json(
            f"{test_name}.json",
            test_data,
            subdir="profilers/scalene/inputs"
        )

    def _get_scalene_input_path(self, test_name: str) -> Optional[str]:
        if not self.enable_scalene:
            return None
        input_path = self.artifact_manager.run_dir / "profilers" / "scalene" / "inputs" / f"{test_name}.json"
        return str(input_path) if input_path.exists() else None
    
    def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤"""
        super().cleanup()
        if hasattr(self, 'profiler') and self.profiler:
            if hasattr(self.profiler, 'cleanup'):
                try:
                    self.profiler.cleanup()
                except Exception as e:
                    print(f"‚ö†Ô∏è  –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ—á–∏—Å—Ç–∫–µ –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤—â–∏–∫–∞: {e}")
