"""
–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ä–∞–Ω–Ω–µ—Ä –¥–ª—è –±–µ–Ω—á–º–∞—Ä–∫–∏–Ω–≥–∞ —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–π —Ç–µ–æ—Ä–∏–∏ –î–µ–º–ø—Å—Ç–µ—Ä–∞-–®–µ–π—Ñ–µ—Ä–∞.
–í—ã–ø–æ–ª–Ω—è–µ—Ç 4-—à–∞–≥–æ–≤—ã–π –ø—Ä–æ—Ü–µ—Å—Å —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∏ —Å–æ–±–∏—Ä–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏.
"""

import os
import json
import time
import tracemalloc
import statistics
import psutil
from typing import Dict, List, Any, Optional, Tuple, Callable
from datetime import datetime
from pathlib import Path

from ..adapters.base_adapter import BaseDempsterShaferAdapter


class UniversalBenchmarkRunner:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ä–∞–Ω–Ω–µ—Ä –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∞–¥–∞–ø—Ç–µ—Ä–æ–≤ —Ç–µ–æ—Ä–∏–∏ –î–®.
    
    –í—ã–ø–æ–ª–Ω—è–µ—Ç:
    1. –ó–∞–≥—Ä—É–∑–∫—É —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    2. –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ 4-—à–∞–≥–æ–≤–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞
    3. –°–±–æ—Ä –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
    4. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
    """
    
    def __init__(self, adapter: BaseDempsterShaferAdapter, 
                 results_dir: str = "results/benchmark"):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞–Ω–Ω–µ—Ä–∞.
        
        Args:
            adapter: –ê–¥–∞–ø—Ç–µ—Ä –¥–ª—è —Ç–µ—Å—Ç–∏—Ä—É–µ–º–æ–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
            results_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        """
        self.adapter = adapter
        self.adapter_name = adapter.__class__.__name__.replace('Adapter', '').lower()
        self.results_dir = results_dir
        self.results = []
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏ –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        self.run_id = f"{self.adapter_name}_{timestamp}"
        self.run_dir = os.path.join(results_dir, self.run_id)
        
        os.makedirs(self.run_dir, exist_ok=True)
        os.makedirs(os.path.join(self.run_dir, "raw"), exist_ok=True)
        os.makedirs(os.path.join(self.run_dir, "profiles"), exist_ok=True)
        os.makedirs(os.path.join(self.run_dir, "aggregated"), exist_ok=True)
        
        print(f"üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Ä–∞–Ω–Ω–µ—Ä –¥–ª—è {self.adapter_name}")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {self.run_dir}")
    
    def run_test(self, test_data: Dict[str, Any], 
                 test_name: str,
                 iterations: int = 3,
                 alphas: Optional[List[float]] = None) -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–¥–∏–Ω —Ç–µ—Å—Ç.
        
        Args:
            test_data: –î–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ DASS
            test_name: –ò–º—è —Ç–µ—Å—Ç–∞ (–¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è)
            iterations: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π
            alphas: –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
            
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∞
        """
        print(f"\nüß™ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∞: {test_name}")
        print(f"   –ò—Ç–µ—Ä–∞—Ü–∏–π: {iterations}")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        test_results = {
            "metadata": {
                "test_name": test_name,
                "adapter": self.adapter_name,
                "iterations": iterations,
                "timestamp": datetime.now().isoformat(),
                "frame_size": len(test_data.get("frame_of_discernment", [])),
                "sources_count": len(test_data.get("bba_sources", []))
            },
            "iterations": [],
            "aggregated": {}
        }
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ –∞–¥–∞–ø—Ç–µ—Ä
        loaded_data = self.adapter.load_from_dass(test_data)
        
        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç—ã –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.1 –¥–ª—è –≤—Å–µ—Ö)
        if alphas is None:
            sources_count = self.adapter.get_sources_count(loaded_data)
            alphas = [0.1] * sources_count  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –≤—Å–µ 0.1
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∏—Ç–µ—Ä–∞—Ü–∏–∏
        for i in range(iterations):
            print(f"   –ò—Ç–µ—Ä–∞—Ü–∏—è {i+1}/{iterations}...", end="", flush=True)
            
            iteration_results = self._run_single_iteration(
                loaded_data=loaded_data,
                test_data=test_data,
                iteration_num=i+1,
                alphas=alphas
            )
            
            test_results["iterations"].append(iteration_results)
            print(" ‚úì")
        
        # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏—Ç–µ—Ä–∞—Ü–∏–π
        test_results["aggregated"] = self._aggregate_iteration_results(
            test_results["iterations"]
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å—ã—Ä—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self._save_test_results(test_results, test_name)
        
        # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ–±—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        self.results.append(test_results)
        
        return test_results
    
    def _run_single_iteration(self, 
                            loaded_data: Any,
                            test_data: Dict[str, Any],
                            iteration_num: int,
                            alphas: List[float]) -> Dict[str, Any]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –æ–¥–Ω—É –∏—Ç–µ—Ä–∞—Ü–∏—é —Ç–µ—Å—Ç–∞.
        
        Returns:
            –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –∏—Ç–µ—Ä–∞—Ü–∏–∏ —Å –º–µ—Ç—Ä–∏–∫–∞–º–∏ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        """
        iteration_results = {
            "iteration": iteration_num,
            "performance": {}
        }
        
        # === –®–ê–ì 1: –ò—Å—Ö–æ–¥–Ω—ã–µ Belief/Plausibility ===
        step1_results, step1_metrics = self._measure_performance(
            self._execute_step1,
            loaded_data,
            step_name="step1_original"
        )
        iteration_results["step1"] = step1_results
        iteration_results["performance"]["step1"] = step1_metrics
        
        # === –®–ê–ì 2: –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –î–µ–º–ø—Å—Ç–µ—Ä–æ–º ===
        step2_results, step2_metrics = self._measure_performance(
            self._execute_step2,
            loaded_data,
            step_name="step2_dempster"
        )
        iteration_results["step2"] = step2_results
        iteration_results["performance"]["step2"] = step2_metrics
        
        # === –®–ê–ì 3: –î–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ + –î–µ–º–ø—Å—Ç–µ—Ä ===
        step3_results, step3_metrics = self._measure_performance(
            self._execute_step3,
            loaded_data,
            alphas,
            step_name="step3_discount_dempster"
        )
        iteration_results["step3"] = step3_results
        iteration_results["performance"]["step3"] = step3_metrics
        
        # === –®–ê–ì 4: –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –Ø–≥–µ—Ä–æ–º ===
        step4_results, step4_metrics = self._measure_performance(
            self._execute_step4,
            loaded_data,
            step_name="step4_yager"
        )
        iteration_results["step4"] = step4_results
        iteration_results["performance"]["step4"] = step4_metrics
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏—Ç–µ—Ä–∞—Ü–∏–∏
        iteration_results["performance"]["total"] = {
            "time_total_ms": sum(
                step["time_ms"] for step in iteration_results["performance"].values() 
                if isinstance(step, dict) and "time_ms" in step
            ),
            "memory_peak_mb": max(
                step.get("memory_peak_mb", 0) for step in iteration_results["performance"].values()
                if isinstance(step, dict)
            )
        }
        
        return iteration_results
    
    def _execute_step1(self, loaded_data: Any) -> Dict[str, Any]:
        """–®–∞–≥ 1: –ò—Å—Ö–æ–¥–Ω—ã–µ Belief/Plausibility –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞"""
        frame_elements = self.adapter.get_frame_of_discernment(loaded_data)
        sources_count = self.adapter.get_sources_count(loaded_data)
        
        results = {
            "frame_elements": frame_elements,
            "sources": []
        }
        
        # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞ –≤—ã—á–∏—Å–ª—è–µ–º Belief –∏ Plausibility
        for i in range(sources_count):
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
            source_data = self._get_source_data(loaded_data, i)
            
            source_results = {
                "source_id": f"source_{i+1}",
                "beliefs": {},
                "plausibilities": {}
            }
            
            # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
            for element in frame_elements:
                belief = self.adapter.calculate_belief(source_data, element)
                plausibility = self.adapter.calculate_plausibility(source_data, element)
                
                source_results["beliefs"][f"{{{element}}}"] = belief
                source_results["plausibilities"][f"{{{element}}}"] = plausibility
            
            # –î–ª—è –≤—Å–µ–≥–æ —Ñ—Ä–µ–π–º–∞ (Œ©)
            omega = "{" + ",".join(sorted(frame_elements)) + "}"
            source_results["beliefs"][omega] = self.adapter.calculate_belief(source_data, frame_elements)  # Bel(Œ©) = 1.0
            source_results["plausibilities"][omega] = self.adapter.calculate_plausibility(source_data, frame_elements)  # Pl(Œ©) = 1.0

            results["sources"].append(source_results)
        
        return results
    
    def _execute_step2(self, loaded_data: Any) -> Dict[str, Any]:
        """–®–∞–≥ 2: –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –ø–æ –ø—Ä–∞–≤–∏–ª—É –î–µ–º–ø—Å—Ç–µ—Ä–∞"""
        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        combined_bpa_str = self.adapter.combine_sources_dempster(loaded_data)
        
        # –ö–û–ù–í–ï–†–¢–ò–†–£–ï–ú —Å—Ç—Ä–æ–∫–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç –Ω–∞—à–µ–≥–æ –∞–¥–∞–ø—Ç–µ—Ä–∞
        combined_bpa = self._convert_string_bpa_to_frozenset(combined_bpa_str)
        
        # –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º BPA –¥–ª—è –≤—ã—á–∏—Å–ª–µ–Ω–∏—è Belief/Plausibility
        combined_data = self._create_combined_data(loaded_data, combined_bpa)
        
        frame_elements = self.adapter.get_frame_of_discernment(loaded_data)
        
        results = {
            "combined_bpa": combined_bpa_str,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å—Ç—Ä–æ–∫–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
            "beliefs": {},
            "plausibilities": {}
        }
        
        # –î–ª—è –∫–∞–∂–¥–æ–≥–æ –æ–¥–∏–Ω–æ—á–Ω–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
        for element in frame_elements:
            belief = self.adapter.calculate_belief(combined_data, element)
            plausibility = self.adapter.calculate_plausibility(combined_data, element)
            
            results["beliefs"][f"{{{element}}}"] = belief
            results["plausibilities"][f"{{{element}}}"] = plausibility
        
        # –î–ª—è –≤—Å–µ–≥–æ —Ñ—Ä–µ–π–º–∞
        omega = "{" + ",".join(sorted(frame_elements)) + "}"
        results["beliefs"][omega] = self.adapter.calculate_belief(combined_data, frame_elements)
        results["plausibilities"][omega] = self.adapter.calculate_plausibility(combined_data, frame_elements)
        
        return results
    
    def _execute_step3(self, loaded_data: Any, alphas: List[float]) -> Dict[str, Any]:
        """–®–∞–≥ 3: –î–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ + –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –î–µ–º–ø—Å—Ç–µ—Ä–æ–º"""
        # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
        sources_count = self.adapter.get_sources_count(loaded_data)
        
        # –ü—Ä–∏–º–µ–Ω—è–µ–º –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫ –∫–∞–∂–¥–æ–º—É –∏—Å—Ç–æ—á–Ω–∏–∫—É —Å –µ–≥–æ alpha
        discounted_bpas_str = []
        for i in range(sources_count):
            # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
            source_data = self._get_source_data(loaded_data, i)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å alpha –¥–ª—è —ç—Ç–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
            alpha = alphas[i] if i < len(alphas) else 0.1
            
            # –î–ª—è –ø—Ä–∏–º–µ–Ω–µ–Ω–∏—è –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –∫ –æ–¥–Ω–æ–º—É –∏—Å—Ç–æ—á–Ω–∏–∫—É
            discounted_list = self.adapter.apply_discounting(source_data, alpha)
            
            if discounted_list and len(discounted_list) > 0:
                discounted_bpas_str.append(discounted_list[0])
            else:
                # –ï—Å–ª–∏ –Ω–µ –ø–æ–ª—É—á–∏–ª–æ—Å—å, –∏—Å–ø–æ–ª—å–∑—É–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–π BPA
                original_bpa = self._extract_bpa_from_source(loaded_data, i)
                discounted_bpas_str.append(original_bpa)
        
        # –ö–û–ù–í–ï–†–¢–ò–†–£–ï–ú —Å—Ç—Ä–æ–∫–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç frozenset
        discounted_bpas = [self._convert_string_bpa_to_frozenset(bpa_str) 
                          for bpa_str in discounted_bpas_str]
        
        # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç —Å –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
        discounted_data = self._create_discounted_data(loaded_data, discounted_bpas)
        
        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
        combined_bpa_str = self.adapter.combine_sources_dempster(discounted_data)
        combined_bpa = self._convert_string_bpa_to_frozenset(combined_bpa_str)
        
        # –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º BPA
        combined_data = self._create_combined_data(discounted_data, combined_bpa)
        
        frame_elements = self.adapter.get_frame_of_discernment(loaded_data)
        
        results = {
            "discounted_bpas": discounted_bpas_str,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å—Ç—Ä–æ–∫–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
            "combined_bpa": combined_bpa_str,
            "beliefs": {},
            "plausibilities": {}
        }
        
        # –î–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
        for element in frame_elements:
            belief = self.adapter.calculate_belief(combined_data, element)
            plausibility = self.adapter.calculate_plausibility(combined_data, element)
            
            results["beliefs"][f"{{{element}}}"] = belief
            results["plausibilities"][f"{{{element}}}"] = plausibility
        
        # –î–ª—è –≤—Å–µ–≥–æ —Ñ—Ä–µ–π–º–∞
        omega = "{" + ",".join(sorted(frame_elements)) + "}"
        results["beliefs"][omega] = self.adapter.calculate_belief(combined_data, frame_elements)
        results["plausibilities"][omega] = self.adapter.calculate_plausibility(combined_data, frame_elements)
        
        return results
    
    def _execute_step4(self, loaded_data: Any) -> Dict[str, Any]:
        """–®–∞–≥ 4: –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –≤—Å–µ—Ö –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ –ø–æ –ø—Ä–∞–≤–∏–ª—É –Ø–≥–µ—Ä–∞"""
        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –≤—Å–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏ –ø–æ –Ø–≥–µ—Ä—É
        combined_bpa_str = self.adapter.combine_sources_yager(loaded_data)
        
        # –ö–û–ù–í–ï–†–¢–ò–†–£–ï–ú —Å—Ç—Ä–æ–∫–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç –≤ —Ñ–æ—Ä–º–∞—Ç frozenset
        combined_bpa = self._convert_string_bpa_to_frozenset(combined_bpa_str)
        
        # –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º BPA
        combined_data = self._create_combined_data(loaded_data, combined_bpa)
        
        frame_elements = self.adapter.get_frame_of_discernment(loaded_data)
        
        results = {
            "combined_bpa": combined_bpa_str,  # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ —Å—Ç—Ä–æ–∫–æ–≤–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
            "beliefs": {},
            "plausibilities": {}
        }
        
        # –î–ª—è –∫–∞–∂–¥–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
        for element in frame_elements:
            belief = self.adapter.calculate_belief(combined_data, element)
            plausibility = self.adapter.calculate_plausibility(combined_data, element)
            
            results["beliefs"][f"{{{element}}}"] = belief
            results["plausibilities"][f"{{{element}}}"] = plausibility
        
        # –î–ª—è –≤—Å–µ–≥–æ —Ñ—Ä–µ–π–º–∞
        omega = "{" + ",".join(sorted(frame_elements)) + "}"
        results["beliefs"][omega] = self.adapter.calculate_belief(combined_data, frame_elements)
        results["plausibilities"][omega] = self.adapter.calculate_plausibility(combined_data, frame_elements)
        
        return results
    
    def _convert_string_bpa_to_frozenset(self, bpa_str: Dict[str, float]) -> Dict[frozenset, float]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç BPA –∏–∑ —Å—Ç—Ä–æ–∫–æ–≤–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç frozenset."""
        if not bpa_str:
            return {}
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–µ—Ç —É–∂–µ –≤ –Ω—É–∂–Ω–æ–º —Ñ–æ—Ä–º–∞—Ç–µ
        first_key = next(iter(bpa_str.keys()))
        if isinstance(first_key, frozenset):
            return bpa_str # type: ignore
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º —Å—Ç—Ä–æ–∫–∏ –≤–æ frozenset
        bpa_frozenset: Dict[frozenset, float] = {}
        for subset_str, mass in bpa_str.items():
            if subset_str == "{}":
                subset = frozenset()
            else:
                elements = subset_str.strip("{}").split(",")
                if elements == ['']:
                    subset = frozenset()
                else:
                    subset = frozenset(elements)
            bpa_frozenset[subset] = mass
        
        return bpa_frozenset
        
    def _measure_performance(self, func: Callable, *args, 
                           step_name: str = "", **kwargs) -> Tuple[Any, Dict[str, float]]:
        """
        –ò–∑–º–µ—Ä—è–µ—Ç –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è —Ñ—É–Ω–∫—Ü–∏–∏.
        
        Returns:
            (—Ä–µ–∑—É–ª—å—Ç–∞—Ç_—Ñ—É–Ω–∫—Ü–∏–∏, –º–µ—Ç—Ä–∏–∫–∏_–ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏)
        """
        metrics = {}
        
        # –ù–∞—á–∏–Ω–∞–µ–º –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏–µ –ø–∞–º—è—Ç–∏
        tracemalloc.start()
        snapshot1 = tracemalloc.take_snapshot()
        
        # –ò–∑–º–µ—Ä—è–µ–º –≤—Ä–µ–º—è CPU
        process = psutil.Process()
        cpu_before = process.cpu_percent(interval=None)
        
        # –í—Ä–µ–º—è –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        start_time = time.perf_counter()
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º —Ñ—É–Ω–∫—Ü–∏—é
        try:
            result = func(*args, **kwargs)
        except Exception as e:
            # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—à–∏–±–∫—É –≤ –º–µ—Ç—Ä–∏–∫–∞—Ö
            result = {"error": str(e)}
            metrics["error"] = str(e)
        
        # –ö–æ–Ω–µ—Ü –∏–∑–º–µ—Ä–µ–Ω–∏—è –≤—Ä–µ–º–µ–Ω–∏
        end_time = time.perf_counter()
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ CPU –ø–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        cpu_after = process.cpu_percent(interval=None)
        
        # –ü–∞–º—è—Ç—å –ø–æ—Å–ª–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è
        snapshot2 = tracemalloc.take_snapshot()
        tracemalloc.stop()
        
        # –í—ã—á–∏—Å–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        metrics["time_ms"] = (end_time - start_time) * 1000  # –º–∏–ª–ª–∏—Å–µ–∫—É–Ω–¥—ã
        
        # –ü–æ—Ç—Ä–µ–±–ª–µ–Ω–∏–µ –ø–∞–º—è—Ç–∏
        memory_stats = snapshot2.compare_to(snapshot1, 'lineno')
        memory_usage = sum(stat.size for stat in memory_stats)
        metrics["memory_peak_mb"] = memory_usage / 1024 / 1024
        
        # –ó–∞–≥—Ä—É–∑–∫–∞ CPU
        metrics["cpu_usage_percent"] = max(0, cpu_after - cpu_before)
        
        return result, metrics
    
    def _get_source_data(self, loaded_data: Any, source_index: int) -> Any:
        """
        –ò–∑–≤–ª–µ–∫–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞.
        """
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Ñ–æ—Ä–º–∞—Ç –¥–∞–Ω–Ω—ã—Ö –Ω–∞—à–µ–≥–æ –∞–¥–∞–ø—Ç–µ—Ä–∞
        if isinstance(loaded_data, dict) and 'bpas' in loaded_data:
            # –°–æ–∑–¥–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Ç–æ–ª—å–∫–æ —Å –æ–¥–Ω–∏–º BPA
            single_source_data = loaded_data.copy()
            if source_index < len(loaded_data['bpas']):
                single_source_data['bpas'] = [loaded_data['bpas'][source_index]]
            else:
                single_source_data['bpas'] = [{}]
            return single_source_data
        
        # –ï—Å–ª–∏ –∞–¥–∞–ø—Ç–µ—Ä –∏–º–µ–µ—Ç –¥—Ä—É–≥–æ–π —Ñ–æ—Ä–º–∞—Ç, –æ—Å—Ç–∞–≤–ª—è–µ–º –∫–∞–∫ –µ—Å—Ç—å
        return loaded_data
    
    def _extract_bpa_from_source(self, loaded_data: Any, source_index: int) -> Dict[str, float]:
        """–ò–∑–≤–ª–µ–∫–∞–µ—Ç BPA –∏–∑ –∏—Å—Ç–æ—á–Ω–∏–∫–∞."""
        source_data = self._get_source_data(loaded_data, source_index)
        
        # –ü—ã—Ç–∞–µ–º—Å—è –∏–∑–≤–ª–µ—á—å BPA
        if isinstance(source_data, dict) and 'bpas' in source_data and source_data['bpas']:
            bpa = source_data['bpas'][0]
            # –ï—Å–ª–∏ BPA –≤ —Ñ–æ—Ä–º–∞—Ç–µ frozenset, –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –≤ —Å—Ç—Ä–æ–∫–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç
            if bpa and isinstance(next(iter(bpa.keys())), frozenset):
                return self._convert_frozenset_bpa_to_string(bpa)
        
        return {}
    
    def _convert_frozenset_bpa_to_string(self, bpa_frozenset: Dict[frozenset, float]) -> Dict[str, float]:
        """–ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç BPA –∏–∑ —Ñ–æ—Ä–º–∞—Ç–∞ frozenset –≤ —Å—Ç—Ä–æ–∫–æ–≤—ã–π —Ñ–æ—Ä–º–∞—Ç."""
        if not bpa_frozenset:
            return {}
        
        bpa_str = {}
        for subset, mass in bpa_frozenset.items():
            if not subset:
                subset_str = "{}"
            else:
                subset_str = "{" + ",".join(sorted(subset)) + "}"
            bpa_str[subset_str] = mass
        
        return bpa_str
    
    def _create_combined_data(self, original_data: Any, 
                            combined_bpa: Dict[frozenset, float]) -> Any:
        """–°–æ–∑–¥–∞–µ—Ç –æ–±—ä–µ–∫—Ç –¥–∞–Ω–Ω—ã—Ö —Å –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º BPA."""
        if isinstance(original_data, dict):
            combined_data = original_data.copy()
            combined_data['bpas'] = [combined_bpa]
            return combined_data
        
        return original_data
    
    def _create_discounted_data(self, original_data: Any,
                              discounted_bpas: List[Dict[frozenset, float]]) -> Any:
        """–°–æ–∑–¥–∞–µ—Ç –æ–±—ä–µ–∫—Ç –¥–∞–Ω–Ω—ã—Ö —Å –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ BPA."""
        if isinstance(original_data, dict):
            discounted_data = original_data.copy()
            discounted_data['bpas'] = discounted_bpas
            return discounted_data
        
        return original_data
    
    def _aggregate_iteration_results(self, iterations: List[Dict]) -> Dict[str, Any]:
        """–ê–≥—Ä–µ–≥–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Å–µ—Ö –∏—Ç–µ—Ä–∞—Ü–∏–π."""
        if not iterations:
            return {}
        
        aggregated = {
            "performance": {}
        }
        
        # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –º–µ—Ç—Ä–∏–∫ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏
        for step in ["step1", "step2", "step3", "step4"]:
            step_times = [
                iteration["performance"][step]["time_ms"]
                for iteration in iterations
                if step in iteration.get("performance", {}) and "error" not in iteration["performance"][step]
            ]
            
            if step_times:
                aggregated["performance"][step] = {
                    "time_ms": {
                        "min": min(step_times),
                        "max": max(step_times),
                        "mean": statistics.mean(step_times),
                        "median": statistics.median(step_times),
                        "std": statistics.stdev(step_times) if len(step_times) > 1 else 0
                    }
                }
        
        # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –∏—Ç–æ–≥–æ–≤–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏
        total_times = [
            iteration["performance"]["total"]["time_total_ms"]
            for iteration in iterations
            if "total" in iteration.get("performance", {})
        ]
        
        if total_times:
            aggregated["performance"]["total"] = {
                "time_total_ms": {
                    "min": min(total_times),
                    "max": max(total_times),
                    "mean": statistics.mean(total_times),
                    "median": statistics.median(total_times),
                    "std": statistics.stdev(total_times) if len(total_times) > 1 else 0
                }
            }
        
        # –ê–≥—Ä–µ–≥–∞—Ü–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –≤—ã—á–∏—Å–ª–µ–Ω–∏–π
        if iterations:
            aggregated["results"] = iterations[-1]
        
        return aggregated
    
    def _save_test_results(self, test_results: Dict[str, Any], test_name: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∞ –≤ —Ñ–∞–π–ª—ã."""
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        filename = f"{test_name}_{self.run_id}.json"
        filepath = os.path.join(self.run_dir, "raw", filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(test_results, f, indent=2, ensure_ascii=False)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á–µ—Ç
        self._create_short_report(test_results, test_name)
    
    def _create_short_report(self, test_results: Dict[str, Any], test_name: str):
        """–°–æ–∑–¥–∞–µ—Ç –∫—Ä–∞—Ç–∫–∏–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç."""
        metadata = test_results["metadata"]
        aggregated = test_results.get("aggregated", {})
        
        report_lines = [
            "=" * 70,
            f"üìä –û–¢–ß–ï–¢ –ü–û –¢–ï–°–¢–£: {test_name}",
            f"üìÖ –í—Ä–µ–º—è: {metadata['timestamp']}",
            f"üìö –ê–¥–∞–ø—Ç–µ—Ä: {metadata['adapter']}",
            f"üßÆ –§—Ä–µ–π–º: {metadata['frame_size']} —ç–ª–µ–º–µ–Ω—Ç–æ–≤",
            f"üìà –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {metadata['sources_count']}",
            f"üîÑ –ò—Ç–µ—Ä–∞—Ü–∏–π: {metadata['iterations']}",
            "=" * 70,
            ""
        ]
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –Ω–∞–ª–∏—á–∏–µ –æ—à–∏–±–æ–∫
        has_errors = False
        for iteration in test_results.get("iterations", []):
            for step in ["step1", "step2", "step3", "step4"]:
                if step in iteration.get("performance", {}) and "error" in iteration["performance"][step]:
                    has_errors = True
                    report_lines.append(f"‚ùå –û—à–∏–±–∫–∞ –≤ {step}: {iteration['performance'][step]['error']}")
        
        if has_errors:
            report_lines.append("\nüìà –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨ (–µ—Å–ª–∏ –¥–æ—Å—Ç—É–ø–Ω–æ):")
        else:
            report_lines.append("üìà –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨:")
        
        report_lines.append("")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –ø–æ —à–∞–≥–∞–º
        perf = aggregated.get("performance", {})
        for step_name, step_data in perf.items():
            if step_name == "total":
                continue
                
            time_data = step_data.get("time_ms", {})
            report_lines.append(f"  {step_name.upper():20}:")
            report_lines.append(f"    –í—Ä–µ–º—è (–º—Å): {time_data.get('mean', 0):.2f} "
                              f"(min: {time_data.get('min', 0):.2f}, "
                              f"max: {time_data.get('max', 0):.2f})")
        
        # –ò—Ç–æ–≥–æ–≤–æ–µ –≤—Ä–µ–º—è
        if "total" in perf:
            total_time = perf["total"].get("time_total_ms", {})
            report_lines.append(f"\n  {'–ò–¢–û–ì–û':20}:")
            report_lines.append(f"    –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time.get('mean', 0):.2f} –º—Å")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        report_filename = f"{test_name}_{self.run_id}_report.txt"
        report_path = os.path.join(self.run_dir, "raw", report_filename)
        
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("\n".join(report_lines))
    
    def run_test_suite(self, test_dir: str, 
                      iterations: int = 3,
                      max_tests: Optional[int] = None) -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –Ω–∞–±–æ—Ä —Ç–µ—Å—Ç–æ–≤ –∏–∑ –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏–∏.
        
        Args:
            test_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è —Å —Ç–µ—Å—Ç–æ–≤—ã–º–∏ —Ñ–∞–π–ª–∞–º–∏ (.json)
            iterations: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ —Ç–µ—Å—Ç–∞
            max_tests: –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤ –¥–ª—è –∑–∞–ø—É—Å–∫–∞
            
        Returns:
            –ê–≥—Ä–µ–≥–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ –≤—Å–µ–º —Ç–µ—Å—Ç–∞–º
        """
        print(f"\nüöÄ –ó–ê–ü–£–°–ö –ù–ê–ë–û–†–ê –¢–ï–°–¢–û–í")
        print(f"üìÅ –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {test_dir}")
        print(f"üîÑ –ò—Ç–µ—Ä–∞—Ü–∏–π –Ω–∞ —Ç–µ—Å—Ç: {iterations}")
        
        # –ù–∞—Ö–æ–¥–∏–º –≤—Å–µ JSON —Ñ–∞–π–ª—ã
        test_files = []
        for root, dirs, files in os.walk(test_dir):
            for file in files:
                if file.endswith('.json') and file != "statistics.json":  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º —Ñ–∞–π–ª —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
                    test_files.append(os.path.join(root, file))
        
        # –û–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if max_tests and max_tests < len(test_files):
            test_files = test_files[:max_tests]
        
        print(f"üìÑ –ù–∞–π–¥–µ–Ω–æ —Ç–µ—Å—Ç–æ–≤: {len(test_files)}")
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–∞–∂–¥—ã–π —Ç–µ—Å—Ç
        successful_tests = 0
        failed_tests = 0
        
        for i, test_file in enumerate(test_files, 1):
            test_name = os.path.splitext(os.path.basename(test_file))[0]
            print(f"\n[{i}/{len(test_files)}] –¢–µ—Å—Ç: {test_name}")
            
            try:
                # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
                with open(test_file, 'r', encoding='utf-8') as f:
                    test_data = json.load(f)
                
                # –ü—Ä–æ–≤–µ—Ä—è–µ–º –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–æ–ª—è
                if "frame_of_discernment" not in test_data or "bba_sources" not in test_data:
                    print(f"   ‚ùå –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç —Ç–µ—Å—Ç–∞ {test_name}")
                    failed_tests += 1
                    continue
                
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º alphas –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞
                sources_count = len(test_data.get("bba_sources", []))
                alphas = [0.1] * sources_count  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é 0.1 –¥–ª—è –≤—Å–µ—Ö
                
                # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç
                self.run_test(
                    test_data=test_data,
                    test_name=test_name,
                    iterations=iterations,
                    alphas=alphas
                )
                
                successful_tests += 1
                
            except json.JSONDecodeError as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ JSON –≤ —Ñ–∞–π–ª–µ {test_name}: {e}")
                failed_tests += 1
            except KeyError as e:
                print(f"   ‚ùå –û—Ç—Å—É—Ç—Å—Ç–≤—É–µ—Ç –ø–æ–ª–µ –≤ —Ç–µ—Å—Ç–µ {test_name}: {e}")
                failed_tests += 1
            except Exception as e:
                print(f"   ‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–∏ —Ç–µ—Å—Ç–∞ {test_name}: {e}")
                failed_tests += 1
        
        # –°–æ–∑–¥–∞–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç –ø–æ –≤—Å–µ–º —Ç–µ—Å—Ç–∞–º
        summary = self._create_summary_report()
        
        print(f"\n‚úÖ –í–´–ü–û–õ–ù–ï–ù–ò–ï –ó–ê–í–ï–†–®–ï–ù–û")
        print(f"üìä –£—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤: {successful_tests}/{len(test_files)}")
        print(f"üìä –ù–µ—É–¥–∞—á–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤: {failed_tests}/{len(test_files)}")
        print(f"üìä –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {self.run_dir}")
        
        return summary
    
    def _create_summary_report(self) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–µ—Ç –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç –ø–æ –≤—Å–µ–º –≤—ã–ø–æ–ª–Ω–µ–Ω–Ω—ã–º —Ç–µ—Å—Ç–∞–º."""
        if not self.results:
            return {}
        
        summary = {
            "metadata": {
                "adapter": self.adapter_name,
                "total_tests": len(self.results),
                "run_id": self.run_id,
                "timestamp": datetime.now().isoformat()
            },
            "tests": [],
            "statistics": {}
        }
        
        # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –≤—Å–µ–º —Ç–µ—Å—Ç–∞–º
        frame_sizes = []
        source_counts = []
        step_times = {
            "step1": [],
            "step2": [],
            "step3": [],
            "step4": [],
            "total": []
        }
        
        successful_tests = 0
        
        for test_result in self.results:
            metadata = test_result["metadata"]
            aggregated = test_result.get("aggregated", {})
            perf = aggregated.get("performance", {})
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º, –±—ã–ª –ª–∏ —Ç–µ—Å—Ç —É—Å–ø–µ—à–Ω—ã–º
            test_successful = True
            for iteration in test_result.get("iterations", []):
                for step in ["step1", "step2", "step3", "step4"]:
                    if step in iteration.get("performance", {}) and "error" in iteration["performance"][step]:
                        test_successful = False
                        break
                if not test_successful:
                    break
            
            if test_successful:
                successful_tests += 1
            
            # –î–æ–±–∞–≤–ª—è–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ—Å—Ç–µ
            test_info = {
                "test_name": metadata["test_name"],
                "frame_size": metadata["frame_size"],
                "sources_count": metadata["sources_count"],
                "successful": test_successful,
                "performance": perf
            }
            summary["tests"].append(test_info)
            
            # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —Ç–æ–ª—å–∫–æ –¥–ª—è —É—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤
            if test_successful:
                frame_sizes.append(metadata["frame_size"])
                source_counts.append(metadata["sources_count"])
                
                # –í—Ä–µ–º—è –ø–æ —à–∞–≥–∞–º
                for step in step_times.keys():
                    if step in perf:
                        time_data = perf[step].get("time_ms", {})
                        if "mean" in time_data:
                            step_times[step].append(time_data["mean"])
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
        summary["statistics"] = {
            "successful_tests": successful_tests,
            "total_tests": len(self.results),
            "success_rate": successful_tests / len(self.results) * 100 if self.results else 0,
            "frame_size": {
                "min": min(frame_sizes) if frame_sizes else 0,
                "max": max(frame_sizes) if frame_sizes else 0,
                "mean": statistics.mean(frame_sizes) if frame_sizes else 0
            },
            "sources_count": {
                "min": min(source_counts) if source_counts else 0,
                "max": max(source_counts) if source_counts else 0,
                "mean": statistics.mean(source_counts) if source_counts else 0
            },
            "performance": {}
        }
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –≤—Ä–µ–º–µ–Ω–∏
        for step, times in step_times.items():
            if times:
                summary["statistics"]["performance"][step] = {
                    "time_ms": {
                        "min": min(times),
                        "max": max(times),
                        "mean": statistics.mean(times),
                        "median": statistics.median(times),
                        "std": statistics.stdev(times) if len(times) > 1 else 0
                    }
                }
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Ç–æ–≥–æ–≤—ã–π –æ—Ç—á–µ—Ç
        summary_file = os.path.join(self.run_dir, "aggregated", "summary.json")
        with open(summary_file, 'w', encoding='utf-8') as f:
            json.dump(summary, f, indent=2, ensure_ascii=False)
        
        # –°–æ–∑–¥–∞–µ–º —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç
        self._create_final_text_report(summary)
        
        return summary
    
    def _create_final_text_report(self, summary: Dict[str, Any]):
        """–°–æ–∑–¥–∞–µ—Ç —Ñ–∏–Ω–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –æ—Ç—á–µ—Ç."""
        metadata = summary["metadata"]
        stats = summary["statistics"]
        
        report_lines = [
            "=" * 70,
            f"üìä –ò–¢–û–ì–û–í–´–ô –û–¢–ß–ï–¢ –ü–û –ë–ï–ù–ß–ú–ê–†–ö–£",
            f"üìÖ –í—Ä–µ–º—è: {metadata['timestamp']}",
            f"üìö –ê–¥–∞–ø—Ç–µ—Ä: {metadata['adapter']}",
            f"üß™ –í—Å–µ–≥–æ —Ç–µ—Å—Ç–æ–≤: {metadata['total_tests']}",
            f"‚úÖ –£—Å–ø–µ—à–Ω—ã—Ö —Ç–µ—Å—Ç–æ–≤: {stats.get('successful_tests', 0)}",
            f"üìà –£—Å–ø–µ—à–Ω–æ—Å—Ç—å: {stats.get('success_rate', 0):.1f}%",
            "=" * 70,
            "",
            "üìà –°–¢–ê–¢–ò–°–¢–ò–ö–ê:",
            ""
        ]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —Ñ—Ä–µ–π–º–∞–º
        frame_stats = stats.get("frame_size", {})
        report_lines.append(f"  –†–∞–∑–º–µ—Ä —Ñ—Ä–µ–π–º–∞ (—É—Å–ø–µ—à–Ω—ã–µ —Ç–µ—Å—Ç—ã):")
        report_lines.append(f"    –ú–∏–Ω–∏–º–∞–ª—å–Ω—ã–π: {frame_stats.get('min', 0)}")
        report_lines.append(f"    –ú–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–π: {frame_stats.get('max', 0)}")
        report_lines.append(f"    –°—Ä–µ–¥–Ω–∏–π: {frame_stats.get('mean', 0):.1f}")
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
        source_stats = stats.get("sources_count", {})
        report_lines.append(f"\n  –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤ (—É—Å–ø–µ—à–Ω—ã–µ —Ç–µ—Å—Ç—ã):")
        report_lines.append(f"    –ú–∏–Ω–∏–º–∞–ª—å–Ω–æ–µ: {source_stats.get('min', 0)}")
        report_lines.append(f"    –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ: {source_stats.get('max', 0)}")
        report_lines.append(f"    –°—Ä–µ–¥–Ω–µ–µ: {source_stats.get('mean', 0):.1f}")
        
        # –ü—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å –ø–æ —à–∞–≥–∞–º
        perf_stats = stats.get("performance", {})
        if perf_stats:
            report_lines.append(f"\n  –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨ (—Å—Ä–µ–¥–Ω–µ–µ –≤—Ä–µ–º—è, –º—Å):")
            
            step_names = {
                "step1": "–ò—Å—Ö–æ–¥–Ω—ã–µ Bel/Pl",
                "step2": "–î–µ–º–ø—Å—Ç–µ—Ä",
                "step3": "–î–∏—Å–∫–æ–Ω—Ç+–î–µ–º–ø—Å—Ç–µ—Ä",
                "step4": "–Ø–≥–µ—Ä",
                "total": "–ò–¢–û–ì–û"
            }
            
            for step, step_name in step_names.items():
                if step in perf_stats:
                    time_data = perf_stats[step].get("time_ms", {})
                    mean_time = time_data.get("mean", 0)
                    report_lines.append(f"    {step_name:20}: {mean_time:.2f} –º—Å")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        report_file = os.path.join(self.run_dir, "aggregated", "final_report.txt")
        with open(report_file, 'w', encoding='utf-8') as f:
            f.write("\n".join(report_lines))
        
        # –¢–∞–∫–∂–µ –≤—ã–≤–æ–¥–∏–º –≤ –∫–æ–Ω—Å–æ–ª—å
        print("\n" + "\n".join(report_lines))