# runners/universal_runner.py
"""
–£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ä–∞–Ω–Ω–µ—Ä –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫ –î–µ–º–ø—Å—Ç–µ—Ä–∞-–®–µ–π—Ñ–µ—Ä–∞.
–í—ã–ø–æ–ª–Ω—è–µ—Ç —Ä–∞—Å—á–µ—Ç—ã —Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Ñ—Ä–µ–π–º–∞ –∏ –≤—Å–µ–≥–æ Œ©.
"""

import os
import json
import time
import gc
import psutil
import statistics
from datetime import datetime
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple, Union
import itertools

# –ò–º–ø–æ—Ä—Ç–∏—Ä—É–µ–º –±–∞–∑–æ–≤—ã–π –∞–¥–∞–ø—Ç–µ—Ä –¥–ª—è type hints
from ..adapters.base_adapter import BaseDempsterShaferAdapter


class UniversalBenchmarkRunner:
    """
    –£–Ω–∏–≤–µ—Ä—Å–∞–ª—å–Ω—ã–π —Ä–∞–Ω–Ω–µ—Ä –¥–ª—è —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –ª—é–±–æ–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ –î–µ–º–ø—Å—Ç–µ—Ä–∞-–®–µ–π—Ñ–µ—Ä–∞.
    
    –í—ã–ø–æ–ª–Ω—è–µ—Ç —Ä–∞—Å—á–µ—Ç—ã —Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ —Ñ—Ä–µ–π–º–∞ –∏ –≤—Å–µ–≥–æ Œ©.
    """
    
    def __init__(self, adapter: BaseDempsterShaferAdapter, library_name: str):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞–Ω–Ω–µ—Ä–∞.
        
        Args:
            adapter: –≠–∫–∑–µ–º–ø–ª—è—Ä –∞–¥–∞–ø—Ç–µ—Ä–∞ –¥–ª—è —Ç–µ—Å—Ç–∏—Ä—É–µ–º–æ–π –±–∏–±–ª–∏–æ—Ç–µ–∫–∏
            library_name: –ò–º—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ (–¥–ª—è –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è)
        """
        self.adapter = adapter
        self.library_name = library_name
        self.process = psutil.Process()
        self.results_dir = None
        self.current_run_dir = None
        
    def run_test_suite(self, test_files: List[str], 
                      output_dir: str = "results",
                      discount_factor: float = 0.1,
                      repetitions: int = 1) -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –ø–æ–ª–Ω—ã–π –Ω–∞–±–æ—Ä —Ç–µ—Å—Ç–æ–≤ —Å –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è–º–∏.
        
        Args:
            test_files: –°–ø–∏—Å–æ–∫ –ø—É—Ç–µ–π –∫ —Ç–µ—Å—Ç–æ–≤—ã–º —Ñ–∞–π–ª–∞–º
            output_dir: –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            discount_factor: –ö–æ—ç—Ñ—Ñ–∏—Ü–∏–µ–Ω—Ç –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            repetitions: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π –∫–∞–∂–¥–æ–≥–æ —Ç–µ—Å—Ç–∞
            
        Returns:
            –°–≤–æ–¥–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        """
        print(f"üöÄ –ó–∞–ø—É—Å–∫ —Ç–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏—è –±–∏–±–ª–∏–æ—Ç–µ–∫–∏: {self.library_name}")
        print(f"üìä –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–µ—Å—Ç–æ–≤: {len(test_files)}")
        print(f"üîÑ –ü–æ–≤—Ç–æ—Ä–µ–Ω–∏–π –∫–∞–∂–¥–æ–≥–æ —Ç–µ—Å—Ç–∞: {repetitions}")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã –±—É–¥—É—Ç —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {output_dir}")
        print("-" * 70)
        
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        self._create_results_directory(output_dir)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é
        self._save_configuration(test_files, discount_factor, repetitions)
        
        all_results = []
        total_time = 0
        
        # –ó–∞–ø—É—Å–∫–∞–µ–º –∫–∞–∂–¥—ã–π —Ç–µ—Å—Ç
        for i, test_file in enumerate(test_files, 1):
            test_name = Path(test_file).stem
            print(f"–¢–µ—Å—Ç {i:3d}/{len(test_files)}: {test_name:<30}", end="", flush=True)
            
            try:
                # –ó–∞–ø—É—Å–∫–∞–µ–º —Ç–µ—Å—Ç —Å –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è–º–∏
                test_results = self._run_single_test_with_repetitions(
                    test_file, discount_factor, repetitions
                )
                
                # –°–æ–±–∏—Ä–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É –ø–æ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è–º
                aggregated = self._aggregate_repetitions(test_results)
                all_results.append(aggregated)
                
                total_time += aggregated['timings']['total_time']['avg']
                
                # –í—ã–≤–æ–¥–∏–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
                avg_time = aggregated['timings']['total_time']['avg']
                std_time = aggregated['timings']['total_time']['std']
                print(f" ‚úì {avg_time:.3f} ¬± {std_time:.3f} —Å–µ–∫")
                
            except Exception as e:
                print(f" ‚úó –û–®–ò–ë–ö–ê: {str(e)}")
                self._save_error(test_file, str(e))
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Å–≤–æ–¥–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        summary = self._create_summary(all_results, total_time)
        self._save_summary(summary)
        
        # –°–æ–∑–¥–∞–µ–º —Å–∏–º–ª–∏–Ω–∫ latest
        self._create_latest_symlink()
        
        print("=" * 70)
        print(f"‚úÖ –¢–µ—Å—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∑–∞–≤–µ—Ä—à–µ–Ω–æ!")
        print(f"üìä –û–±—â–µ–µ –≤—Ä–µ–º—è: {total_time:.2f} —Å–µ–∫")
        print(f"üìÅ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {self.current_run_dir}")
        
        return summary
    
    def _run_single_test_with_repetitions(self, test_file: str, 
                                         discount_factor: float,
                                         repetitions: int) -> List[Dict[str, Any]]:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–¥–∏–Ω —Ç–µ—Å—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑.
        
        Returns:
            –°–ø–∏—Å–æ–∫ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏—è
        """
        test_results = []
        
        for rep in range(repetitions):
            result = self._run_single_test(
                test_file, 
                discount_factor,
                repetition=rep + 1
            )
            test_results.append(result)
        
        return test_results
    
    def _run_single_test(self, test_file: str, 
                        discount_factor: float,
                        repetition: int = 1) -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–¥–∏–Ω —Ç–µ—Å—Ç –ø–æ –ø–æ–ª–Ω–æ–π –º–µ—Ç–æ–¥–∏–∫–µ.
        –°—á–∏—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –¥–ª—è –æ—Ç–¥–µ–ª—å–Ω—ã—Ö —ç–ª–µ–º–µ–Ω—Ç–æ–≤ –∏ –≤—Å–µ–≥–æ Œ©.
        """
        # –°–æ–∑–¥–∞–µ–º –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ç–µ—Å—Ç–∞
        test_name = Path(test_file).stem
        test_dir = os.path.join(self.current_run_dir, "raw", test_name, f"rep_{repetition:03d}")
        os.makedirs(test_dir, exist_ok=True)
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º —Ç–µ—Å—Ç–æ–≤—ã–µ –¥–∞–Ω–Ω—ã–µ
        with open(test_file, 'r', encoding='utf-8') as f:
            dass_data = json.load(f)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        self._save_json(dass_data, os.path.join(test_dir, "input.json"))
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∑–∞–º–µ—Ä—ã
        timings = {}
        
        # 0. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö
        load_start = time.perf_counter()
        loaded_data = self.adapter.load_from_dass(dass_data)
        timings['load'] = time.perf_counter() - load_start
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ—Å—Ç–µ
        frame_elements = self.adapter.get_frame_of_discernment(loaded_data)
        frame_size = len(frame_elements)
        sources_count = self.adapter.get_sources_count(loaded_data)
        
        # –°–æ–±—ã—Ç–∏—è –¥–ª—è —Ä–∞—Å—á–µ—Ç–∞: –æ—Ç–¥–µ–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã –∏ –≤–µ—Å—å Œ©
        events_to_calculate = []
        
        # –û—Ç–¥–µ–ª—å–Ω—ã–µ —ç–ª–µ–º–µ–Ω—Ç—ã
        for element in frame_elements:
            events_to_calculate.append(f"{{{element}}}")
        
        # –í–µ—Å—å —Ñ—Ä–µ–π–º Œ©
        omega_event = "{" + ",".join(sorted(frame_elements)) + "}"
        events_to_calculate.append(omega_event)
        
        # –ü—É—Å—Ç–æ–µ –º–Ω–æ–∂–µ—Å—Ç–≤–æ (–¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏)
        empty_event = "{}"
        events_to_calculate.append(empty_event)
        
        # ==================== 1. –ò–°–•–û–î–ù–´–ï BPA (m1, m2...) ====================
        belief_by_source = []
        plausibility_by_source = []
        
        for source_idx in range(sources_count):
            source_data = self._create_source_data(loaded_data, source_idx)
            
            # Belief
            belief_start = time.perf_counter()
            source_belief = {}
            for event in events_to_calculate:
                try:
                    source_belief[event] = self.adapter.calculate_belief(source_data, event)
                except Exception as e:
                    source_belief[event] = 0.0
            timings[f'belief_source_{source_idx}'] = time.perf_counter() - belief_start
            
            # Plausibility
            plausibility_start = time.perf_counter()
            source_plausibility = {}
            for event in events_to_calculate:
                try:
                    source_plausibility[event] = self.adapter.calculate_plausibility(source_data, event)
                except Exception as e:
                    source_plausibility[event] = 0.0
            timings[f'plausibility_source_{source_idx}'] = time.perf_counter() - plausibility_start
            
            belief_by_source.append(source_belief)
            plausibility_by_source.append(source_plausibility)
        
        # ==================== 2. –î–ï–ú–ü–°–¢–ï–† (m1 ‚äï m2) ====================
        dempster_start = time.perf_counter()
        try:
            combined_bpa_dempster = self.adapter.combine_sources_dempster(loaded_data)
            
            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –¥–∞–Ω–Ω—ã—Ö —Å –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º BPA
            combined_data_dempster = {
                'frame': loaded_data.get('frame', set()),
                'bpa': self._parse_bpa_strings_to_frozenset(combined_bpa_dempster)
            }
            
            # Belief –ø–æ—Å–ª–µ –î–µ–º–ø—Å—Ç–µ—Ä–∞
            belief_dempster = {}
            for event in events_to_calculate:
                belief_dempster[event] = self.adapter.calculate_belief(combined_data_dempster, event)
            
            # Plausibility –ø–æ—Å–ª–µ –î–µ–º–ø—Å—Ç–µ—Ä–∞
            plausibility_dempster = {}
            for event in events_to_calculate:
                plausibility_dempster[event] = self.adapter.calculate_plausibility(combined_data_dempster, event)
                
        except ValueError as e:
            if "–ü–æ–ª–Ω—ã–π –∫–æ–Ω—Ñ–ª–∏–∫—Ç" in str(e) or "–∫–æ–Ω—Ñ–ª–∏–∫—Ç" in str(e).lower():
                # –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª–Ω–æ–≥–æ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞ - —ç—Ç–æ –Ω–æ—Ä–º–∞–ª—å–Ω–∞—è —Å–∏—Ç—É–∞—Ü–∏—è
                combined_bpa_dempster = {}
                belief_dempster = {event: 0.0 for event in events_to_calculate}
                plausibility_dempster = {event: 0.0 for event in events_to_calculate}
            else:
                raise
        except Exception as e:
            # –û–±—Ä–∞–±–æ—Ç–∫–∞ –¥—Ä—É–≥–∏—Ö –æ—à–∏–±–æ–∫
            combined_bpa_dempster = {}
            belief_dempster = {event: 0.0 for event in events_to_calculate}
            plausibility_dempster = {event: 0.0 for event in events_to_calculate}
        
        timings['dempster_combination'] = time.perf_counter() - dempster_start
        
        # ==================== 3. –î–ò–°–ö–û–ù–¢–ò–†–û–í–ê–ù–ò–ï ====================
        discount_start = time.perf_counter()
        
        try:
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–æ –≤—Å–µ–º –∏—Å—Ç–æ—á–Ω–∏–∫–∞–º
            discounted_bpas = self.adapter.apply_discounting(loaded_data, discount_factor)
            
            # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ –∏—Å—Ç–æ—á–Ω–∏–∫–∏
            discounted_loaded_data = loaded_data.copy()
            discounted_loaded_data['bpas'] = [
                self._parse_bpa_strings_to_frozenset(bpa) for bpa in discounted_bpas
            ]
            
            combined_bpa_discounted = self.adapter.combine_sources_dempster(discounted_loaded_data)
            
            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –¥–∞–Ω–Ω—ã—Ö —Å –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º BPA
            combined_data_discounted = {
                'frame': loaded_data.get('frame', set()),
                'bpa': self._parse_bpa_strings_to_frozenset(combined_bpa_discounted)
            }
            
            # Belief –ø–æ—Å–ª–µ –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            belief_discounted = {}
            for event in events_to_calculate:
                belief_discounted[event] = self.adapter.calculate_belief(combined_data_discounted, event)
            
            # Plausibility –ø–æ—Å–ª–µ –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏—è
            plausibility_discounted = {}
            for event in events_to_calculate:
                plausibility_discounted[event] = self.adapter.calculate_plausibility(combined_data_discounted, event)
                
        except Exception as e:
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –∑–∞–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏
            discounted_bpas = []
            combined_bpa_discounted = {}
            belief_discounted = {event: 0.0 for event in events_to_calculate}
            plausibility_discounted = {event: 0.0 for event in events_to_calculate}
        
        timings['discounting'] = time.perf_counter() - discount_start
        
        # ==================== 4. –Ø–ì–ï–† (m1 ‚äï·µß m2) ====================
        yager_start = time.perf_counter()
        
        try:
            combined_bpa_yager = self.adapter.combine_sources_yager(loaded_data)
            
            # –°–æ–∑–¥–∞–µ–º –æ–±—ä–µ–∫—Ç –¥–∞–Ω–Ω—ã—Ö —Å –∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–Ω—ã–º BPA –Ø–≥–µ—Ä–∞
            combined_data_yager = {
                'frame': loaded_data.get('frame', set()),
                'bpa': self._parse_bpa_strings_to_frozenset(combined_bpa_yager)
            }
            
            # Belief –ø–æ—Å–ª–µ –Ø–≥–µ—Ä–∞
            belief_yager = {}
            for event in events_to_calculate:
                belief_yager[event] = self.adapter.calculate_belief(combined_data_yager, event)
            
            # Plausibility –ø–æ—Å–ª–µ –Ø–≥–µ—Ä–∞
            plausibility_yager = {}
            for event in events_to_calculate:
                plausibility_yager[event] = self.adapter.calculate_plausibility(combined_data_yager, event)
                
        except Exception as e:
            # –í —Å–ª—É—á–∞–µ –æ—à–∏–±–∫–∏ –∑–∞–ø–æ–ª–Ω—è–µ–º –Ω—É–ª—è–º–∏
            combined_bpa_yager = {}
            belief_yager = {event: 0.0 for event in events_to_calculate}
            plausibility_yager = {event: 0.0 for event in events_to_calculate}
        
        timings['yager_combination'] = time.perf_counter() - yager_start
        
        # ==================== –°–ë–û–† –†–ï–ó–£–õ–¨–¢–ê–¢–û–í ====================
        total_time = sum(timings.values())
        timings['total_time'] = total_time
        
        # –§–æ—Ä–º–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        results = {
            'test_file': test_file,
            'test_name': test_name,
            'repetition': repetition,
            'metadata': {
                'frame_size': frame_size,
                'sources_count': sources_count,
                'events_count': len(events_to_calculate),
                'discount_factor': discount_factor,
                'frame_elements': frame_elements,
                'calculated_events': events_to_calculate
            },
            'timings': timings,
            'results': {
                'initial_belief': belief_by_source,
                'initial_plausibility': plausibility_by_source,
                'dempster': {
                    'combined_bpa': combined_bpa_dempster,
                    'belief': belief_dempster,
                    'plausibility': plausibility_dempster
                },
                'discounted': {
                    'discounted_bpas': discounted_bpas,
                    'combined_bpa': combined_bpa_discounted,
                    'belief': belief_discounted,
                    'plausibility': plausibility_discounted
                },
                'yager': {
                    'combined_bpa': combined_bpa_yager,
                    'belief': belief_yager,
                    'plausibility': plausibility_yager
                }
            },
            'validation': {
                'empty_set': {
                    'belief': belief_dempster.get('{}', 0),
                    'plausibility': plausibility_dempster.get('{}', 0)
                },
                'omega_set': {
                    'belief': belief_dempster.get(omega_event, 0),
                    'plausibility': plausibility_dempster.get(omega_event, 0)
                }
            }
        }
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å
        self._validate_results(results)
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∞
        self._save_json(results, os.path.join(test_dir, "results.json"))
        self._save_json(timings, os.path.join(test_dir, "timings.json"))
        
        return {
            'test_name': test_name,
            'test_file': test_file,
            'frame_size': frame_size,
            'sources_count': sources_count,
            'repetition': repetition,
            'timings': timings
        }
    
    def _validate_results(self, results: Dict[str, Any]):
        """
        –ü—Ä–æ–≤–µ—Ä—è–µ—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ—Å—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤ —Å —É—á–µ—Ç–æ–º –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç–∏.
        –í—ã–≤–æ–¥–∏—Ç –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ –ø—Ä–∏ –∑–Ω–∞—á–∏—Ç–µ–ª—å–Ω—ã—Ö –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏—è—Ö.
        """
        errors = []
        warnings = []
        
        # –£–≤–µ–ª–∏—á–∏–≤–∞–µ–º –ø–æ–≥—Ä–µ—à–Ω–æ—Å—Ç—å –¥–ª—è –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
        tolerance_warning = 1e-3  # 0.1% –¥–ª—è –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π
        tolerance_error = 1e-2    # 1% –¥–ª—è –æ—à–∏–±–æ–∫
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø—É—Å—Ç–æ–µ –º–Ω–æ–∂–µ—Å—Ç–≤–æ
        empty_bel = results['validation']['empty_set']['belief']
        empty_pl = results['validation']['empty_set']['plausibility']
        
        if abs(empty_bel) > tolerance_error:
            errors.append(f"Bel(‚àÖ) = {empty_bel}, –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 0 (–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {abs(empty_bel):.6f})")
        elif abs(empty_bel) > tolerance_warning:
            warnings.append(f"Bel(‚àÖ) = {empty_bel}, –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 0 (–Ω–µ–±–æ–ª—å—à–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ)")
        
        if abs(empty_pl) > tolerance_error:
            errors.append(f"Pl(‚àÖ) = {empty_pl}, –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 0 (–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {abs(empty_pl):.6f})")
        elif abs(empty_pl) > tolerance_warning:
            warnings.append(f"Pl(‚àÖ) = {empty_pl}, –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 0 (–Ω–µ–±–æ–ª—å—à–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ)")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º Œ©
        omega_event = "{" + ",".join(results['metadata']['frame_elements']) + "}"
        omega_bel = results['results']['dempster']['belief'].get(omega_event, 0)
        omega_pl = results['results']['dempster']['plausibility'].get(omega_event, 0)
        
        if abs(omega_bel - 1.0) > tolerance_error:
            errors.append(f"Bel(Œ©) = {omega_bel}, –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 1 (–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {abs(omega_bel - 1.0):.6f})")
        elif abs(omega_bel - 1.0) > tolerance_warning:
            warnings.append(f"Bel(Œ©) = {omega_bel}, –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 1 (–Ω–µ–±–æ–ª—å—à–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ)")
        
        if abs(omega_pl - 1.0) > tolerance_error:
            errors.append(f"Pl(Œ©) = {omega_pl}, –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 1 (–æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ: {abs(omega_pl - 1.0):.6f})")
        elif abs(omega_pl - 1.0) > tolerance_warning:
            warnings.append(f"Pl(Œ©) = {omega_pl}, –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å 1 (–Ω–µ–±–æ–ª—å—à–æ–µ –æ—Ç–∫–ª–æ–Ω–µ–Ω–∏–µ)")
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ Belief <= Plausibility –¥–ª—è –≤—Å–µ—Ö —Å–æ–±—ã—Ç–∏–π
        for source_idx in range(results['metadata']['sources_count']):
            for event in results['metadata']['calculated_events']:
                bel = results['results']['initial_belief'][source_idx].get(event, 0)
                pl = results['results']['initial_plausibility'][source_idx].get(event, 0)
                
                if bel > pl + tolerance_error:  # –ó–Ω–∞—á–∏—Ç–µ–ª—å–Ω–æ–µ –Ω–∞—Ä—É—à–µ–Ω–∏–µ
                    errors.append(f"–ò—Å—Ç–æ—á–Ω–∏–∫ {source_idx}: Bel({event})={bel:.4f} > Pl({event})={pl:.4f}")
                elif bel > pl + tolerance_warning:  # –ù–µ–±–æ–ª—å—à–æ–µ –Ω–∞—Ä—É—à–µ–Ω–∏–µ
                    warnings.append(f"–ò—Å—Ç–æ—á–Ω–∏–∫ {source_idx}: Bel({event})={bel:.4f} > Pl({event})={pl:.4f}")
        
        # –í—ã–≤–æ–¥–∏–º –æ—à–∏–±–∫–∏ –∏ –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è
        if errors:
            print(f"\n‚ùå –û—à–∏–±–∫–∏ –≤ —Ç–µ—Å—Ç–µ {results['test_name']}:")
            for error in errors[:2]:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º —Ç–æ–ª—å–∫–æ –ø–µ—Ä–≤—ã–µ 2 –æ—à–∏–±–∫–∏
                print(f"  {error}")
        
        if warnings and not errors:  # –ü–æ–∫–∞–∑—ã–≤–∞–µ–º warnings —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω–µ—Ç errors
            if len(warnings) > 2:
                print(f"\n‚ö†Ô∏è  {len(warnings)} –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏–π –¥–ª—è —Ç–µ—Å—Ç–∞ {results['test_name']}")
            else:
                for warning in warnings[:2]:
                    print(f"  {warning}")
    
    def _create_source_data(self, loaded_data: Any, source_idx: int) -> Dict:
        """
        –°–æ–∑–¥–∞–µ—Ç –æ–±—ä–µ–∫—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –∫–æ–Ω–∫—Ä–µ—Ç–Ω–æ–≥–æ –∏—Å—Ç–æ—á–Ω–∏–∫–∞.
        """
        # –ï—Å–ª–∏ –¥–∞–Ω–Ω—ã–µ —Å–æ–¥–µ—Ä–∂–∞—Ç —Å–ø–∏—Å–æ–∫ BPA
        if isinstance(loaded_data, dict) and 'bpas' in loaded_data:
            bpas = loaded_data['bpas']
            if source_idx < len(bpas):
                # –í–æ–∑–≤—Ä–∞—â–∞–µ–º –¥–∞–Ω–Ω—ã–µ —Å –æ–¥–Ω–∏–º BPA
                return {
                    'frame': loaded_data.get('frame', set()),
                    'bpa': bpas[source_idx]
                }
            else:
                # –ï—Å–ª–∏ –∏–Ω–¥–µ–∫—Å –≤—ã—Ö–æ–¥–∏—Ç –∑–∞ –ø—Ä–µ–¥–µ–ª—ã, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –ø–µ—Ä–≤—ã–π BPA
                return {
                    'frame': loaded_data.get('frame', set()),
                    'bpa': bpas[0] if bpas else {}
                }
        
        # –ï—Å–ª–∏ –Ω–µ —É–¥–∞–ª–æ—Å—å, –≤–æ–∑–≤—Ä–∞—â–∞–µ–º –æ—Ä–∏–≥–∏–Ω–∞–ª—å–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        return loaded_data
    
    def _parse_bpa_strings_to_frozenset(self, bpa_strings: Dict[str, float]) -> Dict[frozenset, float]:
        """
        –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç BPA –∏–∑ —Å—Ç—Ä–æ–∫–æ–≤–æ–≥–æ —Ñ–æ—Ä–º–∞—Ç–∞ –≤ frozenset.
        """
        if not bpa_strings:
            return {}
        
        result = {}
        for subset_str, mass in bpa_strings.items():
            if subset_str == "{}":
                subset = frozenset()
            else:
                elements = subset_str.strip("{}").split(",")
                subset = frozenset(elements)
            result[subset] = mass
        return result
    
    def _aggregate_repetitions(self, repetitions_results: List[Dict]) -> Dict[str, Any]:
        """
        –ê–≥—Ä–µ–≥–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö –∑–∞–ø—É—Å–∫–æ–≤.
        """
        if not repetitions_results:
            return {}
        
        first_result = repetitions_results[0]
        
        # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º —Ç–∞–π–º–∏–Ω–≥–∏
        aggregated_timings = {}
        timing_keys = first_result['timings'].keys()
        
        for key in timing_keys:
            # –°–æ–±–∏—Ä–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–µ—Ö –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π, –≥–¥–µ –µ—Å—Ç—å —ç—Ç–æ—Ç –∫–ª—é—á
            values = []
            for r in repetitions_results:
                if key in r['timings']:
                    values.append(r['timings'][key])
            
            if values:  # –ï—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ
                aggregated_timings[key] = {
                    'values': values,
                    'avg': statistics.mean(values),
                    'min': min(values),
                    'max': max(values),
                    'std': statistics.stdev(values) if len(values) > 1 else 0.0,
                    'median': statistics.median(values),
                    'count': len(values)
                }
        
        return {
            'test_name': first_result['test_name'],
            'test_file': first_result['test_file'],
            'frame_size': first_result['frame_size'],
            'sources_count': first_result['sources_count'],
            'repetitions_count': len(repetitions_results),
            'timings': aggregated_timings,
            'raw_repetitions': repetitions_results
        }
    
    def _create_results_directory(self, output_dir: str):
        """–°–æ–∑–¥–∞–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤."""
        timestamp = datetime.now().strftime("%Y-%m-%d_%H-%M-%S")
        self.results_dir = os.path.join(output_dir, self.library_name)
        self.current_run_dir = os.path.join(self.results_dir, f"run_{timestamp}")
        
        os.makedirs(self.current_run_dir, exist_ok=True)
        os.makedirs(os.path.join(self.current_run_dir, "raw"), exist_ok=True)
        os.makedirs(os.path.join(self.current_run_dir, "aggregated"), exist_ok=True)
        os.makedirs(os.path.join(self.current_run_dir, "plots"), exist_ok=True)
    
    def _save_configuration(self, test_files: List[str], discount_factor: float, repetitions: int):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∫–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—é –∑–∞–ø—É—Å–∫–∞."""
        config = {
            'library': self.library_name,
            'timestamp': datetime.now().isoformat(),
            'test_files_count': len(test_files),
            'repetitions': repetitions,
            'test_files': [Path(f).name for f in test_files],
            'discount_factor': discount_factor,
            'system_info': {
                'cpu_count': psutil.cpu_count(),
                'total_memory_mb': psutil.virtual_memory().total / 1024 / 1024
            }
        }
        self._save_json(config, os.path.join(self.current_run_dir, "config.json"))
    
    def _save_summary(self, summary: Dict[str, Any]):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–≤–æ–¥–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã."""
        self._save_json(summary, os.path.join(self.current_run_dir, "summary.json"))
    
    def _save_error(self, test_file: str, error_msg: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ–± –æ—à–∏–±–∫–µ."""
        test_name = Path(test_file).stem
        error_data = {
            'test_file': test_file,
            'test_name': test_name,
            'error': error_msg,
            'timestamp': datetime.now().isoformat()
        }
        
        error_file = os.path.join(self.current_run_dir, "raw", f"{test_name}_error.json")
        self._save_json(error_data, error_file)
    
    def _save_json(self, data: Any, filepath: str):
        """–°–æ—Ö—Ä–∞–Ω—è–µ—Ç –¥–∞–Ω–Ω—ã–µ –≤ JSON —Ñ–∞–π–ª."""
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(data, f, indent=2, ensure_ascii=False)
    
    def _create_summary(self, all_results: List[Dict], total_time: float) -> Dict[str, Any]:
        """–°–æ–∑–¥–∞–µ—Ç —Å–≤–æ–¥–Ω—ã–π –æ—Ç—á–µ—Ç —Å —É—á–µ—Ç–æ–º –ø–æ–≤—Ç–æ—Ä–µ–Ω–∏–π."""
        if not all_results:
            return {}
        
        # –ì—Ä—É–ø–ø–∏—Ä—É–µ–º –ø–æ —Ä–∞–∑–º–µ—Ä—É —Ñ—Ä–µ–π–º–∞
        by_frame_size = {}
        for result in all_results:
            size = result['frame_size']
            if size not in by_frame_size:
                by_frame_size[size] = []
            by_frame_size[size].append(result)
        
        # –í—ã—á–∏—Å–ª—è–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏
        summary = {
            'library': self.library_name,
            'timestamp': datetime.now().isoformat(),
            'total_tests': len(all_results),
            'repetitions': all_results[0]['repetitions_count'] if all_results else 1,
            'total_time': total_time,
            'avg_time_per_test': total_time / len(all_results) if all_results else 0,
            'by_frame_size': {},
            'operation_timings': self._aggregate_operation_timings(all_results)
        }
        
        for size, results in by_frame_size.items():
            avg_times = [r['timings']['total_time']['avg'] for r in results]
            summary['by_frame_size'][str(size)] = {
                'test_count': len(results),
                'avg_time': statistics.mean(avg_times) if avg_times else 0,
                'min_time': min(avg_times) if avg_times else 0,
                'max_time': max(avg_times) if avg_times else 0,
                'std_time': statistics.stdev(avg_times) if len(avg_times) > 1 else 0,
                'total_repetitions': sum(r['repetitions_count'] for r in results)
            }
        
        return summary
    
    def _aggregate_operation_timings(self, all_results: List[Dict]) -> Dict[str, Any]:
        """–ê–≥—Ä–µ–≥–∏—Ä—É–µ—Ç –∑–∞–º–µ—Ä—ã –≤—Ä–µ–º–µ–Ω–∏ –ø–æ –æ–ø–µ—Ä–∞—Ü–∏—è–º."""
        if not all_results:
            return {}
        
        # –°–æ–±–∏—Ä–∞–µ–º –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ –∫–ª—é—á–∏ —Ç–∞–π–º–∏–Ω–≥–æ–≤ –∏–∑ –≤—Å–µ—Ö —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        all_timing_keys = set()
        for result in all_results:
            all_timing_keys.update(result['timings'].keys())
        
        aggregated = {}
        total_avg_time = sum(r['timings']['total_time']['avg'] for r in all_results)
        
        for key in all_timing_keys:
            # –°–æ–±–∏—Ä–∞–µ–º –∑–Ω–∞—á–µ–Ω–∏—è —Ç–æ–ª—å–∫–æ –¥–ª—è —Ç–µ—Ö —Ç–µ—Å—Ç–æ–≤, –≥–¥–µ –µ—Å—Ç—å —ç—Ç–æ—Ç –∫–ª—é—á
            avg_times = []
            for r in all_results:
                if key in r['timings']:
                    avg_times.append(r['timings'][key]['avg'])
            
            if avg_times:  # –ï—Å–ª–∏ –µ—Å—Ç—å —Ö–æ—Ç—è –±—ã –æ–¥–Ω–æ –∑–Ω–∞—á–µ–Ω–∏–µ
                aggregated[key] = {
                    'total': sum(avg_times),
                    'avg': statistics.mean(avg_times),
                    'min': min(avg_times),
                    'max': max(avg_times),
                    'count': len(avg_times),
                    'percentage': (sum(avg_times) / total_avg_time) * 100 if total_avg_time > 0 else 0
                }
        
        return aggregated
    
    def _create_latest_symlink(self):
        """–°–æ–∑–¥–∞–µ—Ç —Å–∏–º–ª–∏–Ω–∫ latest –Ω–∞ —Ç–µ–∫—É—â–∏–π –∑–∞–ø—É—Å–∫."""
        latest_link = os.path.join(self.results_dir, "latest")
        
        if os.path.exists(latest_link):
            if os.path.islink(latest_link):
                os.unlink(latest_link)
            else:
                os.remove(latest_link)
        
        target = os.path.basename(self.current_run_dir)
        os.symlink(target, latest_link)