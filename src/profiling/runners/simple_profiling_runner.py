# src/profiling/runners/simple_profiling_runner.py
"""
SimpleProfilingRunner - —Ä–∞–Ω–Ω–µ—Ä –¥–ª—è –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ—Å—Ç–æ–≤ –î–µ–º–ø—Å—Ç–µ—Ä–∞-–®–µ–π—Ñ–µ—Ä–∞.
–ò–Ω—Ç–µ–≥—Ä–∏—Ä—É–µ—Ç SystemCollector, ArtifactManager –∏ –∞–¥–∞–ø—Ç–µ—Ä—ã –î–®.
"""

import os
import sys
import json
from typing import Dict, Any, Optional, List, Tuple
from pathlib import Path

# –î–æ–±–∞–≤–ª—è–µ–º –ø—É—Ç—å –¥–ª—è –∏–º–ø–æ—Ä—Ç–∞ –∞–¥–∞–ø—Ç–µ—Ä–æ–≤
project_root = Path(__file__).parent.parent.parent
sys.path.insert(0, str(project_root))

from src.profiling.artifacts import ArtifactManager, collect_test_metadata
from src.profiling.collectors import SystemCollector, create_system_collector
from src.adapters.our_adapter import OurImplementationAdapter


class SimpleProfilingRunner:
    """
    –ü—Ä–æ—Å—Ç–æ–π —Ä–∞–Ω–Ω–µ—Ä –¥–ª—è –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏—è —Ç–µ—Å—Ç–æ–≤ –î–µ–º–ø—Å—Ç–µ—Ä–∞-–®–µ–π—Ñ–µ—Ä–∞.
    
    –í—ã–ø–æ–ª–Ω—è–µ—Ç:
    1. –ó–∞–≥—Ä—É–∑–∫—É —Ç–µ—Å—Ç–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö
    2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—é –∞–¥–∞–ø—Ç–µ—Ä–∞ –î–®
    3. –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ 4-—à–∞–≥–æ–≤–æ–≥–æ –ø—Ä–æ—Ü–µ—Å—Å–∞
    4. –°–±–æ—Ä –º–µ—Ç—Ä–∏–∫ —á–µ—Ä–µ–∑ SystemCollector
    5. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —á–µ—Ä–µ–∑ ArtifactManager
    """
    
    def __init__(self, 
                 adapter_name: str = "our",
                 base_dir: str = "results/profiling",
                 run_id: Optional[str] = None,
                 overwrite: bool = False):
        """
        –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è —Ä–∞–Ω–Ω–µ—Ä–∞.
        
        Args:
            adapter_name: –ò–º—è –∞–¥–∞–ø—Ç–µ—Ä–∞ ('our', 'pyds', –∏ —Ç.–¥.)
            base_dir: –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
            run_id: ID –∑–∞–ø—É—Å–∫–∞ (–µ—Å–ª–∏ None, –≥–µ–Ω–µ—Ä–∏—Ä—É–µ—Ç—Å—è –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏)
            overwrite: –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        """
        self.adapter_name = adapter_name
        
        # –°–æ–∑–¥–∞–µ–º ArtifactManager
        self.artifact_manager = ArtifactManager(
            base_dir=base_dir,
            adapter_name=adapter_name,
            run_id=run_id,
            overwrite=overwrite
        )
        
        # –°–æ–∑–¥–∞–µ–º SystemCollector
        self.system_collector = SystemCollector(name=f"system_{adapter_name}")
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º –∞–¥–∞–ø—Ç–µ—Ä –î–®
        self.adapter = self._load_adapter(adapter_name)
        
        print(f"üöÄ SimpleProfilingRunner –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω")
        print(f"   –ê–¥–∞–ø—Ç–µ—Ä: {adapter_name}")
        print(f"   –î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è: {self.artifact_manager.run_dir}")
    
    def _load_adapter(self, adapter_name: str):
        """–ó–∞–≥—Ä—É–∂–∞–µ—Ç –∞–¥–∞–ø—Ç–µ—Ä –î–µ–º–ø—Å—Ç–µ—Ä–∞-–®–µ–π—Ñ–µ—Ä–∞."""
        adapters = {
            "our": OurImplementationAdapter,
            # "pyds": PydsAdapter,    # –ü–æ–∑–∂–µ –¥–æ–±–∞–≤–∏–º
            # "ds": DsAdapter,         # –ü–æ–∑–∂–µ –¥–æ–±–∞–≤–∏–º
        }
        
        if adapter_name not in adapters:
            raise ValueError(f"–ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –∞–¥–∞–ø—Ç–µ—Ä: {adapter_name}")
        
        return adapters[adapter_name]()
    
    def run_test(self, 
                test_data: Dict[str, Any], 
                test_name: str,
                iterations: int = 3) -> Dict[str, Any]:
        """
        –ó–∞–ø—É—Å–∫–∞–µ—Ç –æ–¥–∏–Ω —Ç–µ—Å—Ç –∏ —Å–æ–±–∏—Ä–∞–µ—Ç –º–µ—Ç—Ä–∏–∫–∏.
        
        Args:
            test_data: –î–∞–Ω–Ω—ã–µ —Ç–µ—Å—Ç–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ DASS
            test_name: –ò–º—è —Ç–µ—Å—Ç–∞ (–¥–ª—è –∏–º–µ–Ω–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–æ–≤)
            iterations: –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Ç–µ—Ä–∞—Ü–∏–π
            
        Returns:
            Dict: –°—Ç—Ä—É–∫—Ç—É—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∞
        """
        print(f"\nüß™ –ó–ê–ü–£–°–ö –¢–ï–°–¢–ê: {test_name}")
        print(f"   –ò—Ç–µ—Ä–∞—Ü–∏–π: {iterations}")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ö–æ–¥–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ
        self.artifact_manager.save_test_input(test_data, test_name)
        
        # –°–æ–±–∏—Ä–∞–µ–º –º–µ—Ç–∞–¥–∞–Ω–Ω—ã–µ
        metadata = collect_test_metadata(
            test_data=test_data,
            test_name=test_name,
            iterations=iterations,
            adapter=self.adapter_name
        )
        
        self.artifact_manager.save_json(
            f"{test_name}_metadata.json",
            metadata,
            subdir=f"test_metadata/{test_name}"
        )
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ —á–µ—Ä–µ–∑ –∞–¥–∞–ø—Ç–µ—Ä
        print(f"   1. –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö —á–µ—Ä–µ–∑ –∞–¥–∞–ø—Ç–µ—Ä...")
        loaded_data, load_metrics = self.system_collector.profile(
            self.adapter.load_from_dass,
            test_data
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏ –∑–∞–≥—Ä—É–∑–∫–∏
        self.artifact_manager.save_metrics(
            load_metrics,
            test_name=test_name,
            step_name="load_data",
            iteration=1
        )
        
        # –ü–æ–ª—É—á–∞–µ–º –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ —Ç–µ—Å—Ç–µ
        frame_elements = self.adapter.get_frame_of_discernment(loaded_data)
        sources_count = self.adapter.get_sources_count(loaded_data)
        
        print(f"      –§—Ä–µ–π–º: {len(frame_elements)} —ç–ª–µ–º–µ–Ω—Ç–æ–≤")
        print(f"      –ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {sources_count}")
        
        # –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∞
        test_results = {
            "metadata": {
                "test_name": test_name,
                "adapter": self.adapter_name,
                "iterations": iterations,
                "frame_size": len(frame_elements),
                "sources_count": sources_count
            },
            "iterations": []
        }
        
        # –í—ã–ø–æ–ª–Ω—è–µ–º –∏—Ç–µ—Ä–∞—Ü–∏–∏
        for i in range(1, iterations + 1):
            print(f"   2. –ò—Ç–µ—Ä–∞—Ü–∏—è {i}/{iterations}...", end="", flush=True)
            
            iteration_results = self._run_single_iteration(
                loaded_data=loaded_data,
                test_name=test_name,
                iteration_num=i
            )
            
            test_results["iterations"].append(iteration_results)
            print(" ‚úì")
        
        # –ê–≥—Ä–µ–≥–∏—Ä—É–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        test_results["aggregated"] = self._aggregate_results(
            test_results["iterations"]
        )
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –ø–æ–ª–Ω—ã–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã —Ç–µ—Å—Ç–∞
        self.artifact_manager.save_test_results(test_results, test_name)
        
        # –°–æ–∑–¥–∞–µ–º –∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á–µ—Ç
        self._create_test_report(test_results, test_name)
        
        print(f"\n‚úÖ –¢–ï–°–¢ {test_name} –ó–ê–í–ï–†–®–ï–ù")
        print(f"   –†–µ–∑—É–ª—å—Ç–∞—Ç—ã: {self.artifact_manager.run_dir}")
        
        return test_results
    
    def _run_single_iteration(self, 
                            loaded_data: Any,
                            test_name: str,
                            iteration_num: int) -> Dict[str, Any]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç –æ–¥–Ω—É –∏—Ç–µ—Ä–∞—Ü–∏—é —Ç–µ—Å—Ç–∞ (4 —à–∞–≥–∞ –î–®).
        """
        iteration_results = {
            "iteration": iteration_num,
            "steps": {}
        }
        
        # –®–∞–≥ 1: –ò—Å—Ö–æ–¥–Ω—ã–µ Belief/Plausibility
        step1_results, step1_metrics = self._execute_step_with_profiling(
            step_func=self._execute_step1,
            loaded_data=loaded_data,
            test_name=test_name,
            step_name="step1_original",
            iteration=iteration_num
        )
        
        iteration_results["steps"]["step1"] = {
            "results": step1_results,
            "metrics": step1_metrics
        }
        
        # –®–∞–≥ 2: –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –î–µ–º–ø—Å—Ç–µ—Ä–æ–º
        step2_results, step2_metrics = self._execute_step_with_profiling(
            step_func=self._execute_step2,
            loaded_data=loaded_data,
            test_name=test_name,
            step_name="step2_dempster",
            iteration=iteration_num
        )
        
        iteration_results["steps"]["step2"] = {
            "results": step2_results,
            "metrics": step2_metrics
        }
        
        # –®–∞–≥ 3: –î–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ + –î–µ–º–ø—Å—Ç–µ—Ä
        step3_results, step3_metrics = self._execute_step_with_profiling(
            step_func=self._execute_step3,
            loaded_data=loaded_data,
            test_name=test_name,
            step_name="step3_discount_dempster",
            iteration=iteration_num
        )
        
        iteration_results["steps"]["step3"] = {
            "results": step3_results,
            "metrics": step3_metrics
        }
        
        # –®–∞–≥ 4: –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –Ø–≥–µ—Ä–æ–º
        step4_results, step4_metrics = self._execute_step_with_profiling(
            step_func=self._execute_step4,
            loaded_data=loaded_data,
            test_name=test_name,
            step_name="step4_yager",
            iteration=iteration_num
        )
        
        iteration_results["steps"]["step4"] = {
            "results": step4_results,
            "metrics": step4_metrics
        }
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∏—Ç–µ—Ä–∞—Ü–∏–∏
        total_time = 0.0
        for step in iteration_results["steps"].values():
            if "metrics" in step and "time" in step["metrics"]:
                total_time += step["metrics"]["time"].get("wall_time_ms", 0)
        
        iteration_results["summary"] = {
            "total_time_ms": total_time,
            "steps_count": len(iteration_results["steps"])
        }
        
        return iteration_results
    
    def _execute_step_with_profiling(self, 
                                   step_func, 
                                   loaded_data: Any,
                                   test_name: str,
                                   step_name: str,
                                   iteration: int) -> Tuple[Any, Dict[str, Any]]:
        """
        –í—ã–ø–æ–ª–Ω—è–µ—Ç —à–∞–≥ —Å –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º –∏ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç –º–µ—Ç—Ä–∏–∫–∏.
        """
        # –í—ã–ø–æ–ª–Ω—è–µ–º —à–∞–≥ —Å –ø—Ä–æ—Ñ–∏–ª–∏—Ä–æ–≤–∞–Ω–∏–µ–º
        result, metrics = self.system_collector.profile(
            step_func,
            loaded_data
        )

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –º–µ—Ç—Ä–∏–∫–∏
        self.artifact_manager.save_metrics(
            metrics,
            test_name=test_name,
            step_name=step_name,
            iteration=iteration
        )
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –æ—à–∏–±–∫–∞ - –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º
        if metrics and "error" in metrics and metrics["error"]:
            error_msg = str(metrics["error"])
            if len(error_msg) > 50:
                error_msg = error_msg[:47] + "..."
            print(f"\n‚ö†Ô∏è  {step_name}: {error_msg}")
        
        return result, metrics
    
    def _execute_step1(self, loaded_data: Any) -> Dict[str, Any]:
        """–®–∞–≥ 1: –ò—Å—Ö–æ–¥–Ω—ã–µ Belief/Plausibility."""
        try:
            # –ü–æ–ª—É—á–∞–µ–º —ç–ª–µ–º–µ–Ω—Ç—ã —Ñ—Ä–µ–π–º–∞
            frame_elements = self.adapter.get_frame_of_discernment(loaded_data)
            
            # –ü—Ä–æ—Å—Ç–æ–π –ø—Ä–∏–º–µ—Ä: –≤—ã—á–∏—Å–ª—è–µ–º belief –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞
            if frame_elements:
                first_element = frame_elements[0]
                belief = self.adapter.calculate_belief(loaded_data, first_element)
                plausibility = self.adapter.calculate_plausibility(loaded_data, first_element)
                
                return {
                    "step": "step1",
                    "belief_sample": belief,
                    "plausibility_sample": plausibility,
                    "frame_size": len(frame_elements),
                    "note": "–ü—Ä–∏–º–µ—Ä –≤—ã—á–∏—Å–ª–µ–Ω–∏—è –¥–ª—è –ø–µ—Ä–≤–æ–≥–æ —ç–ª–µ–º–µ–Ω—Ç–∞ —Ñ—Ä–µ–π–º–∞"
                }
            else:
                return {
                    "step": "step1",
                    "error": "–ü—É—Å—Ç–æ–π —Ñ—Ä–µ–π–º —Ä–∞–∑–ª–∏—á–µ–Ω–∏—è",
                    "frame_size": 0
                }
                
        except Exception as e:
            return {
                "step": "step1",
                "error": str(e),
                "error_type": type(e).__name__
            }
    
    def _execute_step2(self, loaded_data: Any) -> Dict[str, Any]:
        """–®–∞–≥ 2: –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –î–µ–º–ø—Å—Ç–µ—Ä–æ–º."""
        try:
            result = self.adapter.combine_sources_dempster(loaded_data)
            return {
                "step": "step2",
                "result_type": type(result).__name__,
                "result_size": len(result) if hasattr(result, '__len__') else "N/A",
                "has_conflict": "full_conflict" in str(result).lower() or "k=1" in str(result).lower()
            }
        except Exception as e:
            error_msg = str(e)
            is_full_conflict = "–ø–æ–ª–Ω—ã–π –∫–æ–Ω—Ñ–ª–∏–∫—Ç" in error_msg.lower() or "k=1" in error_msg.lower()
            
            return {
                "step": "step2",
                "error": error_msg,
                "error_type": type(e).__name__,
                "is_full_conflict": is_full_conflict
            }
    
    def _execute_step3(self, loaded_data: Any) -> Dict[str, Any]:
        """–®–∞–≥ 3: –î–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ + –î–µ–º–ø—Å—Ç–µ—Ä."""
        try:
            # –ü–æ–ª—É—á–∞–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –∏—Å—Ç–æ—á–Ω–∏–∫–æ–≤
            sources_count = self.adapter.get_sources_count(loaded_data)
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ —Å alpha=0.1
            alpha = 0.1
            discounted = self.adapter.apply_discounting(loaded_data, alpha)
            
            # –°–æ–∑–¥–∞–µ–º –Ω–æ–≤—ã–π –æ–±—ä–µ–∫—Ç —Å –¥–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ –¥–∞–Ω–Ω—ã–º–∏
            # (–≠—Ç–æ —É–ø—Ä–æ—â–µ–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è, –≤ —Ä–µ–∞–ª—å–Ω–æ—Å—Ç–∏ –Ω—É–∂–Ω–æ –ø—Ä–∞–≤–∏–ª—å–Ω–æ —Å–∫–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞—Ç—å)
            return {
                "step": "step3",
                "alpha": alpha,
                "sources_count": sources_count,
                "discounted_items": len(discounted) if hasattr(discounted, '__len__') else 0,
                "note": "–î–∏—Å–∫–æ–Ω—Ç–∏—Ä–æ–≤–∞–Ω–∏–µ –ø—Ä–∏–º–µ–Ω–µ–Ω–æ –∫ –∫–∞–∂–¥–æ–º—É –∏—Å—Ç–æ—á–Ω–∏–∫—É"
            }
        except Exception as e:
            return {
                "step": "step3",
                "error": str(e),
                "error_type": type(e).__name__
            }
    
    def _execute_step4(self, loaded_data: Any) -> Dict[str, Any]:
        """–®–∞–≥ 4: –ö–æ–º–±–∏–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ –Ø–≥–µ—Ä–æ–º."""
        try:
            result = self.adapter.combine_sources_yager(loaded_data)
            return {
                "step": "step4",
                "result_type": type(result).__name__,
                "result_size": len(result) if hasattr(result, '__len__') else "N/A"
            }
        except Exception as e:
            return {
                "step": "step4",
                "error": str(e),
                "error_type": type(e).__name__
            }
    
    def _aggregate_results(self, iterations: List[Dict]) -> Dict[str, Any]:
        """–ê–≥—Ä–µ–≥–∏—Ä—É–µ—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –≤—Å–µ—Ö –∏—Ç–µ—Ä–∞—Ü–∏–π."""
        if not iterations:
            return {}
        
        aggregated = {
            "performance": {},
            "steps_summary": {}
        }
        
        # –ê–≥—Ä–µ–≥–∞—Ü–∏—è –ø–æ —à–∞–≥–∞–º
        steps = ["step1", "step2", "step3", "step4"]
        
        for step in steps:
            step_times = []
            step_successful = 0
            
            for iteration in iterations:
                if step in iteration["steps"]:
                    metrics = iteration["steps"][step].get("metrics", {})
                    
                    if metrics and "time" in metrics:
                        step_times.append(metrics["time"].get("wall_time_ms", 0))
                    
                    # –ü—Ä–æ–≤–µ—Ä—è–µ–º —É—Å–ø–µ—à–Ω–æ—Å—Ç—å —à–∞–≥–∞
                    step_result = iteration["steps"][step].get("results", {})
                    if step_result and "error" not in step_result:
                        step_successful += 1
            
            if step_times:
                aggregated["steps_summary"][step] = {
                    "time_ms": {
                        "min": min(step_times) if step_times else 0,
                        "max": max(step_times) if step_times else 0,
                        "mean": sum(step_times) / len(step_times) if step_times else 0,
                        "total": sum(step_times) if step_times else 0
                    },
                    "success_rate": (step_successful / len(iterations) * 100) if iterations else 0
                }
        
        # –û–±—â–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
        total_times = []
        for iteration in iterations:
            total_time = iteration.get("summary", {}).get("total_time_ms", 0)
            if total_time:
                total_times.append(total_time)
        
        if total_times:
            aggregated["performance"]["total"] = {
                "time_ms": {
                    "min": min(total_times),
                    "max": max(total_times),
                    "mean": sum(total_times) / len(total_times),
                    "total": sum(total_times)
                }
            }
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –æ—à–∏–±–∫–∞–º
        error_stats = {}
        for step in steps:
            errors = []
            for iteration in iterations:
                if step in iteration["steps"]:
                    step_result = iteration["steps"][step].get("results", {})
                    if step_result and "error" in step_result:
                        errors.append(step_result.get("error_type", "Unknown"))
            
            if errors:
                error_stats[step] = {
                    "error_count": len(errors),
                    "error_types": list(set(errors))
                }
        
        if error_stats:
            aggregated["error_statistics"] = error_stats
        
        return aggregated
    
    def _create_test_report(self, test_results: Dict[str, Any], test_name: str):
        """–°–æ–∑–¥–∞–µ—Ç –∫—Ä–∞—Ç–∫–∏–π –æ—Ç—á–µ—Ç –ø–æ —Ç–µ—Å—Ç—É."""
        metadata = test_results["metadata"]
        aggregated = test_results.get("aggregated", {})
        
        report_lines = [
            "=" * 60,
            f"üìä –û–¢–ß–ï–¢ –ü–û –¢–ï–°–¢–£: {test_name}",
            f"–ê–¥–∞–ø—Ç–µ—Ä: {metadata['adapter']}",
            f"–§—Ä–µ–π–º: {metadata['frame_size']} —ç–ª–µ–º–µ–Ω—Ç–æ–≤",
            f"–ò—Å—Ç–æ—á–Ω–∏–∫–æ–≤: {metadata['sources_count']}",
            f"–ò—Ç–µ—Ä–∞—Ü–∏–π: {metadata['iterations']}",
            "=" * 60,
            ""
        ]
        
        # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ —à–∞–≥–∞–º
        if "steps_summary" in aggregated:
            report_lines.append("üìà –ü–†–û–ò–ó–í–û–î–ò–¢–ï–õ–¨–ù–û–°–¢–¨ –ü–û –®–ê–ì–ê–ú:")
            report_lines.append("")
            
            for step, stats in aggregated["steps_summary"].items():
                time_stats = stats["time_ms"]
                success_rate = stats["success_rate"]
                
                step_name = {
                    "step1": "–ò—Å—Ö–æ–¥–Ω—ã–µ Bel/Pl",
                    "step2": "–î–µ–º–ø—Å—Ç–µ—Ä",
                    "step3": "–î–∏—Å–∫–æ–Ω—Ç+–î–µ–º–ø—Å—Ç–µ—Ä",
                    "step4": "–Ø–≥–µ—Ä"
                }.get(step, step)
                
                report_lines.append(
                    f"  {step_name:20}: {time_stats['mean']:.2f} ms "
                    f"(min: {time_stats['min']:.2f}, max: {time_stats['max']:.2f}) "
                    f"‚úì {success_rate:.0f}%"
                )
        
        # –ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ–± –æ—à–∏–±–∫–∞—Ö
        if "error_statistics" in aggregated:
            report_lines.append("")
            report_lines.append("‚ö†Ô∏è  –°–¢–ê–¢–ò–°–¢–ò–ö–ê –û–®–ò–ë–û–ö:")
            report_lines.append("")
            
            for step, error_info in aggregated["error_statistics"].items():
                step_name = {
                    "step1": "–ò—Å—Ö–æ–¥–Ω—ã–µ Bel/Pl",
                    "step2": "–î–µ–º–ø—Å—Ç–µ—Ä",
                    "step3": "–î–∏—Å–∫–æ–Ω—Ç+–î–µ–º–ø—Å—Ç–µ—Ä",
                    "step4": "–Ø–≥–µ—Ä"
                }.get(step, step)
                
                report_lines.append(
                    f"  {step_name:20}: {error_info['error_count']} –æ—à–∏–±–æ–∫ "
                    f"({', '.join(error_info['error_types'][:3])})"
                )
        
        # –û–±—â–µ–µ –≤—Ä–µ–º—è
        if "performance" in aggregated and "total" in aggregated["performance"]:
            total_stats = aggregated["performance"]["total"]["time_ms"]
            report_lines.append("")
            report_lines.append(f"üïí –û–ë–©–ï–ï –í–†–ï–ú–Ø: {total_stats['mean']:.2f} ms")
            report_lines.append(f"   –ò—Ç–æ–≥–æ –∑–∞ –≤—Å–µ –∏—Ç–µ—Ä–∞—Ü–∏–∏: {total_stats['total']:.2f} ms")
        
        # –û–±—â–∞—è —É—Å–ø–µ—à–Ω–æ—Å—Ç—å
        successful_steps = 0
        total_steps = 0
        
        for iteration in test_results["iterations"]:
            for step_name, step_data in iteration["steps"].items():
                total_steps += 1
                step_result = step_data.get("results", {})
                if step_result and "error" not in step_result:
                    successful_steps += 1
        
        success_rate = (successful_steps / total_steps * 100) if total_steps > 0 else 0
        
        report_lines.append("")
        report_lines.append(f"‚úÖ –£–°–ü–ï–®–ù–û–°–¢–¨: {success_rate:.1f}% ({successful_steps}/{total_steps} —à–∞–≥–æ–≤)")
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –æ—Ç—á–µ—Ç
        report_content = "\n".join(report_lines)
        
        self.artifact_manager.save_text(
            f"{test_name}_report.txt",
            report_content,
            subdir=f"reports/{test_name}"
        )
    
    def get_run_directory(self) -> Path:
        """–í–æ–∑–≤—Ä–∞—â–∞–µ—Ç –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—é —Å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∞–º–∏."""
        return self.artifact_manager.run_dir
    
    def cleanup(self):
        """–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤."""
        self.artifact_manager.cleanup_temp_files()
        print("üßπ –†–µ—Å—É—Ä—Å—ã –æ—á–∏—â–µ–Ω—ã")


# –§–∞–±—Ä–∏—á–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –¥–ª—è —É–¥–æ–±—Å—Ç–≤–∞
def create_profiling_runner(adapter_name: str = "our",
                          base_dir: str = "results/profiling",
                          run_id: Optional[str] = None,
                          overwrite: bool = False) -> SimpleProfilingRunner:
    """
    –°–æ–∑–¥–∞–µ—Ç —ç–∫–∑–µ–º–ø–ª—è—Ä SimpleProfilingRunner.
    
    Args:
        adapter_name: –ò–º—è –∞–¥–∞–ø—Ç–µ—Ä–∞
        base_dir: –ë–∞–∑–æ–≤–∞—è –¥–∏—Ä–µ–∫—Ç–æ—Ä–∏—è
        run_id: ID –∑–∞–ø—É—Å–∫–∞
        overwrite: –ü–µ—Ä–µ–∑–∞–ø–∏—Å—ã–≤–∞—Ç—å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã
        
    Returns:
        SimpleProfilingRunner: –°–æ–∑–¥–∞–Ω–Ω—ã–π —Ä–∞–Ω–Ω–µ—Ä
    """
    return SimpleProfilingRunner(
        adapter_name=adapter_name,
        base_dir=base_dir,
        run_id=run_id,
        overwrite=overwrite
    )
