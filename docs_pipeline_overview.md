# Реализация пайплайна и архитектуры DS-Benchmark

Этот документ фиксирует, как устроена реализация DS-Benchmark: от подготовки входных данных до получения и интерпретации результатов.

## 1. Цели реализации

DS-Benchmark реализует единый контур для сравнения нескольких библиотек теории Демпстера–Шейфера в одинаковых условиях. Основные цели:

- воспроизводимые входные наборы данных;
- одинаковый API запуска для разных библиотек через адаптеры;
- единая последовательность вычислительных этапов;
- стандартизированный сбор метрик производительности;
- детерминированное хранение артефактов;
- постобработка и интерпретация результатов.

## 2. Сквозной пайплайн (end-to-end)

Ниже описан базовый поток выполнения:

1. **Генерация DASS-наборов** (`scripts/generate_test_data.py`, `src/generators/`).
2. **Валидация входа** (структура гипотез, масс, источников, ограничений).
3. **Запуск сценариев для выбранной библиотеки** (`scripts/profile_benchmark.py`, `src/runners/`).
4. **Выполнение этапов комбинирования** через унифицированный адаптер (`src/adapters/`).
5. **Профилирование** (CPU, Memory, Line, Scalene) через слой `src/profiling/`.
6. **Сохранение артефактов** в иерархию `results/profiling/<library>/<run_id>/...`.
7. **Постобработка** (`scripts/processing/*`) и формирование сводных отчетов.

## 3. Архитектурные блоки

## 3.1 Генераторы и валидация (`src/generators/`)

- Формируют тестовые случаи разных классов сложности (tiny/small/medium/large/xlarge/stress/special).
- Гарантируют корректный формат входных JSON.
- Позволяют повторно использовать одинаковые наборы входных данных между библиотеками.

## 3.2 Адаптерный слой (`src/adapters/`)

- Каждый адаптер скрывает специфику конкретной библиотеки (`pyds`, `dstz`, `dstpy`, собственная реализация).
- Снаружи доступен единый контракт операций, поэтому runner не зависит от внутреннего API библиотек.
- Через фабрику адаптеров выбирается реализация по имени библиотеки.

## 3.3 Runner-слой (`src/runners/`)

- Управляет жизненным циклом запуска: загрузка входов, выбор адаптера, выполнение этапов, сбор метрик.
- Обеспечивает повторяемость за счет единой схемы параметров запуска.
- Разделяет функциональность обычного запуска и профилирующего запуска.

## 3.4 Профилирование (`src/profiling/`)

- Унифицированные интерфейсы профилировщиков: CPU, memory, line-level и Scalene.
- Коллекторы системных метрик и внешних артефактов профайлеров.
- Приведение результатов к стабильной структуре хранения для последующего анализа.

## 3.5 Постобработка (`scripts/processing/`)

- Сравнение результатов профилирования между библиотеками.
- Упаковка артефактов и построение аналитических сводок.
- Подготовка данных для визуализации и интерпретации.

## 4. Вычислительные этапы внутри сценария

Для каждого тестового кейса, как правило, выполняются шаги:

1. `step1_original` — базовая операция комбинирования.
2. `step2_dempster` — правило Демпстера.
3. `step3_discount_dempster` — дисконтирование + Демпстер.
4. `step4_yager` — правило Ягера.

Каждый этап может запускаться многократно (`repN`) для устойчивых измерений.

## 5. Структура входов и выходов

### Входы

- Каталог `data/` содержит наборы сценариев и вспомогательные описания.
- Для каждого теста формируется JSON со структурой DASS-входа.

### Выходы

- Основная директория артефактов: `results/profiling/`.
- Внутри разделение по библиотеке и идентификатору запуска.
- Типичные подпапки: `input/`, `test_results/`, `profilers/`, `logs/`.
- Файлы `session_info.json` и `run_parameters.json` фиксируют контекст запуска.

## 6. Воспроизводимость и прозрачность

Реализация ориентирована на техническую воспроизводимость:

- единые входные наборы для всех библиотек;
- фиксированные этапы выполнения;
- одинаковые профилировщики и формат хранения;
- полные логи и артефакты по каждому кейсу;
- возможность повторного анализа без повторного запуска бенчмарка.

## 7. Минимальный практический сценарий

```bash
pip install -r requirements.txt
python scripts/generate_test_data.py
python scripts/profile_benchmark.py --library pyds
python scripts/processing/compare_profiling_results.py
```

## 8. Рекомендации по расширению реализации

- Добавление новой библиотеки через новый адаптер + регистрацию в фабрике.
- Добавление нового профайлера через реализацию интерфейса `base_profiler`.
- Добавление новых тестовых классов через генератор и валидацию.
- Сохранение обратной совместимости структуры артефактов для накопительного анализа.

## 9. Где смотреть детали

- `README.md` — обзор и навигация.
- `src/generators/README.md` — генерация входов.
- `src/adapters/README.md` — контракт адаптеров.
- `src/runners/README.md` — логика выполнения сценариев.
- `src/profiling/README.md` — профилирование и артефакты.
- `scripts/README.md` — управляющие скрипты.
- `results/README.md` — формат выходных данных.
